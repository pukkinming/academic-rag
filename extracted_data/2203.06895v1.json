{
  "paper_id": "2203.06895v1",
  "title": "Topological Eeg Nonlinear Dynamics Analysis For Emotion Recognition",
  "published": "2022-03-14T07:31:42Z",
  "authors": [
    "Yan Yan",
    "Xuankun Wu",
    "Chengdong Li",
    "Yini He",
    "Zhicheng Zhang",
    "Huihui Li",
    "Ang Li",
    "Lei Wang"
  ],
  "keywords": [
    "EEG emotion recognition",
    "affective computing",
    "topological data analysis",
    "nonlinear dynamics",
    "phase space reconstruction",
    "dynamical systems",
    "biomedical signal processing"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Emotional recognition through exploring the electroencephalography (EEG) characteristics has been widely performed in recent studies. Nonlinear analysis and feature extraction methods for understanding the complex dynamical phenomena are associated with the EEG patterns of different emotions. The phase space reconstruction is a typical nonlinear technique to reveal the dynamics of the brain neural system. Recently, the topological data analysis (TDA) scheme has been used to explore the properties of space, which provides a powerful tool to think over the phase space. In this work, we proposed a topological EEG nonlinear dynamics analysis approach using the phase space reconstruction (PSR) technique to convert EEG time series into phase space, and the persistent homology tool explores the topological properties of the phase space. We perform the topological analysis of EEG signals in different rhythm bands to build emotion feature vectors, which shows high distinguishing ability. We evaluate the approach with two well-known benchmark datasets, the DEAP and DREAMER datasets. The recognition results achieved accuracies of 99.37% and 99.35% in arousal and valence classification tasks with DEAP, and 99.96%, 99.93%, and 99.95% in arousal, valence, and dominance classifications tasks with DREAMER, respectively. The performances are supposed to be outperformed current state-of-art approaches in DREAMER (improved by 1% to 10% depends on temporal length), while comparable to other related works evaluated in DEAP. The proposed work is the first investigation in the emotion recognition oriented EEG topological feature analysis, which brought a novel insight into the brain neural system nonlinear dynamics analysis and feature extraction.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "E MOTION recognition plays a vital role in affective computing, which identifies the human emotional states from behavioral activities or physiological signals. Accurately recognizing the human's emotional states significantly improve the reliability and intelligence level in human-computer interaction  [1] ,  [2] , healthcare monitoring  [3] ,  [4] , and behavior Y. Yan, X. Wu, C. Li, H. Li, and L. Wang are with the Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, Guangdong, 518055, China. E-mail: {yan.yan, xk.wu, cd.li, hh.li, wang.lei}@siat.ac.cn Y.  Yan  evaluation  [5]  applications. Physiological signals variation is spontaneous and complex to conceal when the emotional state changes, providing an ideal emotion recognition technique. EEG signals can be obtained easily with wearable systems measuring the voltage levels changes due to the ionic current flows variation in the neurons of the brain  [6] . As wearable technologies are dramatically developing, the EEG acquiring techniques provide a preferable way to explore brain responses to emotional stimuli. EEG-based emotion recognition has drawn an increasing amount of attention in recent years.\n\nThere are diverse emotion models proposed to describe emotional states. The discrete model categorized the emotional states into six discrete classes: anger, disgust, fear, happiness, sadness, and surprise. The dimensional model considered emotions with arousal, valence, and dominance levels  [7] , which describe the degree from unpleasant to pleasant, passive to active, and submissive to dominant, respectively  [8] . In this work, we use the dimensional model in the emotion recognition tasks, namely the arousal, valence, and dominance levels (low/high), which formed the low/high arousal (LA/HA), low/high valence (LV/HV), and low/high dominance (LD/HD) categories.\n\nEEG signals capture the brain activities with the electrodes placed at different head locations, which tracks the variations of different parts of encephalic regions. The collected EEG signals are often investigated in the bands of δ (1-4 Hz), θ (4-8 Hz), α (8-13 Hz), β (13-30 Hz), and γ (greater than 30 Hz)  [9] ,  [10] . The EEG signals were first decomposed to the frequency bands, and then the feature extracting was performed. Li et al.  [11]  proposed a gamma-band EEG-based emotions-happiness and sadness classification. Shi et al.  [12]  introduced a differential entropy-based approach toward EEGbased vigilance estimating with the EEG bands. Murugappan et al.  [13]  considered the alpha-band EEG signal to build nonlinear features to classify the emotions. This work considers the θ, α, β, and γ band of EEG as used in most emotion recognition applications.\n\nGenerally, the emotional recognition tasks were performed with feature extraction and classification with different classifiers. With the frequency band EEG signals, the common used features are differential entropies  [12] ,  [14] , power spectral density  [15] , differential asymmetry parameters  [16] , the rational asymmetry features  [17]  and the differential caudality  [10] . Meanwhile, the spatial and temporal features used to acquire temporal information in EEG-based emotion recognition, such as Hjorth feature  [18] , fractal dimension  [16] , higher order crossing feature  [19] , global field power temporal features  [20] , local-learning-based spatial-temporal components  [21] , group sparse canonical correlation analysis  [22] , empirical mode decomposition  [23] ,  [24]  and independent residual analysis  [25]  etc. Recently, a variety of deep learning structures have been proposed to extract EEG features toward emotional recognition. Zheng et al.  [10]  proposed a deep neural networks approach to investigate the critical frequency bands and channels for EEG-based emotion recognition. Xin et al.  [26]  combined an auto-encoder network and a subspace alignment solution in a unified framework toward EEG-based emotional state classification. Cui et al.  [27] ,  [28]  introduced an end-to-end regional-asymmetric convolutional neural network. Dynamical graph convolutional neural networks (DGCNN)  [29] , and sparse DGCNN model which modifies DGCNN by imposing a sparseness constraint was introduced by  [30] . Zhong et al.  [8]  proposed a regularized graph neural networksbased method toward emotion recognition using EEG signals.\n\nRecurrent models like reservoir computing  [31] , attentionbased convolutional recurrent neural network  [32]  was also involved in the EEG-based affection computing.\n\nMeanwhile, since EEG is generated by the brain system supposed to be highly complex, the acquired signals indicate nonlinearity, non-stationary and chaotic behavior  [33] . Nonlinear analysis of EEG signals has been widely performed and used to build features toward emotional recognition  [34] ,  [35] ,  [36] ,  [37] ,  [38] . Alcaraz et al.  [39]  conclude the nonlinear characterization of EEG into the five following categories:\n\n(1) Fractal fluctuations quantifications, as proposed in  [40] ,  [41] ,  [42] ; (2) Irregularities quantifications by entropy parameters, such as the works proposed in  [43] ,  [44] ,  [45] ,  [46] ,  [47] ; (3) Information contents quantifications by using discrete symbols, typical examples are  [48] ,  [49] ; (4) Chaos degree descriptors using PSR for feature extraction, such as Lyapunov exponents proposed in  [50] ,  [51] ,  [52] ; (5) Geometric representation of chaos developed in  [53] ,  [54] ,  [55] ,  [33] . The nonlinear characterization of EEG provided essential information of the brain state. The nonlinear descriptors widely adopted in EEG signal analysis show great discrimination ability in emotional states recognition.\n\nThe topological data analysis (TDA) scheme was recently proposed to represent point clouds' geometric structure, which inspired novel insights toward phase space information extraction. The TDA technique adopts a persistent homology  [56] ,  [57]  tool to describe the point clouds, providing a novel description of the structure of the point clouds and topological properties of the phase space. The nonlinear dynamics analysis with topological descriptions has been used in wheeze detection  [58] , heart dynamics analysis toward arrhythmia detection  [59] , gait dynamics analysis toward neurodegenerative disease discrimination  [60] ,  [61] , EEG-based dynamics analysis toward brain state recognition  [62] ,  [63] ,  [64] ,  [65] ,  [66] ,  [67] ,  [68] ,  [69]  and plenty of time series classification applications  [70] ,  [71] ,  [72] . This work proposes a topological nonlinear dynamics analysis approach toward EEG-based emotion recognizing as a complement of the phase space information, namely topological EEG nonlinear dynamics analysis (TEEGNDA). This work is supposed to be the first attempt at topological nonlinear analysis and topological machine learning in emotional state recognition and affective computing. The main contributions of this work are as follows:",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Ii. Preliminary Of Topological Data Analysis",
      "text": "",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "A. Simplicial Complex",
      "text": "Consider point set X in a space, any subset of a point cloud with cardinality k + 1 is called a k-simplex  [73] , as in the graph-theoretic context, the 0-simplices are vertices, 1-simplices are edges, 2-simplices are triangular faces, and 3-simplices are tetrahedrons (Figure  1 .(a)). One simplicial complexes (Figure  1 .(b)) include all the lower dimensional simplices along with their highest dimension ones, thus one graph composed of vertices and edges is described as a 1dimensional simplicial complex. Mathematically, Definition 1: A simplicial complex R is a finite collection of simplices, for each simplex σ, 1) any face of σ ∈ R is also in R, and 2) if σ 1 , σ 2 ∈ R, then σ 1 ∩ σ 2 is a face for both σ 1 and σ 2 .\n\nWith the simplex and simplicial complex notations, point cloud X is converted into a simplicial complex with: Definition 2: Given a scale parameter and a point cloud X, the Vietoris-Rips complex R(X, ) is defined as a simplicial complex contains all subsets with maximum diameter :\n\nin which diamσ means: Definition 3: Let T be a finite topological space with a metric of dist T . The diameter of T is the upper bound of the set of all pairwise distances, i.e.\n\nSince the topological space T is finite, the supremum is attained by some pairs of point, and alway exists when we investigate a point cloud with a finite number of point. Thus, the complex R contains a simplex σ = {v 0 , v 1 , . . .} if and only all the points v 0 , v 1 , . . . are within a distance of at most r to each other. The scale parameter is a variable ranging from 0 to ∞. With the Vietoris-Rips notation, the origin point cloud is R(X, 0), while all points merge in R(X, ∞). The topological properties of the space which the points lying on can be characterized via tracking the Vietoris-Rips complex while gradually increasing the scale parameter, namely the persistent homology technique.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "B. Persistent Homology",
      "text": "Consider the point cloud X with m points {x 1 , x 2 , . . . x m }. As increasing, the -spheres may merge to form new components, and holes (Figure  1 .(e)). 3) Finally, all B(X, ) object merge into one component when value turns large enough. The components and holes appear and disappear as illustrated in Figure  1 .(f), the connected components belong to the 0-dimensional homology class H 0 , while the holes belong to the 1-dimensional homology class H 1 . The H 1 instances are S 0 and S 1 , which denotes the hole located at the middle and bottom right of the complex, respectively.\n\nThe growing process with increasing radius parameters { 0 , 1 , 2 , . . .} ∈ :\n\nis represented as a sequence of complexes:\n\nMeanwhile, the subsequent Rips complex in the sequence is larger than its previous ones, which is as nested. The nested Rips complex sequence is called a filtration, which has the property that\n\nwhen 0 ≤ 1 ≤ . . . n . Thus, for each point cloud embedded from the time series, we have a Vietoris-Rips complex sequence with the varying , i.e., Vietoris-Rips filtration (the theoretical introduction and implementation algorithm of building Vietoris-Rips complex from point cloud are described detailedly in  [74] ). Through tracking the growing process, the birth-death ordered pairs for the homology objects are recorded as persistence of the homology. Mathematically, Definition 4: Let H be a homology class that get created in R(X, i ) and destroyed in R(X, j ), the corresponding filtration values are i , j . Then we say the homology class H has a persistence of:\n\nThe persistences and birth-death ordered pairs can be visualized using barcodes, which track the filtration values of the birth time and death time for each homology object in the nested sequence. The blue bars in the barcodes plot denote the persistence of connected components H 0 , while the red bars represent holes H 1 (Figure  1 .(f)). For higher dimensional phase space, the dimension of the homology class increase accordingly. However, in this work we focus only on three low dimensional homologies, i.e., H 0 , H 1 , and H 2 .",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "C. Topological Summaries",
      "text": "The persistence homology technique extracts the topological characteristics of the point cloud via recording the lifetime of the objects in different homology class. Consider the homology classes with dimensions of 0, 1, and 2, namely H 0 , H 1 , and H 2 . The homology numbers are A, B, C for H 0 , H 1 , and H 2 , respectively. Thus we have three sets to represent the topological features, for H 0 the topological summaries are:\n\nwhile for H 1 we have\n\nand for H 2 the summaries are represented with for l = 1 : 4 4:\n\n(1) Embed time series t = {t 1 , t 2 , . . . , t w } with d and τ to one point cloud X as in Equation  10 5:\n\n(2) Perform the persistent homology process as to build filtration as in 5 6:\n\n(3) Record the persistences and barcodes of H 0 , H 1 , and H 2 as in 7 and 8 7:\n\n(4) Extract the PL of the H 0 , H 1 , and H 2 objects from the barcodes with Equation  12 and Equation  13 7:\n\n(5) Compute the average values of the PLs for each homology class as F ijl 8:\n\nreturn\n\nThe EEG-based emotion recognition approaches include signal pre-processing, signal segmenting, feature extracting, and then used as input of the classifier to classify the emotional states. In this work, the pre-processed and segmented EEG data are firstly used to build feature sets and then recognized with the classifier. We extract the topological features from the EEG with three stages: rhythm band extraction, phase space reconstruction (PSR), topological summaries-based feature extraction, and feature-based emotion classification. The EEG signals are firstly denoised, and then four rhythm bands of θ, α, β, and γ are extracted. We use the PSR technique to convert the time series into the phase space via time-delay embedding for each EEG signal slice. Then we have 4 point clouds revealing the nonlinear dynamics from four different frequency bands. With the persistent homology technique introduced in Section II, we extract the topological summaries from the point clouds. Separately, we build the persistence landscape features based on the topological information of H 0 , H 1 , and H 2 from the point clouds. The rhythm bandbased persistence landscapes are stacked to build the topological features for each EEG channel. Finally, the band-based topological features are stacked to build the feature vectors and then used in the random forests classifier-based recognition system, with which the emotional recognition model is built and evaluated. We term the whole process as topological EEG nonlinear dynamics analysis (TEEGNDA) toward EEG-based emotion recognition. An overview of the proposed TEEGNDA approach is illustrated in Figure  2 . Meanwhile, we illustrate the TEEGNDA algorithm in Algorithm 1.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "B. Pre-Processing And Sub-Band Extraction",
      "text": "The EEG signals include low and high-frequency noise, which is useless in the emotion recognition task. Thus we consider a band-pass filter with cut-off frequencies of 1Hz and 75Hz. The pre-processed EEG signals contain the information within frequency from 1Hz to 75Hz. We extract the four frequency bands of θ, α, β, and γ, with band-pass filters with cut-off frequencies of 1-4Hz, 4-7Hz, 8-13Hz, and 13-30Hz, respectively. Then the sub-band rhythm-based EEG signals are segmented with the sliding windows. There are four sub-band signals extracted for each channel to perform further PSR and corresponding topological feature extraction described in the following part.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "C. Phase Space Reconstruction",
      "text": "A standard strategy for PSR is delay-coordinate embedding, with which the time series from a dynamical system is used to form vector-based points in phase space. Mathematically, for time series t = {t 1 , t 2 . . . t w }, the delay-coordinate embedding process is denoted as\n\nin which τ means the time delay parameter, while d is the dimension of the phase space, k denotes the point index in the point cloud. While the real-world sensors are time-length limited and interfered with by measurement noise, suitable delay-coordinate embedding parameters of τ and d are needed to unfold the dynamics. We suggest  [75]  for the discussions of the PSR in nonlinear time series analysis. We use the average mutual information approach (AMI)  [76]  toward choosing optimal τ , while the false near neighbor (FNN) algorithm  [77]  for d selection. Based on the recognition results of preliminary experiments, we choose the fixed parameters of τ = 8, while d = 10.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "D. Topological Features Extraction",
      "text": "The point cloud generated with the PSR technique reveals the dynamics of the nonlinear system. As described in Section II, the persistent homology tools develop topological descriptors of the nonlinear dynamics from the point cloud in the phase space. In this work, we consider the lower dimensional homology classes of H 0 , H 1 , and H 2 , the corresponding instances of the topological summaries are illustrated in Equation  7 , 8, and 9, respectively. An instance of barcodes illustrated 7 and 8 are illustrated in Figure  1 .(f) and 3.(a). The barcodes plots are further converted into persistence diagrams, which illustrates the persistence of homology object as point (horizontal axis as birth, while vertical for death) (Figure  3 ). In this work, we use PLs extracted from the sub-band point clouds. The main technical advantage of PL descriptor is that it is piecewise-linear functions that form feature vectors that are faster than using corresponding calculations with barcodes or persistence diagrams  [78] .\n\nMathematically, consider the point\n\nin which, b for birth time while d for death time. We tent each point with the function\n\nFormally, PL of a persistence diagram D is a collection of functions as:\n\nwhere k-max is the k-th largest value in the set, in this work we use k = 1 for the maximal value.\n\nFor an intuitive understanding of the PLs, we consider the two H 1 objects' barcodes information represented as two red bars in Figure  3 .(a), namely {{ 4 , 7 }, { 5 , 8 }}. The barcodes plot is converted into persistence diagrams as Figure  3 .(b), which uses the birth parameters as the horizontal axis, while that the endpoint of the barcodes as the vertical axis. Thus, the barcodes are turned into points ( 4 , 7 ) and ( 5 , 8 ) in Figure  3 .(b). Finally, the PLs are achieved via a rotate of the diagonal and the cumulative for the corresponding dimension of homologies, such as the two H 1 objects in Figure  3 .(c) with the blue silhouette curve. The advantage of the persistence landscape representation is that the barcodes and persistence diagrams are mapped as elements of functional space to make it possible to perform the statistical analysis and build machine learning models. Other theoretical analysis and advantages discussions can be referred to in  [79] . In this work, we use the average value of PLs of H 0 , H 1 , and H 2 as our topological features, which are used as the input for the classifier.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "E. Classification With Topological Features",
      "text": "In this work, we consider the following experiments to illustrate the distinguishing ability of the proposed topological approach:\n\n1) Exp. #1: TEEGNDA uses all available channel fusion strategies with four frequency bands EEG to perform emotional states. We use several popular classifiers combined with the extracted emotion feature vectors, including the Gaussian Naive Bayes (GNB) classifier, K-nearest neighbor (kNN) classifier, Logistic Regression (LR) classifier, support vector machine (SVM) classifier, and Random Forests (RF) classifier. 2) Exp. #2: TEEGNDA using single frequency band EEG of all available channel for emotion recognition to compare the rhythm band discrepancies.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Iv. Experiments",
      "text": "To validate the proposed approach, we conduct the experiments on two widely used databases, the DREAMER database and DEAP database, both include multiple channels of EEG recordings. First, we introduce the involved datasets; then we demonstrate the model implementations; finally, we present the experiments and results of Exp. #1, #2, #3, #4, and #5, respectively.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "A. Data Materials",
      "text": "The DEAP dataset includes physiological signals of 32 subjects (16 males and 16 females), which are recorded when watching 40 music videos. There are 32-channel EEG signals and other 8-channel physiological signals, in which only the EEG data are involved in the experiments. The EEG rate is resampled from 512Hz to 128Hz, and the electrooculography artifacts were removed using the blind source separation technique. The 40 one-minute clips were used to affect the participant's emotional state, with the self-assessment levels of arousal, valence, liking, and dominance for each video from 1 to 9 recorded. Details of the DEAP dataset can be referred to in  [80] . We select the valence and arousal classification tasks as our model assessment criteria with a threshold value of 5 (LV when valence score less than 5, and HV when greater than 5, the similar setting for LA/HA). Thus we have two binary classification tasks for the DEAP dataset, and we use DEAP-V and DEAP-A as the abbreviations of valence classification and arousal classification tasks, respectively.\n\nThe DREAMER database is a multimodal database including EEG and ECG recordings when the subjects were audio-visual stimulated. Twenty-three subjects (14 males and 9 females) were asked to record the self-assessment levels (1 to 5) of arousal, valence, and dominance after each stimulus. The EEG signals were recorded with a sampling frequency of 128Hz, while most of the artifacts were removed with linear phase FIR filters. The involved film clips' lengths ranging from 65 seconds to 393 seconds, which are used to arousal emotional states, the total number of the video used is 18. The locations of the headset are aligned according to the International 10-20 system: AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4, M1, and M2  [81] . The mastoid sensor at M1 acted as a ground reference point for comparing the voltage of all other sensors, while the mastoid sensor at M2 was a feed-forward reference for reducing external electrical interference. Details of the DREAMER dataset can be referred to in  [82] . Thus, the signal from the other 14 contact sensors was recorded and used for feature extraction. We choose the valence, arousal, and dominance levels to evaluate the models with a threshold value of 3. Similarly, we use DREAMER-V, DREAMER-A, and DREAMER-D as the abbreviations for the three tasks in DREAMER, respectively.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "B. Implementations",
      "text": "In this work, we only use the EEG signals from both datasets. After the preprocessing stage, in the DEAP dataset, we have 40 1-minute long time series for each subject, while in DREAMER, we have 18 time series (65s to 393s long) for each subject. Each time series is segmented with specific overlap settings using fixed sample length (details in the description of the following experiments). We shuffle all the segmented samples from different trials for each subject to build the training/testing sets, 80% used for training and 20% used for testing. Then, we use 10-fold cross-validation to assess the performance of the proposed model. The mean classification accuracies with standard deviations based on subject-specified experiments are used as our model assessment criterion. We use the Python package of giotto-tda  [83]  to perform the topological feature extraction, and scikitlearn  [84]  in classification and cross-validation. Most of the classifier parameters are based on the default parameters in the packages without further tuning.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "C. Exp. #1: Emotion Recognition With Teegnda",
      "text": "In Exp. #1, four rhythm bands from the preprocessed signal, including θ-band, α-band, β-band, and γ-band, are extracted. We perform the PSR and topological feature extraction from each rhythm separately to build the feature vector. The same procedures are performed to extract the topological features from the 32 channels of EEG in DEAP and 14 channels of EEG in DREAMER. For each band signal, we use d = 8 and τ = 10 as our PSR parameters to convert the signals into point clouds. Thus, the PLs are extracted from the point clouds. We set the PL distribution ranges as 50 for each subband frequency signal and point cloud, and then we have a 200-D feature vector for each channel, which means the dimensions of the final feature vectors are 6400 = 200 and 2800 = 200 × 14 for DEAP and DREAMER, respectively. At the same time, we use the 1s temporal window size (namely 128 points since the sampling frequency is 128Hz) with a 25% overlap to perform the EEG signal segmentation. For each subject, we use the TEEGNDA approach to distinguish the emotional states of the arousal and valence in DEAP, and arousal, valence and dominance in DREAMER as previous work in  [32] .",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "As Illustrated In",
      "text": "",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "D. Exp. #2: Emotion Recognition With Teegnda Based On Single Rhythm Band",
      "text": "In previous emotion recognition models, extracting information from the signals from different rhythm bands of EEG provides meaningful features to distinguish the emotional states. Thus, we consider comparing the classification ability with different EEG rhythm bands (here θ, α, β, and γ bands are involved). As shown in Table  II , the results of emotion recognition tasks using different rhythm bands are illustrated. For the DEAP dataset, the emotion recognition results for LA/HA are 97.27/2.77(%), 99.13/0.86(%), 83.29/5.37(%), and 86.38/5.19(%) with θ-band, α-band, β-band, and γ-band, respectively. The best performance accomplished is based on combining the four bands, namely the Total-column with 99.37/0.73(%), which is better than the single rhythm solution. The emotion recognition results for LA/HA classification in DEAP are 97.37/2.83(%), 99.20/0.95(%), 82.08/5.88(%), and 85.72/5.57(%) with θ-band, α-band, β-band, and γ-band, respectively. We can see that the fusion of the four rhythm bands is better performed than the single ones, as shown in the Total-column with an accuracy/standard deviation(%) of 99.35/0.91.\n\nMeanwhile, for the DREAMER dataset, the emotion recognition task of LA/HA in DREAMER are 99.81/0.34(%), 99.67/0.77(%), 98.16/1.46(%), and 97.42/2.16(%) with θband, α-band, β-band, and γ-band, respectively. The best performance was accomplished in the Total-column with an accuracy/standard deviation(%) of 99.96/0.07. The emotion recognition task of DREAMER-V is 99.86/0.36, 99.72/0.67, 98.22/1.46, and 97.61/1.76 with θ-band, α-band, β-band, and γ-band, respectively. The best performance was accomplished in the Total-column with an accuracy/standard deviation(%) of 99.93/0.07. The results of the emotion recognition task of DREAMER-D are 99.83/0.51, 99.81/0.46, 98.08/1.43, and 97.45/1.68 with θ-band, α-band, β-band, and γ-band, respectively. The best performance was accomplished in the Totalcolumn with an accuracy/standard deviation(%) of 99.95/0.07.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "E. Exp. #3: Emotion Recognition With Teegnda With Different Sliding Window Size",
      "text": "In Exp #3, we consider the model's performance with three kinds of temporal windows with different lengths (i.e., 1s, 2s, and 4s), the overlap for segmentation is 25%, and 3s with the overlap of 0%. With the four-band rhythm information from all available channels, the recognition results of the DEAP and DREAMER are illustrated in Table  III . With 1s temporal size of window with 25% overlap, we have accuracies/standard deviations(%) of 99.37/0.73, 99.35/0.91, 99.96/0.07, 99.93/0.07, and 99.95/0.07 for the five recognition tasks based on two datasets. While in 2s with 25% overlap case, we have accuracies/standard deviations(%) of 95.17/0.   III , we achieve the highest recognition accuracy with a 1s temporal window length in DEAP-A, DEAP-V, DREAMER-A, DREAMER-V, and DREAMER-D, which are better than other longer temporal window lengths. The performance reduced when the temporal window turns too long is due to the increasing of EEG signals complexity as the temporal size increases, which holds the same conclusion as in the previous studies.\n\nIn addition, we consider the 0.5s case to check the capability in tracking the small changes, with embedding parameters of d = 3, τ = 5 (the 0.5s-window segments contain only 64 points), and overlapping equals to 0. We accomplish accuracies/standard deviations(%) of 97.93/0.03, 98.28/0.03, 99.93/0.09, 99.92/0.10, and 99.82/0.53 for the five tasks. The detailed results of DEAP subjects are illustrated in the supplement file of  Most emotion-recognition BCI systems use multiple channels for feature extraction of dynamical functional connectivity analysis. Though the multi-channel settings contain much more information than the single-bipolar EEG channel case, the burden brought by the electrodes restricts the application in wearable systems for lightweight applications. Single-bipolar EEG channel settings can significantly reduce the complexity of emotion-recognition-based BCI systems. An example can be refereed in  [85] . This work considered the single-channel EEG-based emotion recognition task with two datasets using ground reference electrode points in the 10-20 system.\n\nIn Exp. #4, we systematically study the TEEGNDA analysis's channel variations, including emotion recognition experiments with single channels. The features involved in Exp #4 are based on the combination of four rhythm bands. The results proposed are based on the average accuracies of 32 subjects from the DEAP dataset, while 23 subjects from the DREAMER dataset. As Table  IV  illustrates, the single channel-based DEAP-A, DEAP-V tasks perform worse than the combination-of-all situation. However, the average accuracy(%) with single-channel EEG information is 90.60 with a standard deviation(%) of 0.52 in LA/HA-DEAP task and 89.78/0.59(%) in single channel-based LV/HV-DEAP task. The single-channel experiments results for DREAMER are illustrated in Table  V , with average accuracies/standard deviations(%) of 98.51/0.36, 98.44/0.39, and 98.47/0.39 for DREAMER-A, DREAMER-V, and DREAMER-D, respectively, lower than the multiple-channel fusion case.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "G. Exp. #5: Emotion Recognition With Multi-Class Assessments",
      "text": "In Exp. #5, we consider two multi-class emotion recognition tasks based on the valence, arousal, and dominance levels. Each emotion coordinate's high/low level in the valencearousal-dominance model could be mapped into the Plutchik Wheel emotion model  [31]  as mentioned above. Here we consider such two tasks from the involved dataset: the 4class classification in DEAP and the 8-class classification in DREAMER. The TEEGNDA framework built with RF classifier based on 1-s sliding window size of 25% overlap is performed on DEAP and DREAMER for the multi-class classification tasks. The PSR parameters are the as previous 1s case with d = 8 and τ = 10.\n\nAs illustrated in Table  VI , we use the average values of overall accuracies, mean precisions, mean recalls, and mean F1-Scores of the multiple emotion classes as the assessments of the model. For the 4-class classification task to distinguish LALV, LAHV, HALV, and HAHV labels in the DEAP dataset, the average recognition accuracy of the 32 subjects is 99.00% with a standard deviation of 1.38%. The average values/standard deviations of 4-class recall and F1-Scores are 98.36/2.30% and 98.80/1.67%. For the 8-class classification tasks in DREAMER, the average recognition accuracy of the 23 subjects is 99.89% with a standard deviation of 0.20%. The average values/standard deviations of 8-class recall and V. DISCUSSION EEG-based emotional state recognition contributes remarkably to a better understanding of human affections. Exploring the nonlinear dynamical system-based EEG features has been previously investigated using descriptors such as entropy, geometrical parameters, fractal dimensions. This work explores the topological properties of the nonlinear phase spaces of EEG sub rhythm band signals. We found that the topological features extracted show excellent distinguishing ability in EEG-based emotional state recognition with the persistent homology technique. Moreover, the EEG-based emotion recognition comparative studies of rhythm band, window size, and channel are also performed for comparisons, illustrating the proposed approach's robustness. The proposed topological nonlinear dynamics analysis scheme provides an alternative descriptor compared to standard widely adopted features such as differential entropy (DE), power spectral density (PSD), asymmetry (ASM), differential asymmetry (DASM), differential caudality (DCAU). Meanwhile, the TEEGNDA approach also shows competitive recognition ability compared to other recently proposed techniques. In this section, we first compare our results with some of the previous related studies in EEG-based emotion recognition, and then we illustrate the technique details, while finally, we discuss method limitations and potential future directions.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "A. Comparison With Related Work",
      "text": "There are a variety of works proposed for emotional state classification, typical rhythm sub-band EEG based features are DE, PSD, ASM, DASM, and DCAU  [9] ,  [10] ,  [30] . Recently, Zhang et al.  [30]  proposed a sparse dynamic graph convolutional neural network (sparse DGCNN) framework to investigate the rhythm sub-band EEG-based emotion recognition. Comprehensive comparisons have been proposed using the DE, PSD, ASM, DASM, and DCAU features. In  [29]  Despite the EEG rhythm band-based frameworks, there are a variety of approaches have been developed based on the preprocessed raw EEG. The recent fast-developing techniques of deep learning models adopted the representative ability of large-scale neural networks to reveal the nonlinearities of",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "B. Comparison With Other Nonlinear Dynamics Descriptors",
      "text": "The TEEGNDA approach is developed based on describing the nonlinear dynamics revealed in the phase space. We introduced some related works using other descriptions such as entropy-based and geometrical representation-based approaches in the introductions. Compared to current widely used descriptors, the TDA technique provides a choice to extract information from the phase space. Namely, we term it as topological nonlinear dynamics analysis, which shows excellent representative ability to classify the emotional states.\n\nIn order to show the superiorities, we perform the rhythm band analysis-based emotion recognition tasks using six typical nonlinear descriptors: fuzzy entropy, approximate entropy, sample entropy, recurrent plot, Poincare plot, and Lyapunov exponents (with 1s sliding window length and 25% overlap, implemented in the same way as in the TEEGNDA framework, by replacing the rhythm band signal feature extracting with these six nonlinear parameter calculation). The parameter of each approach is set as the same in our approach to guarantee fairness in the comparisons. As presented in Table  VIII , the TDA technique outperforms the other nonlinear descriptors, including entropy-based and geometry-based ones.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "C. Model Parameters Discussion",
      "text": "The EEG signals of different frequency bands were embedded into the phase space via time-delay embedding with fixed time-delay τ and dimension d. The embedding parameters determined how well the nonlinear dynamics revealed in the phase space could potentially impact the nonlinear models developed with statistical parameters or geometrical representation. The changing of embedding parameters causes the geometrical structure variation in phase space. The topological descriptors consider the state points' connection relationships underlaying the phase space, which are more robust than the geometrical descriptors such as recurrent or Poincare plots.\n\nThe tracked topological objects, such as the 1-dimensional homologies (holes) in the filtration process, are less impacted by the embedding parameters.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "D. Limitations And Potential Improvement",
      "text": "The subject-independent analysis has been widely considered in the EEG-based emotion recognition works, which were used to show the recognition ability of general patterns in EEG. Significantly, modern deep learning techniques provide a powerful tool to represent such kinds of cross-subject features as in  [10] ,  [30] ,  [8]  via the network structure. In the current work, the individual difference in EEG dramatically impacts the final recognition accuracy. Firstly, the emotional rating scores recorded through watching emotional film clips are different in different subjects in the emotion score site. The valence and arousal dimensions are different even using the same stimuli, caused by the differences in inner psychological characteristics. Secondly, in the physiological characteristics site, as a sensitive and real-time physiological model, EEG signals could vary from individual to individual due to their unique internal physiological characteristics  [30] . Thirdly in the nonlinear modeling site, the proposed model explores the topological description of the point clouds in the frequencyband EEG phase space, which reveals the nonlinear dynamics of the brain neural system, which is supposed to be mainly impacted by the individual physiological characteristics. The topological descriptions give subtle structure information of the point cloud in the phase space, as each point of the cloud illustrates a potential state of the nonlinear system revealed the personality and individual differences. Thus, the subjectindependent evaluation cannot deal with the three individual differences, which is supposed to be the main limitation in the subject-independent analysis compared to other feature-fusion systems and deep learning structures.",
      "page_start": 11,
      "page_end": 12
    },
    {
      "section_name": "Vi. Conclusion",
      "text": "In this paper, we proposed a topological nonlinear dynamics analysis scheme for EEG-based emotion recognition together with the TEEGNDA framework. The EEG signals reveal the brain dynamics as measurements of a nonlinear system in the dynamical system theory. The emotion states represented with arousal, valence, and dominance level are distinguished by investigating the phase spaces' topological properties of different EEG rhythm bands. The proposed TEEGNDA approach adopts persistent homology techniques to extract topological features from different EEG rhythm bands to build feature vectors toward emotion classification tasks. The results demonstrate that the TEEGNDA approach performs excellently in the subject-wise experiments in the DEAP and DREAMER datasets, namely with average accuracy/standard deviation (%) of 99.37/0.73 for DEAP-A, 99.35/0.91 for DEAP-V, 99.96/0.07 for DREAMER-A, 99.93/0.07 for DREAMER-V, and 99.95/0.07 for DREAMER-D, which show great performance and competitive to other models using the similar experimental settings. Furthermore, we compared the performance of the approach using different EEG rhythms bands, temporal windows, and single-channel choices. The proposed approach also shows good recognition ability with single-channel EEG signals. The topological features bring an alternative tool toward EEG signal analysis and brain dynamics analysis.",
      "page_start": 11,
      "page_end": 11
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: (a)). One simplicial",
      "page": 2
    },
    {
      "caption": "Figure 1: (b)) include all the lower dimensional",
      "page": 2
    },
    {
      "caption": "Figure 1: Preliminary of topological data analysis: (a) the k-simplexes; (b) the",
      "page": 3
    },
    {
      "caption": "Figure 1: (d)) {B(x1, ϵ), B(x2, ϵ), · · · , B(xm, ϵ)}.",
      "page": 3
    },
    {
      "caption": "Figure 1: (f), the connected components belong to the",
      "page": 3
    },
    {
      "caption": "Figure 1: (f)). For higher dimensional",
      "page": 3
    },
    {
      "caption": "Figure 1: (f) illustrates the barcodes demonstrations of H0 and",
      "page": 4
    },
    {
      "caption": "Figure 2: Meanwhile, we illustrate",
      "page": 4
    },
    {
      "caption": "Figure 2: The framework of the TEEGNDA model for EEG emotion recognition consists of the phase space reconstruction via time-delay embedding, Barcode",
      "page": 5
    },
    {
      "caption": "Figure 1: (f) and 3.(a). The",
      "page": 5
    },
    {
      "caption": "Figure 3: (a), namely {{ϵ4, ϵ7}, {ϵ5, ϵ8}}. The barcodes",
      "page": 5
    },
    {
      "caption": "Figure 3: (b). Finally, the PLs are achieved via a rotate of the",
      "page": 5
    },
    {
      "caption": "Figure 3: Persistence landscapes developed from the barcodes: (a) barcodes",
      "page": 6
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "S0\nS1\nS0": "dim 0: H0"
        },
        {
          "S0\nS1\nS0": "dim 1: H1"
        }
      ],
      "page": 3
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Multimodal emotion recognition in response to videos",
      "authors": [
        "M Soleymani",
        "M Pantic",
        "T Pun"
      ],
      "year": "2011",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "2",
      "title": "Physiological signals and their use in augmenting emotion recognition for human-machine interaction",
      "authors": [
        "R Knapp",
        "J Kim",
        "E André"
      ],
      "year": "2011",
      "venue": "Emotion-oriented Systems"
    },
    {
      "citation_id": "3",
      "title": "EEG-based emotion recognition approach for e-healthcare applications",
      "authors": [
        "M Ali",
        "A Mosa",
        "F Machot",
        "K Kyamakya"
      ],
      "year": "2016",
      "venue": "2016 eighth international conference on ubiquitous and future networks (ICUFN)"
    },
    {
      "citation_id": "4",
      "title": "Hurst exponent based brain behavior analysis of stroke patients using EEG signals",
      "authors": [
        "W Choong",
        "W Khairunizam",
        "M Murugappan",
        "M Omar",
        "S Bong",
        "A Junoh",
        "Z Razlan",
        "A Shahriman",
        "W Mustafa"
      ],
      "year": "2019",
      "venue": "Proceedings of the 11th National Technical Seminar on Unmanned System Technology"
    },
    {
      "citation_id": "5",
      "title": "Exploring EEG effective connectivity network in estimating influence of color on emotion and memory",
      "authors": [
        "M Chai",
        "H Amin",
        "L Izhar",
        "M Saad",
        "M Abdul Rahman",
        "A Malik",
        "T Tang"
      ],
      "year": "2019",
      "venue": "Frontiers in Neuroinformatics"
    },
    {
      "citation_id": "6",
      "title": "Robust multichannel EEG compressed sensing in the presence of mixed noise",
      "authors": [
        "C Li",
        "W Tao",
        "J Cheng",
        "Y Liu",
        "X Chen"
      ],
      "year": "2019",
      "venue": "IEEE Sensors Journal"
    },
    {
      "citation_id": "7",
      "title": "Pleasure-arousal-dominance: A general framework for describing and measuring individual differences in temperament",
      "authors": [
        "A Mehrabian"
      ],
      "year": "1996",
      "venue": "Current Psychology"
    },
    {
      "citation_id": "8",
      "title": "EEG-based emotion recognition using regularized graph neural networks",
      "authors": [
        "P Zhong",
        "D Wang",
        "C Miao"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "9",
      "title": "Identifying stable patterns over time for emotion recognition from EEG",
      "authors": [
        "W.-L Zheng",
        "J.-Y Zhu",
        "B.-L Lu"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "10",
      "title": "Investigating critical frequency bands and channels for EEG-based emotion recognition with deep neural networks",
      "authors": [
        "W.-L Zheng",
        "B.-L Lu"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on Autonomous Mental Development"
    },
    {
      "citation_id": "11",
      "title": "Emotion classification based on gamma-band EEG",
      "authors": [
        "M Li",
        "B.-L Lu"
      ],
      "year": "2009",
      "venue": "2009 Annual International Conference of the IEEE Engineering in medicine and biology society"
    },
    {
      "citation_id": "12",
      "title": "Differential entropy feature for EEG-based vigilance estimation",
      "authors": [
        "L.-C Shi",
        "Y.-Y Jiao",
        "B.-L Lu"
      ],
      "year": "2013",
      "venue": "2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)"
    },
    {
      "citation_id": "13",
      "title": "Appraising human emotions using time frequency analysis based EEG alpha band features",
      "authors": [
        "M Murugappan",
        "R Nagarajan",
        "S Yaacob"
      ],
      "year": "2009",
      "venue": "2009 Innovative Technologies in Intelligent Systems and Industrial Applications"
    },
    {
      "citation_id": "14",
      "title": "EEG-based emotion classification using deep belief networks",
      "authors": [
        "W.-L Zheng",
        "J.-Y Zhu",
        "Y Peng",
        "B.-L Lu"
      ],
      "year": "2014",
      "venue": "2014 IEEE International Conference on Multimedia and Expo (ICME)"
    },
    {
      "citation_id": "15",
      "title": "Toward emotion aware computing: an integrated approach using multichannel neurophysiological recordings and affective visual stimuli",
      "authors": [
        "C Frantzidis",
        "C Bratsas",
        "C Papadelis",
        "E Konstantinidis",
        "C Pappas",
        "P Bamidis"
      ],
      "year": "2010",
      "venue": "IEEE Transactions on Information Technology in Biomedicine"
    },
    {
      "citation_id": "16",
      "title": "Real-time fractal-based valence level recognition from EEG",
      "authors": [
        "Y Liu",
        "O Sourina"
      ],
      "year": "2013",
      "venue": "Transactions on Computational Science XVIII"
    },
    {
      "citation_id": "17",
      "title": "EEG-based emotion recognition in music listening",
      "authors": [
        "Y.-P Lin",
        "C.-H Wang",
        "T.-P Jung",
        "T.-L Wu",
        "S.-K Jeng",
        "J.-R Duann",
        "J.-H Chen"
      ],
      "year": "2010",
      "venue": "IEEE Transactions on Biomedical Engineering"
    },
    {
      "citation_id": "18",
      "title": "EEG analysis based on time domain properties",
      "authors": [
        "B Hjorth"
      ],
      "year": "1970",
      "venue": "Electroencephalography and Clinical Neurophysiology"
    },
    {
      "citation_id": "19",
      "title": "Emotion recognition from EEG using higher order crossings",
      "authors": [
        "P Petrantonakis",
        "L Hadjileontiadis"
      ],
      "year": "2009",
      "venue": "IEEE Transactions on Information Technology in Biomedicine"
    },
    {
      "citation_id": "20",
      "title": "Identification of spatial and temporal features of EEG",
      "authors": [
        "N Jrad",
        "M Congedo"
      ],
      "year": "2012",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "21",
      "title": "Spatial-temporal feature analysis on single-trial event related potential for rapid face identification",
      "authors": [
        "L Jiang",
        "Y Wang",
        "B Cai",
        "Y Wang",
        "Y Wang"
      ],
      "year": "2017",
      "venue": "Frontiers in Computational Neuroscience"
    },
    {
      "citation_id": "22",
      "title": "Multichannel EEG-based emotion recognition via group sparse canonical correlation analysis",
      "authors": [
        "W Zheng"
      ],
      "year": "2016",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems"
    },
    {
      "citation_id": "23",
      "title": "Emotion recognition from EEG signals by using multivariate empirical mode decomposition",
      "authors": [
        "A Mert",
        "A Akan"
      ],
      "year": "2018",
      "venue": "Pattern Analysis and Applications"
    },
    {
      "citation_id": "24",
      "title": "Electroencephalogram emotion recognition based on empirical mode decomposition and optimal feature selection",
      "authors": [
        "Z.-T Liu",
        "Q Xie",
        "M Wu",
        "W.-H Cao",
        "D.-Y Li",
        "S.-H Li"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems"
    },
    {
      "citation_id": "25",
      "title": "Temporal and spatial features of single-trial EEG for brain-computer interface",
      "authors": [
        "Q Zhao",
        "L Zhang"
      ],
      "year": "2007",
      "venue": "Computational Intelligence and Neuroscience"
    },
    {
      "citation_id": "26",
      "title": "Unsupervised domain adaptation techniques based on auto-encoder for non-stationary EEG-based emotion recognition",
      "authors": [
        "X Chai",
        "Q Wang",
        "Y Zhao",
        "X Liu",
        "O Bai",
        "Y Li"
      ],
      "year": "2016",
      "venue": "Computers in Biology and Medicine"
    },
    {
      "citation_id": "27",
      "title": "Spatial-temporal recurrent neural network for emotion recognition",
      "authors": [
        "T Zhang",
        "W Zheng",
        "Z Cui",
        "Y Zong",
        "Y Li"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Cybernetics"
    },
    {
      "citation_id": "28",
      "title": "EEGbased emotion recognition using an end-to-end regional-asymmetric convolutional neural network",
      "authors": [
        "H Cui",
        "A Liu",
        "X Zhang",
        "X Chen",
        "K Wang",
        "X Chen"
      ],
      "year": "2020",
      "venue": "Knowledge-Based Systems"
    },
    {
      "citation_id": "29",
      "title": "EEG emotion recognition using dynamical graph convolutional neural networks",
      "authors": [
        "T Song",
        "W Zheng",
        "P Song",
        "Z Cui"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "30",
      "title": "Sparsedgcnn: Recognizing emotion from multichannel EEG signals",
      "authors": [
        "G Zhang",
        "M Yu",
        "Y.-J Liu",
        "G Zhao",
        "D Zhang",
        "W Zheng"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "31",
      "title": "Unsupervised learning in reservoir computing for EEG-based emotion recognition",
      "authors": [
        "R Fourati",
        "B Ammar",
        "J Sanchez-Medina",
        "A Alimi"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "32",
      "title": "EEGbased emotion recognition via channel-wise attention and self attention",
      "authors": [
        "W Tao",
        "C Li",
        "R Song",
        "J Cheng",
        "Y Liu",
        "F Wan",
        "X Chen"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "33",
      "title": "Emotion recognition using EEG phase space dynamics and poincare intersections",
      "authors": [
        "M Soroush",
        "K Maghooli",
        "S Setarehdan",
        "A Nasrabadi"
      ],
      "year": "2020",
      "venue": "Biomedical Signal Processing and Control"
    },
    {
      "citation_id": "34",
      "title": "Nonlinear methodologies applied to automatic recognition of emotions: an EEG review",
      "authors": [
        "B García-Martínez",
        "A Martínez-Rodrigo",
        "R Alcaraz",
        "A Fernández-Caballero",
        "P González"
      ],
      "year": "2017",
      "venue": "International Conference on Ubiquitous Computing and Ambient Intelligence"
    },
    {
      "citation_id": "35",
      "title": "A novel method of EEG-based emotion recognition using nonlinear features variability and dempster-shafer theory",
      "authors": [
        "M Soroush",
        "K Maghooli",
        "S Setarehdan",
        "A Nasrabadi"
      ],
      "year": "2018",
      "venue": "Biomedical Engineering: Applications, Basis and Communications"
    },
    {
      "citation_id": "36",
      "title": "Recognizing affective state patterns using regularized learning with nonlinear dynamical features of EEG",
      "authors": [
        "M Fan",
        "C.-A Chou"
      ],
      "year": "2018",
      "venue": "2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)"
    },
    {
      "citation_id": "37",
      "title": "EEGbased emotion recognition using nonlinear feature",
      "authors": [
        "J Tong",
        "S Liu",
        "Y Ke",
        "B Gu",
        "F He",
        "B Wan",
        "D Ming"
      ],
      "year": "2017",
      "venue": "2017 IEEE 8th International Conference on Awareness Science and Technology (iCAST"
    },
    {
      "citation_id": "38",
      "title": "Emotion recognition through EEG phase space dynamics and dempstershafer theory",
      "authors": [
        "M Soroush",
        "K Maghooli",
        "S Setarehdan",
        "A Nasrabadi"
      ],
      "year": "2019",
      "venue": "Medical Hypotheses"
    },
    {
      "citation_id": "39",
      "title": "Recent advances and challenges in nonlinear characterization of brain dynamics for automatic recognition of emotional states",
      "authors": [
        "R Alcaraz",
        "B García-Martínez",
        "R Zangróniz",
        "A Martínez-Rodrigo"
      ],
      "year": "2017",
      "venue": "International Work-Conference on the Interplay Between Natural and Artificial Computation"
    },
    {
      "citation_id": "40",
      "title": "EEG-based subject-dependent emotion recognition algorithm using fractal dimension",
      "authors": [
        "Y Liu",
        "O Sourina"
      ],
      "year": "2014",
      "venue": "2014 IEEE International Conference on Systems, Man, and Cybernetics"
    },
    {
      "citation_id": "41",
      "title": "EEG based emotion recognition system using mfdfa as feature extractor",
      "authors": [
        "S Paul",
        "A Mazumder",
        "P Ghosh",
        "D Tibarewala",
        "G Vimalarani"
      ],
      "year": "2015",
      "venue": "2015 International Conference on Robotics, Automation, Control and Embedded Systems (RACE)"
    },
    {
      "citation_id": "42",
      "title": "Recognition of emotional states induced by music videos based on nonlinear feature extraction and som classification",
      "authors": [
        "S Hatamikia",
        "A Nasrabadi"
      ],
      "year": "2014",
      "venue": "2014 21th Iranian Conference on Biomedical Engineering (ICBME)"
    },
    {
      "citation_id": "43",
      "title": "Comparative study of approximate entropy and sample entropy robustness to spikes",
      "authors": [
        "A Molina-Picó",
        "D Cuesta-Frau",
        "M Aboy",
        "C Crespo",
        "P Miró-Martínez",
        "S Oltra-Crespo"
      ],
      "year": "2011",
      "venue": "Artificial Intelligence in Medicine"
    },
    {
      "citation_id": "44",
      "title": "Emotion recognition based on the sample entropy of EEG",
      "authors": [
        "X Jie",
        "R Cao",
        "L Li"
      ],
      "year": "2014",
      "venue": "Biomedical Materials and Engineering"
    },
    {
      "citation_id": "45",
      "title": "Application of entropy-based metrics to identify emotional distress from electroencephalographic recordings",
      "authors": [
        "B García-Martínez",
        "A Martínez-Rodrigo",
        "R Zangroniz Cantabrana",
        "J Garcia",
        "R Alcaraz"
      ],
      "year": "2016",
      "venue": "Entropy"
    },
    {
      "citation_id": "46",
      "title": "Emotional stress recognition system for affective computing based on bio-signals",
      "authors": [
        "S Hosseini",
        "M Khalilzadeh",
        "S Changiz"
      ],
      "year": "2010",
      "venue": "Journal of Biological Systems"
    },
    {
      "citation_id": "47",
      "title": "An improved multiscale entropy algorithm and its performance analysis in extraction of emotion EEG features",
      "authors": [
        "X Li",
        "J Xie",
        "Y Hou",
        "J Wang"
      ],
      "year": "2015",
      "venue": "High Technology Letters"
    },
    {
      "citation_id": "48",
      "title": "Novel algorithm for measuring the complexity of electroencephalographic signals in emotion recognition",
      "authors": [
        "D.-W Chen",
        "N Han",
        "J.-J Chen",
        "H Guo"
      ],
      "year": "2017",
      "venue": "Journal of Medical Imaging and Health Informatics"
    },
    {
      "citation_id": "49",
      "title": "Application of the feature extraction based on combination of permutation entropy and multi-fractal index to emotion recognition",
      "authors": [
        "X Li",
        "X Qi",
        "Y Tian",
        "X Sun",
        "M Fran",
        "E Cai"
      ],
      "year": "2016",
      "venue": "Chinese High Technology Letters"
    },
    {
      "citation_id": "50",
      "title": "Studying emotion through nonlinear processing of EEG",
      "authors": [
        "S Hoseingholizade",
        "M Golpaygani",
        "A Monfared"
      ],
      "year": "2012",
      "venue": "Procedia-Social and Behavioral Sciences"
    },
    {
      "citation_id": "51",
      "title": "Feature extraction for EEGbased emotion prediction applications through chaotic analysis",
      "authors": [
        "S Acar",
        "H Saraoglu",
        "S Akar"
      ],
      "year": "2015",
      "venue": "2015 19th National Biomedical Engineering Meeting (BIYOMUT)"
    },
    {
      "citation_id": "52",
      "title": "Nonlinear analysis of EEG signals at different mental states",
      "authors": [
        "K Natarajan",
        "R Acharya",
        "F Alias",
        "T Tiboleng",
        "S Puthusserypady"
      ],
      "year": "2004",
      "venue": "Biomedical Engineering Online"
    },
    {
      "citation_id": "53",
      "title": "EEG-based emotion recognition using recurrence plot analysis and k nearest neighbor classifier",
      "authors": [
        "F Bahari",
        "A Janghorbani"
      ],
      "year": "2013",
      "venue": "2013 20th Iranian Conference on Biomedical Engineering (ICBME)"
    },
    {
      "citation_id": "54",
      "title": "A recurrence quantification analysis-based channelfrequency convolutional neural network for emotion recognition from EEG",
      "authors": [
        "Y.-X Yang",
        "Z.-K Gao",
        "X.-M Wang",
        "Y.-L Li",
        "J.-W Han",
        "N Marwan",
        "J Kurths"
      ],
      "year": "2018",
      "venue": "Chaos: An Interdisciplinary Journal of Nonlinear Science"
    },
    {
      "citation_id": "55",
      "title": "Recurrence quantification analysis and neural networks for emotional EEG classification",
      "authors": [
        "A Goshvarpour",
        "A Abbasi",
        "A Goshvarpour"
      ],
      "year": "2016",
      "venue": "Applied Medical Informatics"
    },
    {
      "citation_id": "56",
      "title": "Persistent homology-a survey",
      "authors": [
        "H Edelsbrunner",
        "J Harer"
      ],
      "year": "2008",
      "venue": "Contemporary Mathematics"
    },
    {
      "citation_id": "57",
      "title": "A roadmap for the computation of persistent homology",
      "authors": [
        "N Otter",
        "M Porter",
        "U Tillmann",
        "P Grindrod",
        "H Harrington"
      ],
      "year": "2017",
      "venue": "EPJ Data Science"
    },
    {
      "citation_id": "58",
      "title": "Persistent homology of delay embeddings and its application to wheeze detection",
      "authors": [
        "S Emrani",
        "T Gentimis",
        "H Krim"
      ],
      "year": "2014",
      "venue": "IEEE Signal Processing Letters"
    },
    {
      "citation_id": "59",
      "title": "Nonlinear dynamic approaches to identify atrial fibrillation progression based on topological methods",
      "authors": [
        "B Safarbali",
        "S Golpayegani"
      ],
      "year": "2019",
      "venue": "Biomedical Signal Processing and Control"
    },
    {
      "citation_id": "60",
      "title": "Gait rhythm dynamics for neuro-degenerative disease classification via persistence landscape-based topological representation",
      "authors": [
        "Y Yan",
        "K Ivanov",
        "O Mumini Omisore",
        "T Igbe",
        "Q Liu",
        "Z Nie",
        "L Wang"
      ],
      "year": "2020",
      "venue": "Sensors"
    },
    {
      "citation_id": "61",
      "title": "Classification of neurodegenerative diseases via topological motion analysis-a comparison study for multiple gait fluctuations",
      "authors": [
        "Y Yan",
        "O Omisore",
        "Y.-C Xue",
        "H.-H Li",
        "Q.-H Liu",
        "Z.-D Nie",
        "J Fan",
        "L Wang"
      ],
      "year": "2020",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "62",
      "title": "Topological inference for EEG and MEG",
      "authors": [
        "J Kilner",
        "K Friston"
      ],
      "year": "2010",
      "venue": "The Annals of Applied Statistics"
    },
    {
      "citation_id": "63",
      "title": "Topological data analysis of single-trial electroencephalographic signals",
      "authors": [
        "Y Wang",
        "H Ombao",
        "M Chung"
      ],
      "year": "2018",
      "venue": "The annals of applied statistics"
    },
    {
      "citation_id": "64",
      "title": "Topological classifier for detecting the emergence of epileptic seizures",
      "authors": [
        "M Piangerelli",
        "M Rucco",
        "L Tesei",
        "E Merelli"
      ],
      "year": "2018",
      "venue": "BMC Research Notes"
    },
    {
      "citation_id": "65",
      "title": "Statistical persistent homology of brain signals",
      "authors": [
        "Y Wang",
        "H Ombao",
        "M Chung"
      ],
      "year": "2019",
      "venue": "ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing"
    },
    {
      "citation_id": "66",
      "title": "Parameter investigation of topological data analysis for EEG signals",
      "authors": [
        "F Altındis",
        "B Yılmaz",
        "S Borisenok",
        "K İc"
      ],
      "year": "2021",
      "venue": "Biomedical Signal Processing and Control"
    },
    {
      "citation_id": "67",
      "title": "Detecting autism spectrum disorder using topological data analysis",
      "authors": [
        "S Majumder",
        "F Apicella",
        "F Muratori",
        "K Das"
      ],
      "year": "2020",
      "venue": "ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing"
    },
    {
      "citation_id": "68",
      "title": "Topological signal processing in neuroimaging studies",
      "authors": [
        "Y Wang",
        "R Behroozmand",
        "L Johnson",
        "L Bonilha",
        "J Fridriksson"
      ],
      "year": "2020",
      "venue": "2020 IEEE 17th International Symposium on Biomedical Imaging Workshops (ISBI Workshops)"
    },
    {
      "citation_id": "69",
      "title": "Topological data analysis of task-based fmri data from experiments on schizophrenia",
      "authors": [
        "B Stolz",
        "T Emerson",
        "S Nahkuri",
        "M Porter",
        "H Harrington"
      ],
      "year": "2021",
      "venue": "Journal of Physics: Complexity"
    },
    {
      "citation_id": "70",
      "title": "On time-series topological data analysis: New data and opportunities",
      "authors": [
        "L Seversky",
        "S Davis",
        "M Berger"
      ],
      "year": "2016",
      "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition workshops"
    },
    {
      "citation_id": "71",
      "title": "Time series classification via topological data analysis",
      "authors": [
        "Y Umeda"
      ],
      "year": "2017",
      "venue": "Information and Media Technologies"
    },
    {
      "citation_id": "72",
      "title": "Chatter classification in turning using machine learning and topological data analysis",
      "authors": [
        "F Khasawneh",
        "E Munch",
        "J Perea"
      ],
      "year": "2018",
      "venue": "IFAC-PapersOnLine"
    },
    {
      "citation_id": "73",
      "title": "Persistent homology in multivariate data visualization",
      "authors": [
        "B Rieck"
      ],
      "year": "2017",
      "venue": "Persistent homology in multivariate data visualization"
    },
    {
      "citation_id": "74",
      "title": "Fast construction of the vietoris-rips complex",
      "authors": [
        "A Zomorodian"
      ],
      "year": "2010",
      "venue": "Computers & Graphics"
    },
    {
      "citation_id": "75",
      "title": "Nonlinear time-series analysis revisited",
      "authors": [
        "E Bradley",
        "H Kantz"
      ],
      "year": "2015",
      "venue": "Chaos: An Interdisciplinary Journal of Nonlinear Science"
    },
    {
      "citation_id": "76",
      "title": "Independent coordinates for strange attractors from mutual information",
      "authors": [
        "A Fraser",
        "H Swinney"
      ],
      "year": "1986",
      "venue": "Physical Review A"
    },
    {
      "citation_id": "77",
      "title": "Determining embedding dimension for phase-space reconstruction using a geometrical construction",
      "authors": [
        "M Kennel",
        "R Brown",
        "H Abarbanel"
      ],
      "year": "1992",
      "venue": "Physical Review A"
    },
    {
      "citation_id": "78",
      "title": "Statistical topological data analysis using persistence landscapes",
      "authors": [
        "P Bubenik"
      ],
      "year": "2015",
      "venue": "Journla of Machine Learning Research"
    },
    {
      "citation_id": "79",
      "title": "Stochastic convergence of persistence landscapes and silhouettes",
      "authors": [
        "F Chazal",
        "B Fasy",
        "F Lecci",
        "A Rinaldo",
        "L Wasserman"
      ],
      "year": "2014",
      "venue": "Proceedings of the Thirtieth Annual Symposium on Computational Geometry"
    },
    {
      "citation_id": "80",
      "title": "Deap: A database for emotion analysis; using physiological signals",
      "authors": [
        "S Koelstra",
        "C Muhl",
        "M Soleymani",
        "J.-S Lee",
        "A Yazdani",
        "T Ebrahimi",
        "T Pun",
        "A Nijholt",
        "I Patras"
      ],
      "year": "2011",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "81",
      "title": "Validation of the emotiv EPOC®-EEG gaming system for measuring research quality auditory ERPs",
      "authors": [
        "N Badcock",
        "P Mousikou",
        "Y Mahajan",
        "P De Lissa",
        "J Thie",
        "G Mcarthur"
      ],
      "year": "2013",
      "venue": "PeerJ"
    },
    {
      "citation_id": "82",
      "title": "Electrical modeling of semiconductor laser diode for heterodyne rof system simulation",
      "authors": [
        "W.-E Kassa",
        "A.-L Billabert",
        "S Faci",
        "C Algani"
      ],
      "year": "2013",
      "venue": "IEEE Journal of Quantum Electronics"
    },
    {
      "citation_id": "83",
      "title": "giotto-tda: A topological data analysis toolkit for machine learning and data exploration",
      "authors": [
        "G Tauzin",
        "U Lupo",
        "L Tunstall",
        "J Pérez",
        "M Caorsi",
        "A Medina-Mardones",
        "A Dassatti",
        "K Hess"
      ],
      "year": "2021",
      "venue": "Journal of Machine Learning Research"
    },
    {
      "citation_id": "84",
      "title": "Scikit-learn: Machine learning in python",
      "authors": [
        "F Pedregosa",
        "G Varoquaux",
        "A Gramfort",
        "V Michel",
        "B Thirion",
        "O Grisel",
        "M Blondel",
        "P Prettenhofer",
        "R Weiss",
        "V Dubourg"
      ],
      "year": "2011",
      "venue": "the Journal of Machine Learning Research"
    },
    {
      "citation_id": "85",
      "title": "Emotion recognition from single-channel EEG signals using a two-stage correlation and instantaneous frequency-based filtering method",
      "authors": [
        "S Taran",
        "V Bajaj"
      ],
      "year": "2019",
      "venue": "Computer methods and programs in biomedicine"
    },
    {
      "citation_id": "86",
      "title": "Recognition of emotions using multichannel EEG data and DBN-GC-based ensemble deep learning framework",
      "authors": [
        "J Dauwels",
        "H Chao",
        "H Zhi",
        "L Dong",
        "Y Liu"
      ],
      "year": "2018",
      "venue": "Computational Intelligence and Neuroscience",
      "doi": "10.1155/2018/9750904"
    }
  ]
}