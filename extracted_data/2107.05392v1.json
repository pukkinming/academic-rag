{
  "paper_id": "2107.05392v1",
  "title": "Fuzzy-Rough Nearest Neighbour Approaches For Emotion Detection In Tweets",
  "published": "2021-07-08T12:52:47Z",
  "authors": [
    "Olha Kaminska",
    "Chris Cornelis",
    "Veronique Hoste"
  ],
  "keywords": [
    "Fuzzy-rough nearest neighbour approach",
    "Emotion Detection",
    "Natural Language Processing"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Social media are an essential source of meaningful data that can be used in different tasks such as sentiment analysis and emotion recognition. Mostly, these tasks are solved with deep learning methods. Due to the fuzzy nature of textual data, we consider using classification methods based on fuzzy rough sets. Specifically, we develop an approach for the SemEval-2018 emotion detection task, based on the fuzzy rough nearest neighbour (FRNN) classifier enhanced with ordered weighted average (OWA) operators. We use tuned ensembles of FRNN-OWA models based on different text embedding methods. Our results are competitive with the best SemEval solutions based on more complicated deep learning methods.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Over the past decades, the increasing availability of digital text material has allowed the domain of Natural Language Processing (NLP) to make significant headway in a wide number of applications, such as for example in the detection of hate speech  [13]  or emotion detection  [19] .\n\nIn this paper, we report on our work on emotion detection for the SemEval-2018 Task 1 EI-oc: Affect in Tweets for English 1 [15]. This task represents a classification problem with tweets labeled with emotion intensity scores from 0 to 3 for four different emotions: anger, sadness, joy, and fear.\n\nWe explored this task in our previous work  [11] , using the weighted k Nearest Neighbours classification approach. We chose this method over popular neural network based solutions because of its explainability. Explainable models allow to investigate the classification progress and discover new patterns.\n\nOur purpose in this paper is to explore the efficiency of the fuzzy-rough nearest neighbour (FRNN) classifier  [10]  and its extensions based on ordered weighted average (OWA) operators  [3, 12]  for this task. The motivation behind the usage of FRNN is to investigate the potential of relatively simple and transparent instance-based methods for the emotion detection task, in comparison with the black-box solutions offered by deep learning approaches. While the latter can solve sentiment analysis tasks with remarkable accuracy, they provide very little insight about how they reach their conclusions. This does not mean that we dismiss deep learning technology altogether; indeed, to prepare tweets for classification, we represent them by numerical vectors using some of the most popular current neural network based text embedding models  [1, 2, 4, 17] . This strategy should allow us to strike the right balance between interpretability and accuracy of the approach.\n\nThe remainder of this paper has the following structure: Section 2 contains an overview of related work, focusing on the SemEval-2018 Task 1 winning solutions. Section 3 describes the main steps of our proposal, including data preprocessing and tweet representation and classification, and also recalls the competition's evaluation measures. Section 4 reports on our approach's performance for the training data in different setups, while Section 5 evaluates the best approach on the test data. Finally, Section 6 provides a discussion of the obtained results and some ideas for further research.\n\nThe source code of this paper is available online at the GitHub repository 2  .",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Related Work",
      "text": "We start this section by briefly describing the most successful solutions 3  to the SemEval-2018 shared task. The winning approach  [5]  used ensembles of XG-Boost and Random Forest classification models using tweet embedding vectors, while the second place was taken by  [6] , who used Long Short Term Memory (LSTM) neural nets with transfer learning. The third place contestants  [18]  presented a complex ensemble of models with Gated-Recurrent-Units (GRU) and a convolutional neural network (CNN) with the role of an attention mechanism.\n\nAs is clear, the best approaches all used deep learning technology in one way or another, thus reflecting the current state-of-the-art and trends in automated text analysis (see e.g.  [14]  for a comprehensive overview). This tendency is further reinforced by the use of the Pearson Correlation Coefficient (see formula  (6)  in Section 3.5) as the sole evaluation measure for the competition, since this measure lends itself well to NN-based optimization.\n\nTo gain more insight into how tweets express different emotions and emotion intensities, instance-based methods may be used that discern tweets based on a similarity or distance metric. In particular, we want to explore the use of fuzzy rough set techniques for this purpose. We are not the first to do so: for example, in  [21, 22] , Wang et al. used fuzzy rough set methods to discover emotions and their intensities in multi-label social media textual data.\n\nIn this paper, we will use the fuzzy rough nearest neighbour (FRNN) classification algorithm originally proposed in  [10] , and refined later with Ordered Weighted Average (OWA) operators  [3, 12] .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Methodology",
      "text": "In this section, we describe the key ingredients of our methodology. At the data level, we first discuss the data preprocessing steps and then elaborate on the different text embedding methods we implemented. Furthermore, we introduce the similarity relation we used to compare the tweet vectors and discuss the two main setups we used for classification, i.e., FRNN-OWA used as a standalone classifier and within an ensemble. We end the section by a description of the used evaluation method.\n\nThe task we consider is the emotion intensity ordinal classification task (EIoc,  [15] ) for the emotions anger, fear, joy, and sadness. The aim is to classify an English tweet into one of four ordinal classes. Each class represents a level of emotion intensity: 0 stands for \"no emotion can be inferred\", 1 corresponds to \"low amount of emotion can be inferred\", 2 means \"moderate amount of emotion can be inferred\", and 3 -\"high amount of emotion can be inferred\". For each emotion, the training, development, and test datasets were provided in the framework of the SemEval-2018 competition. We merge training and development datasets for training our model.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Data Cleaning",
      "text": "Before the embedding process, we may apply some operations to clean the tweets. In the first, general step, we delete account tags starting with @ , extra white spaces, newline symbols ('\\n'), all numbers, and punctuation marks. We do not delete hashtags because they can be a source of useful information  [16] , so we just remove # symbols. Also, we replace '&' with the word 'and' and replace emojis with their textual descriptions. We save emojis as they can be helpful for precision improvement  [23] . Emojis are represented either by punctuation marks and/or a combination of letters, or as a small image decoded with Unicode. For the first type, we used their descriptions from the list of emoticons on Wikipedia 4  for replacement. For the second type, we use the Python package \"emoji\" 5  for transformation.\n\nThe second step of tweet preprocessing is stop-word removal. For this purpose, the stop-words list from the NLTK package 6  is used.\n\nBoth general preprocessing and stop-word removal are optional for our purposes: during the experimental stage, we will examine whether they improve classification results or not.\n\nWe also explored some important characteristics of the datasets and presented them in Table  1 . One of characteristics is the class imbalance. It is quantified by the Imbalance Ratio (IR) which is equal to the ratio of the sizes of the largest and the smallest classes in the dataset.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Tweet Embedding",
      "text": "We represent each tweet as a vector, or set of vectors, to perform classification.\n\nFor this purpose, we use the following word embedding techniques:\n\n-Gensim pre-trained Word2Vec 7  , which contains a vocabulary with 3 million words and phrases and assigns a 300-dimension vector to each of them, obtained by training on a Google News dataset. -DeepMoji 8  is a state-of-the-art sentiment embedding model. Millions of tweets with emojis were used to train the model to recognize emotions. DeepMoji provides for each sentence (tweet) a vector of size 2,304 dimensions. The model has implementations for several Python packages, and we used the one on PyTorch, made available by Huggingface 9  . -Universal Sentence Encoder (USE)  [2]  is a sentence-level embedding method, which means it will create vectors for sentences or tweets as a whole. It was developed by the TensorFlow team  10  . USE provides a 512-dimensional vector for a text paragraph (tweet), and was trained on several data sources for different NLP tasks such as text classification, sentence similarity, etc. The model was trained in two ways, using a deep averaging network (DAN) and a Transformer encoder. We chose the second type of USE after basic experiments for our further experiments.\n\n-Bidirectional Encoder Representations from Transformers (BERT), proposed by Devlin et al.  [4] . The Google AI Language Team developed a script 11  that we use to assign pre-computed feature vectors with length 768 from a Py-Torch BERT model to all the words of a tweet. If the BERT vocabulary does not contain some word, then during the embedding, this word is split into tokens (for example, if the word \"tokens\" is not in the BERT dictionary, then it can be represented as \"tok\", \"##en\", \"##s\"), and a vector is created for each token. -Sentence-BERT (SBERT) is a tuned and modified BERT model developed by Reimers et al.  [17] . The model operates on the sentence level and provides vectors with the same size as the original BERT. SBERT is based on siamese (twin) and triplet network structures, which can processes two sentences (tweets) simultaneously in the same way. -The Twitter-roBERTa-based model for Emotion Recognition presented by Barbieri et al.  [1]  provides embeddings on word level similar to the original BERT. We consider one of seven fine-tuned roBERTa-based models trained for different tasks with specific data for each of them. The model we chose was trained for the emotion detection task from the same SemEval competition (E-c) using a different set of tweets  [15]  with emotions such as anger, joy, sadness, and optimism.\n\nAll listed sentence-level embeddings methods are applied to the tweets as a whole, while for the word-and token-level approaches, we calculated a tweet vector by taking its words' or tokens' vectors mean. The experiments were performed for all four emotion datasets and the obtained results are provided in Section 4.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Similarity Relation",
      "text": "To be able to compare tweet vectors, we need an adequate similarity relation. We opted for the cosine metric, given by Formula (1):  [7] .\n\nHere, A and B are elements from the same vector space, A • B is their scalar product, and ||x|| is the vector norm of element x.\n\nAs this metric returns values between -1 (perfectly dissimilar vectors), and 1 (perfectly similar vectors), we rescale them to [0,1] using Formula (2) below, which we will use as our primary similarity relation.\n\n(2)",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Classification Methods",
      "text": "In this section, we first recall the OWA-based Fuzzy Rough Nearest Neighbor (FRNN-OWA) classification method and then explain how to construct ensembles with it to solve the emotion detection task.\n\nFRNN-OWA The fuzzy rough nearest neighbour (FRNN) method  [8, 9, 10]  is an instance-based classifier that uses the lower (L) and upper (U) approximations from fuzzy rough set theory to make classifications. In order to make the method more robust and noise-tolerant, lower and upper approximations are usually calculated with Ordered Weighted Average (OWA) aggregation operators  [3] . The OWA aggregation of a set of values V using weight vector\n\nis given by Formula (3):\n\nwhere v (i) is the i th largest element in V .\n\nIn this paper, we used the following types of OWA operators 12  :\n\n-Strict weights, which contain only one non-zero position that does not depend on the actual values that are being aggregated:\n\n= 1, 0, ..., 0 . Strict weights correspond to the original FRNN proposal from  [8] .\n\n-Exponential weights (Exp), which are drawn from an exponential function with base 2:\n\n-Additive weights (Add), which model linearly decreasing or increasing weights:\n\np(p+1) , ..., 4 p(p+1) , 2 p(p+1) . -Inverse additive weights (Invadd) are also based on the ratio between consecutive elements in the weight vectors:\n\n1 p , the p th harmonic number.\n\n-Mean weights, which weight each element equally:\n\n-→\n\nWe used the implementation of the FRNN-OWA classifier  [12]  provided by the fuzzy-rough-learn package  13  . To classify a test instance y, the method calculates its membership to the lower and upper approximation of each decision class C:\n\nThe algorithm then assigns y to the class C for which C(y) + C(y) is highest.\n\nUsually, the computation in Formula (  4 ) is restricted to the k nearest neighbours of y from the training data belonging to classes other than C, while in Formula (5) we consider only y's k nearest neighbours from class C. There is no universal rule to determine the value of the parameter k. As a default, we\n\nwhere N is the size of the dataset. In order to examine the influence of k on the obtained classification results, we will use different k values for the best-performing approaches in our experiments for each dataset.\n\nWe performed experiments for each emotion dataset with different OWA types for lower and upper approximations with various numbers of k.\n\nClassifier ensembles We used the FRNN-OWA method both as a standalone method and as part of a classification ensemble. For this purpose, a separate model was trained for every choice of tweet embedding. Each model was based on each dataset's best setup and embedding (choice of tweet preprocessing, OWA types, and the number of neighbours k).\n\nTo determine the test label, we use a weighted voting function on the different outputs of our models. As possible voting functions v, we considered average, median, maximum, minimum, and majority. In the voting function the models' outputs receive some weights.\n\nThe full architecture of our ensemble approach is presented in Fig.  1 . In Section 4, we perform several experiments to detect the most accurate ensemble setup, including the best voting function, the most suitable values of weights -→ E , and the proper combination of models (feature vectors).",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Evaluation Method",
      "text": "We used 5-fold cross-validation to evaluate the results of our approaches. As evaluation measure the Pearson Correlation Coefficient (PCC)  (6)  was chosen, as it was also the evaluation measure used for the competition.\n\nAssuming that y is the vector of predicted values and x is the vector of correct values, we compute\n\nwhere x i and y i present the i th components of vectors x and y respectively and x and ȳ are their means.\n\nThe PCC measure provides a value between -1, which corresponds to a total negative linear correlation, and 1 -a total positive linear correlation, where 0 represents no linear correlation. Hence, the best classification model should provide the highest PCC.\n\nAfter submitting the obtained test labels to the competition web page, the PCC scores for each emotion dataset were averaged.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Experiments",
      "text": "In this section, we present our results for the classification approaches discussed in the previous section. Initially, we explore the best individual FRNN-OWA setup, including the preprocessing options, the chosen tweet embedding, the OWA types and the number of neighbours k. In a second set of experiments, we evaluate various ensemble approaches.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Detecting The Best Setup For Embeddings",
      "text": "We performed experiments with different OWA types to detect the best setup for each dataset. We also investigated for each dataset whether it was beneficial to apply tweet preprocessing and stop-words cleaning. Finally, we explored the most suitable k value for each embedding for each emotion dataset.\n\nFirst, the pipeline was performed for each embedding and emotion dataset after general preprocessing with the same OWA type for upper and lower approximations (strict, additive, exponential, and mean) and a different number of neighbors (from 5 to 23 with step 2). As the results showed, the best results were obtained with the additive (\"add\") OWA type for most embeddings, so we chose them for the further experiments. The best results for each dataset and each embedding are presented in Table  2 .\n\nNext, we calculated the PCC score for all embeddings and datasets with the best add OWA types, while varying the preparation level of the tweets: raw tweets (no preparation at all), standard preprocessing (text transformation steps mentioned in Section 3.1, excluding stop-words removal), and stop-words cleaning (the same as above, but including stop-words removal). To examine which setup works better, we performed a statistical analysis of results with a two-sided t-test (we assume the statistical significance of the p-value on the 0.05 level). For calculation, the Python's package stats was used. Results are presented in Table  2 . As we can see, some embeddings do not require any preprocessing at all, like DeepMoji and BERT. The standard preprocessing showed an improvement for other methods, and only Word2Vec seems to benefit from an additional stop-words removal step.\n\nFor most of the experiments, the obtained p-values are below the chosen threshold of 0.05. For some cases, the p-value was above the threshold, which means no significant difference exists between the compared options. In this situation, for the dataset, we chose the option that works better for other datasets. For example, for the BERT embedding, the joy dataset was the only one with the p > 0.05, when for anger, sadness, and fear p is below 0.05 (so cleaned tweets performed better). Hence, we will use cleaned tweets for joy because this is the best setup for the other emotions.\n\nFinally, for each embedding and dataset, we examined the PCC of the best setup (the combination of the best OWA types and the most efficient text preparation) for the different number of neighbours. The highest PCC scores and the proper k values are also listed in Table  2 .\n\nThe best setup for each combination of embedding and dataset was used in further experiments. We also can draw several intermediate conclusions. Remarkably, the highest PCC scores for all datasets among all embeddings were provided by the roBERTa-based model, which does not come as a surprise,since this model was fine-tuned on similar data and its performance is in line with earlier results for similar classification tasks  [1] . The second-best approach was DeepMoji, while BERT and Word2Vec provided the lowest scores. Also, we can see that the PCC scores for the fear dataset are often the lowest among the other emotions, which might probably be due to the fact that the fear dataset is the most unbalanced dataset. Similarly, the joy dataset shows high results, as the most balanced one.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Ensembles",
      "text": "To improve the PCC scores provided by individual embeddings, we also investigated an ensemble approach. To determine the best setup of the ensemble, we tuned several parameters, i.e., the voting function, the models' weights and the selection of the strongest embedding models.\n\nFirst, we compared different voting functions for all datasets: majority, mean, rounded mean, median, maximum, minimum. We note that for the majority voting function implementation we use the mode() function from the Python package stats. It chooses the most frequent label prediction, and in case of ties, this function returns the lowest value.\n\nNoteworthy is that some voting functions provide a float value between 0 and 3 instead of the required intensity labels 0, 1, 2, or 3. This was not a problem, though, during training because our labels are not different classes, but ordinal intensity labels. At testing time, the obtained values were rounded to submit our predictions. The general setup for comparing the voting functions was based on the six previously discussed models (one for each embedding method) with the parameters determined in Table  2 , where each predicted output has the same weight equal to 1. The results are presented in Table  3 . As we can see, the mean voting function consistently provided the best results for all datasets, while median performs second best. Although the rounding of the mean's output decreases the PCC results, it remains the best voting function. So, for further experiments, we will use the average as a voting function.\n\nNext, we check the use of weights assigned to the models' outputs in the voting function. In particular, we use confidence scores (CS) to give more weight to the better models.\n\nA confidence score is a float value, usually between 0 and 1, provided by a classification model for each prediction class. This value illustrates the accuracy of the model's prediction for a particular class. For FRNN-OWA, the models return four scores (one for each class). They are the mean membership degrees in the upper and lower approximations.\n\nTo get confidence scores, we divide each score by the sum of all four class scores. In this way, we obtain the values C i,j : four scores (one per class label i, i = 0, ..., 3) for every model j (j = 1, ..., 6). We use the confidence scores in the following ways:\n\n-Majority voting. The most intuitive approach, where we take as a prediction the label with the highest sum of confidence scores. -Weighted average (WA). As we saw above, the best voting function is the mean, so we will upgrade it with confidence scores as weights to calculate the prediction label as a weighted average of labels. The output could be a float number, so we also check the rounded option.\n\nExperiments were performed with all six embedding models. Results are provided in the upper half of Table  4 .  As we can see, weighted average with confidence scores performed the best. Predictably, rounding decreased the weighted average's score, and it is similar to the results provided by a majority of confidence scores. If we compare them with the values in Table  3 , considering the mandatory rounding step, we can conclude that these approaches with confidence scores do not increase PCC scores.\n\nWe analyzed the obtained confidence scores and noticed that they are close to each other, approximately, in the range from 0.4 to 0.6. Our hypothesis is that since we have a high dimensional task like ours, the confidence scores will be close to 0.5: the upper approximation memberships will be close to 1 and the lower ones to 0, resulting in similar values for each class. In other words, the contribution of such a classifier is low.\n\nTo mend this issue, we perform rescaling of the original membership scores in order to increase the differences among them. For this purpose, we subtract mean 0.5 from each score C i,j and divide the result by a small value α (0 < α < 1). Next, for each class i we compute the sum of the scores for each model. Since the obtained values may be negative, we use the softmax transformation to turn them into probabilities. The steps of this rescaling process are summarized in Formula (7):\n\nwhere α is a parameter to tune. To detect the best value of α for each dataset, we performed a grid search, calculating PCC scores for different α values to choose the one that provides the biggest PCC. Finally, to calculate the predicted label, we apply the weighted average on classes, where weights are calculated probabilities. Results of this approach with the best α for each dataset are provided in the lower half of Table  4 .\n\nCompared with the original confidence scores and values from Table  3 , scaled scores performed better for each dataset for both average and rounded average. Hence, we will use scaled confidence scores as models' output weights in the following experiments.\n\nThe last step of ensemble tuning is to determine the most accurate set of models in the ensemble. The idea behind this is to see how the PCC score will change depending on the models (embeddings) that we are using in the ensemble to answer the question: is it possible to improve the score by rejecting the weak models' results.\n\nFor this purpose, we used grid search, where the PCC score was calculated for each subset of all six models (features) and compared. The predicted label was calculated using a rounded average function with weights equal to the scaled confidence scores. We used a rounded average since it returns integers, so we can use them to submit to the competition web-page. In this way, we detected the best setup for each emotion dataset. The results for cross-validation evaluation are presented in Table  5 .\n\nAs we can see, all datasets have in common the same features such as roBERTa, DeepMoji, and USE models (we denote them with \"r/D/U\"). Another one or two features are different for each dataset. We can mainly see that more features provide better results, but the weak models' pruning also takes place.\n\nIn the end, we could obtain the best ensemble setup with the required parameters for each emotion dataset.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Results On The Test Data",
      "text": "From Section 4 we obtained the best setup for each dataset: an ensemble of several models based on different features with proper text preprocessing, k value, and additive lower and upper OWA types for each. The predicted test label is calculated as the mean of the models' outputs with scaled confidence scores as weights.\n\nTo measure the best ensemble's effectiveness, we evaluate it on the test data. We calculate PCC values for each emotion dataset and average the results, as was done by the competition organizers. As the output of the ensemble's mean voting function, obtained predictions are in float format, so to satisfy the submitting format, they were rounded to the nearest integer value. The obtained results are presented in Table  5 , where we provided results for the combined training and development data to compare them. As we can see from Table  5 , results for the test data are predictably worse than those for the combined training and development datasets. The PCC scores for sadness and joy datasets are higher than for anger, and fear, as usual, has lower results.\n\nWe submitted the predicted labels for the test data in the required format to the competition webpage  14  . After submission, we took the second place in the competition leader board with PCC = 0.654.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Conclusion And Future Work",
      "text": "In this paper, we designed a weighted ensemble of FRNN-OWA classifiers to tackle the emotion detection task. Our approach uses several embeddings, which are mostly sentiment-oriented and applied at sentence-level. We demonstrated that our method, despite its simple design, is competitive to the competition's winning approaches, which are all black-boxes.\n\nAs a possible improvement, we may consider additional text preparation steps, for example, bigger weights for hashtags and emojis or exclamation mark usage, before the embedding step.\n\nFinally, we hypothesize that the lower PCC scores the fear dataset could be related to the dataset's imbalance. As a possible approach to solve this issue, we may use specific classification machine learning methods for imbalanced data. For example, in paper  [20] , several fuzzy rough set theory methods are described specifically targeting imbalanced data sets.",
      "page_start": 13,
      "page_end": 13
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Scheme of the ensemble architecture.",
      "page": 7
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Ghent University, Ghent, Belgium": "{Olha.Kaminska,Chris.Cornelis,Veronique.Hoste}@UGent.be"
        },
        {
          "Ghent University, Ghent, Belgium": "Abstract. Social media are an essential source of meaningful data that"
        },
        {
          "Ghent University, Ghent, Belgium": "can be used in diﬀerent\ntasks\nsuch as\nsentiment analysis and emotion"
        },
        {
          "Ghent University, Ghent, Belgium": "recognition. Mostly, these tasks are solved with deep learning methods."
        },
        {
          "Ghent University, Ghent, Belgium": "Due to the fuzzy nature of textual data, we consider using classiﬁcation"
        },
        {
          "Ghent University, Ghent, Belgium": "methods based on fuzzy rough sets."
        },
        {
          "Ghent University, Ghent, Belgium": "Speciﬁcally, we develop an approach for the SemEval-2018 emotion de-"
        },
        {
          "Ghent University, Ghent, Belgium": "tection task, based on the fuzzy rough nearest neighbour (FRNN) clas-"
        },
        {
          "Ghent University, Ghent, Belgium": "siﬁer enhanced with ordered weighted average (OWA) operators. We use"
        },
        {
          "Ghent University, Ghent, Belgium": "tuned ensembles of FRNN–OWA models based on diﬀerent\ntext\nem-"
        },
        {
          "Ghent University, Ghent, Belgium": "bedding methods. Our\nresults are\ncompetitive with the best SemEval"
        },
        {
          "Ghent University, Ghent, Belgium": "solutions based on more complicated deep learning methods."
        },
        {
          "Ghent University, Ghent, Belgium": "Keywords: Fuzzy-rough nearest neighbour approach · Emotion Detec-"
        },
        {
          "Ghent University, Ghent, Belgium": "tion · Natural Language Processing"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1\nIntroduction": "Over\nthe past decades,"
        },
        {
          "1\nIntroduction": ""
        },
        {
          "1\nIntroduction": ""
        },
        {
          "1\nIntroduction": "of hate speech [13] or emotion detection [19]."
        },
        {
          "1\nIntroduction": ""
        },
        {
          "1\nIntroduction": "2018 Task 1 EI-oc: Aﬀect\nin Tweets"
        },
        {
          "1\nIntroduction": "classiﬁcation problem with tweets labeled with emotion intensity scores from 0"
        },
        {
          "1\nIntroduction": "to 3 for four diﬀerent emotions: anger, sadness,"
        },
        {
          "1\nIntroduction": ""
        },
        {
          "1\nIntroduction": "Neighbours classiﬁcation approach. We chose this method over popular neural"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "network based solutions because of\nits explainability. Explainable models allow"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "to investigate the classiﬁcation progress and discover new patterns."
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "Our purpose\nin this paper\nis\nto explore\nthe\neﬃciency of\nthe\nfuzzy-rough"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "nearest neighbour\n(FRNN) classiﬁer\n[10] and its extensions based on ordered"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "weighted average (OWA) operators [3,12]\nfor this task. The motivation behind"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "the usage of FRNN is to investigate the potential of relatively simple and trans-"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "parent\ninstance-based methods\nfor\nthe emotion detection task,\nin comparison"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "with the black-box solutions oﬀered by deep learning approaches. While the lat-"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "ter can solve sentiment analysis\ntasks with remarkable accuracy,\nthey provide"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "very little insight about how they reach their conclusions. This does not mean"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "that we dismiss deep learning technology altogether; indeed, to prepare tweets for"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "classiﬁcation, we represent\nthem by numerical vectors using some of\nthe most"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "popular current neural network based text embedding models\n[1,2,4,17]. This"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "strategy should allow us to strike the right balance between interpretability and"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "accuracy of the approach."
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "The remainder of this paper has the following structure: Section 2 contains an"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "overview of related work, focusing on the SemEval-2018 Task 1 winning solutions."
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "Section 3 describes the main steps of our proposal,\nincluding data preprocessing"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "and tweet\nrepresentation and classiﬁcation, and also recalls\nthe competition’s"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "evaluation measures. Section 4 reports on our approach’s performance for\nthe"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "training data in diﬀerent setups, while Section 5 evaluates the best approach on"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "the test data. Finally, Section 6 provides a discussion of the obtained results and"
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "some ideas for further research."
        },
        {
          "2\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "The source code of this paper is available online at the GitHub repository2."
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "FRNN Approaches for Emotion Detection in Tweets": "similarity or distance metric. In particular, we want to explore the use of",
          "3": "fuzzy"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "rough set techniques for this purpose. We are not the ﬁrst to do so: for example,",
          "3": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "in [21,22], Wang et al. used fuzzy rough set methods to discover emotions and",
          "3": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "their intensities in multi-label social media textual data.",
          "3": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "",
          "3": "In this paper, we will use the fuzzy rough nearest neighbour (FRNN) clas-"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "siﬁcation algorithm originally proposed in [10], and reﬁned later with Ordered",
          "3": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "Weighted Average (OWA) operators [3,12].",
          "3": ""
        }
      ],
      "page": 3
    },
    {
      "caption": "Table 1: One of characteristics is the class imbalance. It is quan-",
      "data": [
        {
          "4": "",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": "Both general preprocessing and stop-word removal are optional"
        },
        {
          "4": "poses: during the",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": "experimental\nstage, we will\nexamine whether"
        },
        {
          "4": "classiﬁcation results or not.",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": ""
        },
        {
          "4": "",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": "We also explored some\nimportant\ncharacteristics of"
        },
        {
          "4": "sented them in Table 1. One of characteristics is the class imbalance. It is quan-",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": ""
        },
        {
          "4": "tiﬁed by the Imbalance Ratio (IR) which is equal to the ratio of the sizes of the",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": ""
        },
        {
          "4": "largest and the smallest classes in the dataset.",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": ""
        },
        {
          "4": "Table 1. Characteristics of",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": "the\ncombined train and development data for"
        },
        {
          "4": "emotion datasets.",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": ""
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 1: One of characteristics is the class imbalance. It is quan-",
      "data": [
        {
          "We represent each tweet as a vector, or set of vectors, to perform classiﬁcation.": "For this purpose, we use the following word embedding techniques:"
        },
        {
          "We represent each tweet as a vector, or set of vectors, to perform classiﬁcation.": ""
        },
        {
          "We represent each tweet as a vector, or set of vectors, to perform classiﬁcation.": "words\nand phrases and assigns a 300-dimension vector"
        },
        {
          "We represent each tweet as a vector, or set of vectors, to perform classiﬁcation.": "obtained by training on a Google News dataset."
        },
        {
          "We represent each tweet as a vector, or set of vectors, to perform classiﬁcation.": ""
        },
        {
          "We represent each tweet as a vector, or set of vectors, to perform classiﬁcation.": ""
        },
        {
          "We represent each tweet as a vector, or set of vectors, to perform classiﬁcation.": "provides\nfor\neach sentence"
        },
        {
          "We represent each tweet as a vector, or set of vectors, to perform classiﬁcation.": "model has\nimplementations\nfor"
        },
        {
          "We represent each tweet as a vector, or set of vectors, to perform classiﬁcation.": "one on PyTorch, made available by Huggingface9."
        },
        {
          "We represent each tweet as a vector, or set of vectors, to perform classiﬁcation.": ""
        },
        {
          "We represent each tweet as a vector, or set of vectors, to perform classiﬁcation.": "which means\nit will\ncreate vectors"
        },
        {
          "We represent each tweet as a vector, or set of vectors, to perform classiﬁcation.": ""
        },
        {
          "We represent each tweet as a vector, or set of vectors, to perform classiﬁcation.": ""
        },
        {
          "We represent each tweet as a vector, or set of vectors, to perform classiﬁcation.": "for diﬀerent NLP tasks\nsuch as"
        },
        {
          "We represent each tweet as a vector, or set of vectors, to perform classiﬁcation.": ""
        },
        {
          "We represent each tweet as a vector, or set of vectors, to perform classiﬁcation.": ""
        },
        {
          "We represent each tweet as a vector, or set of vectors, to perform classiﬁcation.": "experiments for our further experiments."
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "– Bidirectional Encoder Representations from Transformers (BERT), proposed"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "by Devlin et al. [4]. The Google AI Language Team developed a script11 that"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "we use to assign pre-computed feature vectors with length 768 from a Py-"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "Torch BERT model\nto all\nthe words of a tweet.\nIf\nthe BERT vocabulary"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "does not contain some word, then during the embedding, this word is split"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "into tokens\n(for example,\nif\nthe word ”tokens” is not\nin the BERT dictio-"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "nary, then it can be represented as ”tok”, ”##en”, ”##s”), and a vector"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "is created for each token."
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "– Sentence-BERT (SBERT) is a tuned and modiﬁed BERT model developed"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "by Reimers et al. [17]. The model operates on the sentence level and provides"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "vectors with the same size as the original BERT. SBERT is based on siamese"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "(twin) and triplet network structures, which can processes\ntwo sentences"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "(tweets) simultaneously in the same way."
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "– The Twitter-roBERTa-based model\nfor Emotion Recognition presented by"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "Barbieri et al.\n[1] provides embeddings on word level similar to the original"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "BERT. We consider one of seven ﬁne-tuned roBERTa-based models trained"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "for diﬀerent tasks with speciﬁc data for each of them. The model we chose was"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "trained for the emotion detection task from the same SemEval competition"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "(E-c) using a diﬀerent\nset of\ntweets\n[15] with emotions\nsuch as anger,\njoy,"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n5": "sadness, and optimism."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "trained for the emotion detection task from the same SemEval competition": "(E-c) using a diﬀerent\nset of\ntweets\n[15] with emotions\nsuch as anger,\njoy,"
        },
        {
          "trained for the emotion detection task from the same SemEval competition": "sadness, and optimism."
        },
        {
          "trained for the emotion detection task from the same SemEval competition": "All\nlisted sentence-level\nembeddings methods are applied to the\ntweets as a"
        },
        {
          "trained for the emotion detection task from the same SemEval competition": "whole, while for\nthe word- and token-level approaches, we calculated a tweet"
        },
        {
          "trained for the emotion detection task from the same SemEval competition": "vector by taking its words’ or tokens’ vectors mean. The experiments were per-"
        },
        {
          "trained for the emotion detection task from the same SemEval competition": "formed for all\nfour emotion datasets and the obtained results are provided in"
        },
        {
          "trained for the emotion detection task from the same SemEval competition": "Section 4."
        },
        {
          "trained for the emotion detection task from the same SemEval competition": "3.3\nSimilarity relation"
        },
        {
          "trained for the emotion detection task from the same SemEval competition": "To be able to compare tweet vectors, we need an adequate similarity relation."
        },
        {
          "trained for the emotion detection task from the same SemEval competition": "We opted for the cosine metric, given by Formula (1):\n[7]."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "6\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "3.4\nClassiﬁcation methods"
        },
        {
          "6\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "In this\nsection, we ﬁrst\nrecall\nthe OWA-based Fuzzy Rough Nearest Neighbor"
        },
        {
          "6\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "(FRNN-OWA) classiﬁcation method and then explain how to construct ensem-"
        },
        {
          "6\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "bles with it to solve the emotion detection task."
        },
        {
          "6\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "FRNN-OWA The fuzzy rough nearest neighbour (FRNN) method [8,9,10]\nis"
        },
        {
          "6\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "an instance-based classiﬁer that uses the lower (L) and upper (U) approximations"
        },
        {
          "6\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "from fuzzy rough set theory to make classiﬁcations. In order to make the method"
        },
        {
          "6\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "more robust and noise-tolerant,\nlower and upper approximations are usually cal-"
        },
        {
          "6\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "culated with Ordered Weighted Average (OWA) aggregation operators [3]. The"
        },
        {
          "6\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "−"
        },
        {
          "6\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "OWA aggregation of a set of values V using weight vector\n= (cid:104)w1, w2, ..., w|V |(cid:105),"
        },
        {
          "6\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "is given by Formula (3):\nwith (∀i)(wi ∈ [0, 1]) and (cid:80)|V |"
        },
        {
          "6\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "i=1 wi = 1,"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "is the ith largest element in V .\nwhere v(i)": "In this paper, we used the following types of OWA operators12:"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "– Strict weights, which contain only one non-zero position that does not de-"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "pend on the actual values that are being aggregated:"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "strict\nstrict\n−\n−"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "→W\n= (cid:104)0, 0, ..., 1(cid:105)\nU\nL"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "original FRNN proposal\nfrom [8]."
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "– Exponential weights (Exp), which are drawn from an exponential"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "with base 2:"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "exp\n−"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "→W\n1"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "= (cid:104)\nL\n2p−1 ,\n2p−1 , ..., 2p−2\n2p−1 , 2p−1\n2p−1 (cid:105)"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "exp\n−"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "→W\n2\n1\n= (cid:104) 2p−1"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "U\n2p−1 , 2p−2\n2p−1 , ...,\n2p−1 ,\n2p−1 (cid:105)."
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "– Additive weights (Add), which model linearly decreasing or increasing weights:"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "add\n−"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "→W\n2\n2"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "= (cid:104)\nL\np(p+1) ,\np(p+1) , ..., 2(p−1)\np+1 (cid:105)"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "add\n−"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "→W\n4\n2"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "= (cid:104)\nU\np+1 , 2(p−1)\np(p+1) , ...,\np(p+1) ,\np(p+1) (cid:105)."
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "– Inverse additive weights (Invadd) are also based on the ratio between con-"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "secutive elements in the weight vectors:"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "invadd\n−"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "→W\n1\n1\n1"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "1D\n,\n, ...,\n,\n(cid:105)\n= (cid:104)\nL"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "pDp\n(p−1)Dp\n2Dp\np"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "invadd\n−"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "→W\n1\n1\n1"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "1D\n,\n, ...,\n,\n(cid:105),\n= (cid:104)\nU"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "p\n2Dp\n(p−1)Dp\npDp"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "1p\n, the pth harmonic number.\nwith Dp = (cid:80)p"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "i=1"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "– Mean weights, which weight each element equally:"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "mean\nmean\n−\n−"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "→W\n→W\n=\n= (cid:104) 1"
        },
        {
          "is the ith largest element in V .\nwhere v(i)": "L\nU\np , 1\np , ..., 1\np (cid:105)"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "its membership to the lower and upper approximation of each decision class C:"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "{1 − R(x, y) | x ∈ X \\ C})\n(4)\nC(y) = OW A−→"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "W L"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "{R(x, y) | x ∈ C})\n(5)\nC(y) = OW A−→"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "W U"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "The algorithm then assigns y to the class C for which C(y) + C(y) is highest."
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "Usually, the computation in Formula (4) is restricted to the k nearest neigh-"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "bours of y from the training data belonging to classes other\nthan C, while in"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "Formula (5) we consider only y’s k nearest neighbours\nfrom class C. There is"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "no universal\nrule to determine the value of\nthe parameter k. As a default, we"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "√"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "N2\n, where N is\nthe size of\nthe dataset.\nIn order\nto examine the\ncan put k ="
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "inﬂuence of k on the obtained classiﬁcation results, we will use diﬀerent k values"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "for the best-performing approaches in our experiments for each dataset."
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "We performed experiments\nfor\neach emotion dataset with diﬀerent OWA"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "types for lower and upper approximations with various numbers of k."
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "Classiﬁer ensembles We used the FRNN-OWA method both as a standalone"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "method and as part of a classiﬁcation ensemble. For\nthis purpose, a separate"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "model was trained for every choice of tweet embedding. Each model was based"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "on each dataset’s best setup and embedding (choice of tweet preprocessing, OWA"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "types, and the number of neighbours k)."
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "To determine the test label, we use a weighted voting function on the diﬀerent"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "outputs of our models. As possible voting functions v, we considered average,"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "median, maximum, minimum, and majority. In the voting function the models’"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "outputs receive some weights."
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "The\nfull architecture of our\nensemble approach is presented in Fig. 1.\nIn"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "Section 4, we perform several experiments to detect the most accurate ensemble"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "−"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n7": "setup,\nincluding the best voting function, the most suitable values of weights\n,"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table 2: Next, we calculated the PCC score for all embeddings and datasets with",
      "data": [
        {
          "8": "3.5",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": "Evaluation method"
        },
        {
          "8": "We used 5-fold cross-validation to evaluate",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": "the"
        },
        {
          "8": "evaluation measure the Pearson Correlation Coeﬃcient (PCC) (6) was chosen,",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": ""
        },
        {
          "8": "as it was also the evaluation measure used for the competition.",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": ""
        },
        {
          "8": "",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": "Assuming that y is the vector of predicted values and x is the vector of correct"
        },
        {
          "8": "values, we compute",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": ""
        },
        {
          "8": "",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": "(cid:80)"
        },
        {
          "8": "",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": "i (xi − ¯x)(yi − ¯y)"
        },
        {
          "8": "",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": ",\nP CC ="
        },
        {
          "8": "",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": "(cid:112)(cid:80)"
        },
        {
          "8": "",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": "i (yi − ¯y)2\ni (xi − ¯x)2 (cid:80)"
        },
        {
          "8": "",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": "where xi and yi present the ith components of vectors x and y respectively"
        },
        {
          "8": "and ¯x and ¯y are their means.",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": ""
        },
        {
          "8": "",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": "The PCC measure provides a value between -1, which corresponds to a total"
        },
        {
          "8": "negative",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": "linear\ncorrelation, and 1 - a total positive\nlinear"
        },
        {
          "8": "0 represents no linear correlation. Hence,",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": ""
        },
        {
          "8": "provide the highest PCC.",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": ""
        },
        {
          "8": "",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": "After submitting the obtained test labels to the competition web page, the"
        },
        {
          "8": "PCC scores for each emotion dataset were averaged.",
          "Olha Kaminska , Chris Cornelis, and Veronique Hoste": ""
        }
      ],
      "page": 8
    },
    {
      "caption": "Table 2: The best setup for each combination of dataset and embedding.",
      "data": [
        {
          "FRNN Approaches for Emotion Detection in Tweets": "",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "Anger",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "roBERTa-based",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "Yes",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "No",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "19",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "0.6779 0.6956",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "DeepMoji",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "No",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "No",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "23",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "0.5853 0.6520",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "BERT",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "No",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "No",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "19",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "0.4492 0.5374",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "SBERT",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "Yes",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "No",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "19",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "0.5016 0.5660",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "USE",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "Yes",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "No",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "23",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "0.5054 0.5693",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "Word2Vec",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "Yes",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "Yes",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "21",
          "9": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "0.5009 0.5099",
          "9": ""
        }
      ],
      "page": 9
    },
    {
      "caption": "Table 2: The best setup for each combination of embedding and dataset was used",
      "data": [
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "Finally,\nfor each embedding and dataset, we examined the PCC of the best"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "setup (the combination of the best OWA types and the most eﬃcient text prepa-"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "ration) for the diﬀerent number of neighbours. The highest PCC scores and the"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "proper k values are also listed in Table 2."
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "The best\nsetup for\neach combination of\nembedding and dataset was used"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "in further experiments. We also can draw several\nintermediate conclusions. Re-"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "markably,\nthe highest PCC scores\nfor all datasets among all embeddings were"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "provided by the roBERTa-based model, which does not come as a surprise,since"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "this model was ﬁne-tuned on similar data and its performance is\nin line with"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "earlier results for similar classiﬁcation tasks [1]. The second-best approach was"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "DeepMoji, while BERT and Word2Vec provided the lowest scores. Also, we can"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "see that the PCC scores for the fear dataset are often the lowest among the other"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "emotions, which might probably be due to the fact that the fear dataset is the"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "most unbalanced dataset. Similarly,\nthe joy dataset\nshows high results, as\nthe"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "most balanced one."
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "4.2\nEnsembles"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "To improve the PCC scores provided by individual embeddings, we also investi-"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "gated an ensemble approach. To determine the best setup of the ensemble, we"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "tuned several parameters,\ni.e., the voting function, the models’ weights and the"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "selection of the strongest embedding models."
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "First, we compared diﬀerent voting functions for all datasets: majority, mean,"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "rounded mean, median, maximum, minimum. We note\nthat\nfor\nthe majority"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "voting function implementation we use the mode()\nfunction from the Python"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "package stats. It chooses the most frequent label prediction, and in case of ties,"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "this function returns the lowest value."
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "Noteworthy is that some voting functions provide a ﬂoat value between 0 and"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "3 instead of the required intensity labels 0, 1, 2, or 3. This was not a problem,"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "though, during training because our labels are not diﬀerent classes, but ordinal"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "intensity labels. At\ntesting time,\nthe obtained values were rounded to submit"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "our predictions. The general setup for comparing the voting functions was based"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "on the six previously discussed models (one for each embedding method) with"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "the parameters determined in Table 2, where\neach predicted output has\nthe"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "same weight equal\nto 1. The results are presented in Table 3. As we can see,"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "the mean voting function consistently provided the best results for all datasets,"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "while median performs second best. Although the rounding of the mean’s output"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "decreases the PCC results,\nit remains the best voting function. So,\nfor further"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "experiments, we will use the average as a voting function."
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "Next, we check the use of weights assigned to the models’ outputs\nin the"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "voting function. In particular, we use conﬁdence scores (CS) to give more weight"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "to the better models."
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "A conﬁdence score is a ﬂoat value, usually between 0 and 1, provided by a"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "classiﬁcation model\nfor each prediction class. This value illustrates the accuracy"
        },
        {
          "10\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "of\nthe model’s prediction for a particular class. For FRNN-OWA,\nthe models"
        }
      ],
      "page": 10
    },
    {
      "caption": "Table 3: Results for ensembles with different voting functions for all datasets.",
      "data": [
        {
          "FRNN Approaches for Emotion Detection in Tweets": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "Voting function Anger"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "0.6141"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": ""
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "0.6485"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "0.6414"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "0.4856"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets": "0.5959"
        }
      ],
      "page": 11
    },
    {
      "caption": "Table 3: Results for ensembles with different voting functions for all datasets.",
      "data": [
        {
          "Maximum": "Minimum",
          "0.4856": "0.5959",
          "0.4668": "0.6411",
          "0.5625": "0.5016",
          "0.5640": "0.3885"
        },
        {
          "Maximum": "",
          "0.4856": "",
          "0.4668": "",
          "0.5625": "",
          "0.5640": ""
        },
        {
          "Maximum": "",
          "0.4856": "",
          "0.4668": "",
          "0.5625": "",
          "0.5640": ""
        },
        {
          "Maximum": "To get conﬁdence scores, we divide each score by the sum of all",
          "0.4856": "",
          "0.4668": "",
          "0.5625": "",
          "0.5640": ""
        },
        {
          "Maximum": "In this way, we obtain the values Ci,j:",
          "0.4856": "",
          "0.4668": "",
          "0.5625": "four\nscores",
          "0.5640": "(one per class"
        },
        {
          "Maximum": "",
          "0.4856": "",
          "0.4668": "",
          "0.5625": "",
          "0.5640": ""
        },
        {
          "Maximum": "",
          "0.4856": "",
          "0.4668": "",
          "0.5625": "",
          "0.5640": ""
        }
      ],
      "page": 11
    },
    {
      "caption": "Table 3: Results for ensembles with different voting functions for all datasets.",
      "data": [
        {
          "Table 4. Results for ensembles with diﬀerent usage of conﬁdence scores for all datasets.": "Approach"
        },
        {
          "Table 4. Results for ensembles with diﬀerent usage of conﬁdence scores for all datasets.": ""
        },
        {
          "Table 4. Results for ensembles with diﬀerent usage of conﬁdence scores for all datasets.": "Majority voting"
        },
        {
          "Table 4. Results for ensembles with diﬀerent usage of conﬁdence scores for all datasets.": "Weighted average"
        },
        {
          "Table 4. Results for ensembles with diﬀerent usage of conﬁdence scores for all datasets.": "WA rounded"
        },
        {
          "Table 4. Results for ensembles with diﬀerent usage of conﬁdence scores for all datasets.": ""
        },
        {
          "Table 4. Results for ensembles with diﬀerent usage of conﬁdence scores for all datasets.": "Weighted average"
        },
        {
          "Table 4. Results for ensembles with diﬀerent usage of conﬁdence scores for all datasets.": ""
        },
        {
          "Table 4. Results for ensembles with diﬀerent usage of conﬁdence scores for all datasets.": "WA rounded"
        },
        {
          "Table 4. Results for ensembles with diﬀerent usage of conﬁdence scores for all datasets.": ""
        }
      ],
      "page": 11
    },
    {
      "caption": "Table 4: ComparedwiththeoriginalconfidencescoresandvaluesfromTable3,scaled",
      "data": [
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "We analyzed the obtained conﬁdence scores and noticed that they are close"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "to each other, approximately,\nin the range from 0.4 to 0.6. Our hypothesis\nis"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "that since we have a high dimensional task like ours, the conﬁdence scores will"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "be close to 0.5: the upper approximation memberships will be close to 1 and the"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "lower ones\nto 0,\nresulting in similar values\nfor each class.\nIn other words,\nthe"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "contribution of such a classiﬁer is low."
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "To mend this issue, we perform rescaling of the original membership scores"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "in order to increase the diﬀerences among them. For this purpose, we subtract"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "and divide\nthe\nresult by a small value α\nthe mean 0.5 from each score Ci,j"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "(0 < α < 1). Next,\nfor\neach class\ni we\ncompute\nthe\nsum of\nthe\nscores\nfor"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "each model. Since\nthe obtained values may be negative, we use\nthe\nsoftmax"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "transformation to turn them into probabilities. The steps of this rescaling process"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "are summarized in Formula (7):"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "exp((cid:80)"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "j(Ci,j − 0.5)/α)"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": ",\n(7)\nCi ="
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "k exp((cid:80)\nj(Ck,j − 0.5)/α)"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "where α is a parameter to tune. To detect the best value of α for each dataset, we"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "performed a grid search, calculating PCC scores for diﬀerent α values to choose"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "the one that provides the biggest PCC."
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "Finally,\nto calculate the predicted label, we apply the weighted average on"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "classes, where weights are calculated probabilities. Results of this approach with"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "the best α for each dataset are provided in the lower half of Table 4."
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "Compared with the original conﬁdence scores and values from Table 3, scaled"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "scores performed better for each dataset for both average and rounded average."
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "Hence, we will use\nscaled conﬁdence\nscores as models’ output weights\nin the"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "following experiments."
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "The last\nstep of ensemble tuning is\nto determine the most accurate set of"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "models in the ensemble. The idea behind this is to see how the PCC score will"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "change depending on the models (embeddings) that we are using in the ensemble"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "to answer the question:\nis it possible to improve the score by rejecting the weak"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "models’ results."
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "For this purpose, we used grid search, where the PCC score was calculated"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "for each subset of all six models (features) and compared. The predicted label"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "was calculated using a rounded average function with weights equal to the scaled"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "conﬁdence scores. We used a rounded average since it returns integers, so we can"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "use them to submit to the competition web-page.\nIn this way, we detected the"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "best setup for each emotion dataset. The results for cross-validation evaluation"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "are presented in Table 5."
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "As we\ncan see,\nall datasets have\nin common the\nsame\nfeatures\nsuch as"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "roBERTa, DeepMoji, and USE models\n(we denote them with “r/D/U”). An-"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "other one or two features are diﬀerent for each dataset. We can mainly see that"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "more features provide better\nresults, but\nthe weak models’ pruning also takes"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "place."
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "In the end, we could obtain the best ensemble setup with the required pa-"
        },
        {
          "12\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "rameters for each emotion dataset."
        }
      ],
      "page": 12
    },
    {
      "caption": "Table 5: , where we provided results for the combined",
      "data": [
        {
          "FRNN Approaches for Emotion Detection in Tweets\n13": "5\nResults on the test data"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n13": "From Section 4 we obtained the best\nsetup for\neach dataset: an ensemble of"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n13": "several models based on diﬀerent\nfeatures with proper\ntext preprocessing, k"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n13": "value, and additive lower and upper OWA types\nfor each. The predicted test"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n13": "label\nis calculated as\nthe mean of\nthe models’ outputs with scaled conﬁdence"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n13": "scores as weights."
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n13": "To measure the best ensemble’s eﬀectiveness, we evaluate it on the test data."
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n13": "We calculate PCC values for each emotion dataset and average the results, as was"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n13": "done by the competition organizers. As the output of the ensemble’s mean voting"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n13": "function, obtained predictions are in ﬂoat format, so to satisfy the competition’s"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n13": "submitting format, they were rounded to the nearest integer value. The obtained"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n13": "results are presented in Table 5, where we provided results\nfor\nthe combined"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n13": "training and development data to compare them."
        }
      ],
      "page": 13
    },
    {
      "caption": "Table 5: , where we provided results for the combined",
      "data": [
        {
          "Table 5. The best approach on the cross-validation and test data for all datasets.": "Dataset"
        },
        {
          "Table 5. The best approach on the cross-validation and test data for all datasets.": ""
        },
        {
          "Table 5. The best approach on the cross-validation and test data for all datasets.": "Anger"
        },
        {
          "Table 5. The best approach on the cross-validation and test data for all datasets.": "Joy"
        },
        {
          "Table 5. The best approach on the cross-validation and test data for all datasets.": "Sadness"
        },
        {
          "Table 5. The best approach on the cross-validation and test data for all datasets.": "Fear"
        },
        {
          "Table 5. The best approach on the cross-validation and test data for all datasets.": "Averaged scores"
        }
      ],
      "page": 13
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "14\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "As a possible\nimprovement, we may consider additional\ntext preparation"
        },
        {
          "14\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "steps,\nfor example, bigger weights for hashtags and emojis or exclamation mark"
        },
        {
          "14\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "usage, before the embedding step."
        },
        {
          "14\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "Finally, we hypothesize that the lower PCC scores for the fear dataset could"
        },
        {
          "14\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "be related to the dataset’s imbalance. As a possible approach to solve this issue,"
        },
        {
          "14\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "we may use speciﬁc classiﬁcation machine learning methods for imbalanced data."
        },
        {
          "14\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "For example,\nin paper [20], several fuzzy rough set theory methods are described"
        },
        {
          "14\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "speciﬁcally targeting imbalanced data sets."
        },
        {
          "14\nOlha Kaminska , Chris Cornelis, and Veronique Hoste": "References"
        }
      ],
      "page": 14
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "References": "1. Barbieri,"
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "2. Cer, D., Yang, Y., Kong,"
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "8."
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "9."
        },
        {
          "References": ""
        }
      ],
      "page": 14
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "10.\nJensen, R., Cornelis, C.: Fuzzy-rough nearest neighbour classiﬁcation and predic-"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "tion. Theoretical Computer Science 412(42), 5871–5884 (2011)"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "11. Kaminska, O., Cornelis, C., Hoste, V.: Nearest neighbour approaches\nfor\nemo-"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "tion detection in tweets.\nIn: Proceedings of\nthe Eleventh Workshop on Compu-"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "tational Approaches\nto Subjectivity, Sentiment and Social Media Analysis. pp."
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "203–212. Association for Computational Linguistics, Online (Apr 2021), https:"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "//www.aclweb.org/anthology/2021.wassa-1.22"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "12. Lenz, O.U., Peralta, D., Cornelis, C.: Scalable approximate frnn-owa classiﬁcation."
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "IEEE Transactions on Fuzzy Systems 28(5), 929–938 (2019)"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "13. MacAvaney, S., Yao, H.R., Yang, E., Russell, K., Goharian, N., Frieder, O.: Hate"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "speech detection: Challenges and solutions. PloS one 14(8), e0221152 (2019)"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "14. Minaee, S., Kalchbrenner, N., Cambria, E., Nikzad, N., Chenaghlu, M., Gao, J.:"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "Deep learning based text classiﬁcation: A comprehensive review. arXiv e-prints pp."
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "arXiv–2004 (2020)"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "15. Mohammad, S.M., Bravo-Marquez, F., Salameh, M., Kiritchenko, S.: Semeval-2018"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "Task 1: Aﬀect in tweets.\nIn: Proceedings of\nInternational Workshop on Semantic"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "Evaluation (SemEval-2018). New Orleans, LA, USA (2018)"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "16. Mohammad, S.M., Kiritchenko, S.: Using hashtags to capture ﬁne emotion cate-"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "gories from tweets. Computational Intelligence 31(2), 301–326 (2015)"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "17. Reimers,\nN.,\nGurevych,\nI.:\nSentence-BERT:\nSentence\nembeddings\nusing"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "Siamese\nBERT-networks.\nIn:\nProceedings\nof\nthe\n2019\nConference\non\nEm-"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "pirical Methods\nin Natural\nLanguage Processing\nand\nthe\n9th\nInternational"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "Joint\nConference\non\nNatural\nLanguage\nProcessing\n(EMNLP-IJCNLP).\npp."
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "3982–3992.\nAssociation\nfor\nComputational\nLinguistics,\nHong\nKong,\nChina"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "(Nov\n2019).\nhttps://doi.org/10.18653/v1/D19-1410,\nhttps://www.aclweb.org/"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "anthology/D19-1410"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "18. Rozental, A., Fleischer, D.: Amobee at SemEval-2018 task 1: GRU neural net-"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "work with\na CNN attention mechanism for\nsentiment\nclassiﬁcation.\nIn: Pro-"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "ceedings\nof The\n12th\nInternational Workshop\non\nSemantic\nEvaluation.\npp."
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "218–225. Association\nfor Computational\nLinguistics, New Orleans,\nLouisiana"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "(Jun\n2018).\nhttps://doi.org/10.18653/v1/S18-1033,\nhttps://www.aclweb.org/"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "anthology/S18-1033"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "19. Sailunaz, K., Dhaliwal, M., Rokne, J., Alhajj, R.: Emotion detection from text and"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "speech: a survey. Social Network Analysis and Mining 8(1), 1–26 (2018)"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "20. Vluymans, S.: Dealing with imbalanced and weakly labelled data in machine learn-"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "ing using fuzzy and rough set methods. Springer (2019)"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "21. Wang, C., Feng, S., Wang, D., Zhang, Y.: Fuzzy-rough set based multi-labeled"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "emotion intensity analysis for sentence, paragraph and document. In: Li, J., Ji, H.,"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "Zhao, D., Feng, Y. (eds.) Natural Language Processing and Chinese Computing."
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "pp. 444–452. Springer International Publishing, Cham (2015)"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "22. Wang, C., Wang, D., Feng, S., Zhang, Y.: An approach of\nfuzzy relation equation"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "and fuzzy-rough set\nfor multi-label\nemotion intensity analysis.\nIn:\nInternational"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "Conference on Database Systems for Advanced Applications. pp. 65–80. Springer"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "(2016)"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "23. Wolny, W.: Emotion\nanalysis\nof\ntwitter\ndata\nthat\nuse\nemoticons\nand\nemoji"
        },
        {
          "FRNN Approaches for Emotion Detection in Tweets\n15": "ideograms (2016)"
        }
      ],
      "page": 15
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "TweetEval: Unified benchmark and comparative evaluation for tweet classification",
      "authors": [
        "F Barbieri",
        "J Camacho-Collados",
        "L Espinosa Anke",
        "L Neves"
      ],
      "year": "2020",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020",
      "doi": "10.18653/v1/2020.findings-emnlp.148"
    },
    {
      "citation_id": "2",
      "title": "Universal sentence encoder for English",
      "authors": [
        "D Cer",
        "Y Yang",
        "S Kong",
        "N Hua",
        "N Limtiaco",
        "St",
        "R John",
        "N Constant",
        "M Guajardo-Cespedes",
        "S Yuan",
        "C Tar",
        "B Strope",
        "R Kurzweil"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
      "doi": "10.18653/v1/D18-2029"
    },
    {
      "citation_id": "3",
      "title": "Ordered weighted average based fuzzy rough sets",
      "authors": [
        "C Cornelis",
        "N Verbiest",
        "R Jensen"
      ],
      "year": "2010",
      "venue": "International Conference on Rough Sets and Knowledge Technology"
    },
    {
      "citation_id": "4",
      "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "J Devlin",
        "M Chang",
        "K Lee",
        "K Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter"
    },
    {
      "citation_id": "5",
      "title": "SeerNet at SemEval-2018 task 1: Domain adaptation for affect in tweets",
      "authors": [
        "V Duppada",
        "R Jain",
        "S Hiray"
      ],
      "year": "2018",
      "venue": "Proceedings of The 12th International Workshop on Semantic Evaluation",
      "doi": "10.18653/v1/S18-1002"
    },
    {
      "citation_id": "6",
      "title": "psyml at semeval-2018 task 1: Transfer learning for sentiment and emotion analysis",
      "authors": [
        "G Gee",
        "E Wang"
      ],
      "year": "2018",
      "venue": "Proceedings of The 12th International Workshop on Semantic Evaluation"
    },
    {
      "citation_id": "7",
      "title": "Similarity measures for text document clustering",
      "authors": [
        "A Huang"
      ],
      "year": "2008",
      "venue": "Proceedings of the sixth new zealand computer science research student conference (NZCSRSC2008)"
    },
    {
      "citation_id": "8",
      "title": "A new approach to fuzzy-rough nearest neighbour classification",
      "authors": [
        "R Jensen",
        "C Cornelis"
      ],
      "year": "2008",
      "venue": "International conference on rough sets and current trends in computing"
    },
    {
      "citation_id": "9",
      "title": "Fuzzy-rough nearest neighbour classification",
      "authors": [
        "R Jensen",
        "C Cornelis"
      ],
      "year": "2011",
      "venue": "Transactions on rough sets XIII"
    },
    {
      "citation_id": "10",
      "title": "Fuzzy-rough nearest neighbour classification and prediction",
      "authors": [
        "R Jensen",
        "C Cornelis"
      ],
      "year": "2011",
      "venue": "Theoretical Computer Science"
    },
    {
      "citation_id": "11",
      "title": "Nearest neighbour approaches for emotion detection in tweets",
      "authors": [
        "O Kaminska",
        "C Cornelis",
        "V Hoste"
      ],
      "year": "2021",
      "venue": "Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis"
    },
    {
      "citation_id": "12",
      "title": "Scalable approximate frnn-owa classification",
      "authors": [
        "O Lenz",
        "D Peralta",
        "C Cornelis"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Fuzzy Systems"
    },
    {
      "citation_id": "13",
      "title": "Hate speech detection: Challenges and solutions",
      "authors": [
        "S Macavaney",
        "H Yao",
        "E Yang",
        "K Russell",
        "N Goharian",
        "O Frieder"
      ],
      "year": "2019",
      "venue": "PloS one"
    },
    {
      "citation_id": "14",
      "title": "Deep learning based text classification: A comprehensive review",
      "authors": [
        "S Minaee",
        "N Kalchbrenner",
        "E Cambria",
        "N Nikzad",
        "M Chenaghlu",
        "J Gao"
      ],
      "year": "2020",
      "venue": "Deep learning based text classification: A comprehensive review"
    },
    {
      "citation_id": "15",
      "title": "Semeval-2018 Task 1: Affect in tweets",
      "authors": [
        "S Mohammad",
        "F Bravo-Marquez",
        "M Salameh",
        "S Kiritchenko"
      ],
      "year": "2018",
      "venue": "Proceedings of International Workshop on Semantic Evaluation (SemEval-2018)"
    },
    {
      "citation_id": "16",
      "title": "Using hashtags to capture fine emotion categories from tweets",
      "authors": [
        "S Mohammad",
        "S Kiritchenko"
      ],
      "year": "2015",
      "venue": "Computational Intelligence"
    },
    {
      "citation_id": "17",
      "title": "Sentence-BERT: Sentence embeddings using Siamese BERT-networks",
      "authors": [
        "N Reimers",
        "I Gurevych"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
      "doi": "10.18653/v1/D19-1410"
    },
    {
      "citation_id": "18",
      "title": "Amobee at SemEval-2018 task 1: GRU neural network with a CNN attention mechanism for sentiment classification",
      "authors": [
        "A Rozental",
        "D Fleischer"
      ],
      "year": "2018",
      "venue": "Proceedings of The 12th International Workshop on Semantic Evaluation",
      "doi": "10.18653/v1/S18-1033"
    },
    {
      "citation_id": "19",
      "title": "Emotion detection from text and speech: a survey",
      "authors": [
        "K Sailunaz",
        "M Dhaliwal",
        "J Rokne",
        "R Alhajj"
      ],
      "year": "2018",
      "venue": "Social Network Analysis and Mining"
    },
    {
      "citation_id": "20",
      "title": "Dealing with imbalanced and weakly labelled data in machine learning using fuzzy and rough set methods",
      "authors": [
        "S Vluymans"
      ],
      "year": "2019",
      "venue": "Dealing with imbalanced and weakly labelled data in machine learning using fuzzy and rough set methods"
    },
    {
      "citation_id": "21",
      "title": "Fuzzy-rough set based multi-labeled emotion intensity analysis for sentence, paragraph and document",
      "authors": [
        "C Wang",
        "S Feng",
        "D Wang",
        "Y Zhang"
      ],
      "year": "2015",
      "venue": "Natural Language Processing and Chinese Computing"
    },
    {
      "citation_id": "22",
      "title": "An approach of fuzzy relation equation and fuzzy-rough set for multi-label emotion intensity analysis",
      "authors": [
        "C Wang",
        "D Wang",
        "S Feng",
        "Y Zhang"
      ],
      "year": "2016",
      "venue": "International Conference on Database Systems for Advanced Applications"
    },
    {
      "citation_id": "23",
      "title": "Emotion analysis of twitter data that use emoticons and emoji ideograms",
      "authors": [
        "W Wolny"
      ],
      "year": "2016",
      "venue": "Emotion analysis of twitter data that use emoticons and emoji ideograms"
    }
  ]
}