{
  "paper_id": "2501.11166v1",
  "title": "Aima At Semeval-2024 Task 10: History-Based Emotion Recognition In Hindi-English Code-Mixed Conversations",
  "published": "2025-01-19T20:56:45Z",
  "authors": [
    "Mohammad Mahdi Abootorabi",
    "Nona Ghazizadeh",
    "Seyed Arshan Dalili",
    "Alireza Ghahramani Kure",
    "Mahshid Dehghani",
    "Ehsaneddin Asgari"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "In this study, we introduce a solution to the Se-mEval 2024 Task 10 on subtask 1, dedicated to Emotion Recognition in Conversation (ERC) in code-mixed Hindi-English conversations. ERC in code-mixed conversations presents unique challenges, as existing models are typically trained on monolingual datasets and may not perform well on code-mixed data. To address this, we propose a series of models that incorporate both the previous and future context of the current utterance, as well as the sequential information of the conversation. To facilitate the processing of code-mixed data, we developed a Hinglish-to-English translation pipeline to translate the code-mixed conversations into English. We designed four different base models, each utilizing powerful pre-trained encoders to extract features from the input but with varying architectures. By ensembling all of these models, we developed a final model that outperforms all other baselines.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "The first subtask of SemEval 2024 Task 10 focuses on Emotion Recognition in Conversation (ERC)  (Kumar et al., 2023) . This subtask requires the design of a model capable of predicting an emotion for each utterance. Our final system is an ensemble of four high-performing models we developed in this paper. Our primary strategy involves leveraging powerful pre-trained models and utilizing the context of preceding and succeeding utterances in the conversation. We also consider the sequential information of the conversation to accurately predict emotions. The final system is designed to work with Hindi-English code-mixed conversations. A detailed description of the task is available in  (Kumar et al., 2024) .\n\nERC is an emerging research frontier in Natural Language Processing (NLP), that aims to identify emotions in conversational data. The ability to accurately recognize emotions in conversation is crucial for a variety of applications, including opinion mining from social media platforms  (Poria et al., 2019) . ERC is also extremely important for generating emotion-aware dialogues that require an understanding of the user's emotions. It is useful in various sectors, such as healthcare for psychological analysis and education to aid in understanding student frustration  (Antony et al., 2021) .\n\nERC presents several research challenges due to the complexity and rapid changeability of emotions in conversation. The same words can convey different emotions depending on the context, adding a layer of complexity to the task  (Kumar et al., 2023) . This complexity is further amplified in code-mixed conversations, a common phenomenon in multilingual societies and online social media platforms where two or more languages are used interchangeably. The challenges in ERC for code-mixed conversations include (i) Linguistic Complexity, due to complex linguistic structures and sentence or word-level language switches; (ii) Insufficient Training Data, as the scarcity of annotated datasets hampers the training of deep learning models; (iii) Cultural Nuances, since emotions can be expressed differently across cultures and languages; and (iv) Ambiguity and Context-Dependence, as word meaning and emotions vary based on context and language.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Background",
      "text": "The official dataset for this task is the MaSaC dataset  (Bedi et al., 2023) , a mixed Hindi-English language dataset relevant to our study of emotion recognition in code-mixed dialogues  (Kumar et al., 2023) . This dataset consists of approximately 8506 train, 1354 validation, and 1580 test sentences. ERC has garnered significant attention in the NLP community due to its potential applications.\n\nRecent research in ERC has attempted to ad-dress these challenges, but there are still many areas for improvement. For instance, most current approaches to ERC focus on text-based data, overlooking the rich emotional information that can be gleaned from other modalities such as voice tone and facial expressions  (Kumar et al., 2023) . With recent advances in Large Language Models (LLMs), many works leverage the power of these large models for ERC task  (Tu et al., 2023) .  (Lei et al., 2023 ) introduced a novel approach, which leverages LLMs to reformulate the ERC task from a discriminative framework to a generative one. This approach has shown significant improvements over previous models on several ERC datasets. While considerable research has focused on discerning the emotions of individual speakers in monolingual dialogues, understanding the emotional dynamics in code-mixed conversations has received relatively less attention. This is the gap our study aims to address.  (Kumar et al., 2023)  proposed an innovative approach that integrates commonsense information with dialogue context to interpret emotions more accurately in code-mixed dialogues. They developed a pipeline based on a knowledge graph to extract relevant commonsense facts and fuse them with the dialogue representation.  (Wadhawan and Aggarwal, 2021) , the closest work to ours, introduced a new Hinglish dataset for emotion detection in Hindi-English code-mixed tweets. They trained various deep learning approaches, including transformer-based models, for emotion recognition task performance on this dataset.\n\nThis paper aims to delve deeper into the current state of ERC and propose models to take a step toward solving these challenges. Our method differs from existing approaches in that it incorporates both context and sequential information to improve emotion prediction performance.\n\n3 System Overview",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Preprocessing Data",
      "text": "In the preprocessing stage, we implement a twostep translation process due to the unique nature of our data, which comprises Hindi-English mixed conversations. At present, there are no robust models trained specifically in this mixed language, nor are there translators capable of directly translating Hindi-English mixed text to English with acceptable performance. As a result, we first need to translate our data to English. In the first step, we transform our Hindi-English mixed conversations into Hindi using the indic-trans transliteration module  (Bhat et al., 2015) , a tool proficient in crosstransliteration among all Indian languages. Following this, we employ SeamlessM4T Medium  (Communication et al., 2023)  to translate these Hindi conversations into English. The English conversations obtained from this process serve as our preprocessed data.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Model Architecture",
      "text": "In this section, we propose the model architectures that were used to construct our final ensemble model. We designed three distinct architectures, and the final model is an ensemble of four models trained based on these architectures. The second model follows the same architecture as the first, but it is trained on an augmented dataset. Our system predicts the emotion of the current sentence using majority voting based on the predicted emotions from four base models.\n\nGiven the specific domain of the task and the limited number of samples in the dataset, it is crucial to strike a balance between model complexity and performance. Overly complex models may lead to overfitting, especially given the unique distribution of our dataset. Conversely, overly simple models may not capture the complexity of this particular task. Therefore, we aimed to find a balance, ensuring adequate model complexity to learn effectively from the data without leading to overfitting. Furthermore, due to the limited dataset for this task and the special domain and emotions that are used, such as contempt, we leveraged the encoder component of a pre-trained RoBERTa-based model  (Liu et al., 2019)  for the emotion recognition task in sentences, and fine-tuned it for our specific task and domain. This model was trained on the GoEmotions dataset  (Demszky et al., 2020) , allowing us to employ the capabilities of pre-trained models for our task. This encoder was incorporated into all of our base models for sentence encoding. In the following parts, each of our base models is explained in detail. An overview of architectures is shown in Figure  1 .",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Simple History-Based Model",
      "text": "This model leverages both the current sentence, for which we aim to predict the emotion, and the preceding sentence along with its associated emotion as historical information to enhance the model's prediction. Both the current and previous sentences are processed through our pre-trained encoder to obtain their respective embeddings. We then employed a multi-head attention mechanism  (Vaswani et al., 2017)  with 8 heads. In this mechanism, the keys are derived from the embeddings of the previous sentence, while the queries and values are derived from the current sentence. The use of 8 heads in the attention mechanism enables the model to capture information from different representational spaces at various levels of abstraction. This design allows the model to focus on the most relevant parts of the current sentence based on the context provided by the previous sentence.\n\nFor emotion representation, we utilized a 50dimensional embedding space learned by our model. The embedding of the previous emotion and the output of the attention mechanism are concatenated and passed through a feed-forward classifier to predict the emotion. This classifier consists of two linear layers, a LeakyReLU activation function, and a Softmax layer for output normalization.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Simple History-Based Model + Data Augmentation",
      "text": "This model architecture is identical to the base model described earlier.\n\nThe key difference lies in the training data. We used a Pegasus paraphrase model  (Zhang et al., 2019)  to augment our dataset and increase its size. We expanded our dataset by randomly selecting three sentences from the first ten paraphrases of each original sentence. Given the limited size of the original dataset, this augmentation method should enhance the model's learning capability by exposing it to a wider range of data.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Full History-Based Model",
      "text": "This model, which is an extension of the Simple History-Based model, aims to leverage more historical information for improved performance. In addition to the current sentence, previous sentence, and previous emotion, we also incorporated the concatenated string of all previous sentences in the conversation into our model. The rationale behind this is to enable the model to access additional information and gain a better understanding of the context of the current sentence within the conversation. The concatenated string of all previous sentences is processed through our pre-trained encoder to obtain the history embedding. This encoding is then passed through a simple feed-forward neural network, which consists of two linear layers, a batch normalization layer, a dropout layer, and a LeakyReLU activation function. This network transforms the 768-dimensional input into a 128dimensional space.\n\nThe processing for the current sentence, previous sentence, and previous emotion remains the same as in the Simple History-Based Model. For the classifier network, we concatenated the output of the feed-forward network for previous sentences with the output of the attention mechanism and the emotion embedding. This concatenated vector is then passed to the classifier to predict the current emotion. The classifier comprises three linear layers, a batch normalization layer, two dropout layers, a LeakyReLU activation function, a ReLU activation function, and a Softmax layer for output normalization.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Context-Aware Gru-Based Model",
      "text": "This model, more complex than its predecessors, introduces several key modifications. Firstly, it incorporates information from both the preceding and succeeding sentences in a conversation, allowing the model to leverage both past and future contexts. Secondly, in contrast to previous architectures that use the emotion of the previous sentence, this model omits this feature to prevent error propagation during the inference phase. If a model incorrectly predicts the emotion of one sentence, it could potentially use this incorrect information when predicting the emotion of the next sentence, leading to further errors. Lastly, this model employs a Gated Recurrent Unit (GRU)  (Chung et al., 2014; Cho et al., 2014) , enabling it to leverage the sequential information in the conversation.\n\nThe model processes all sentences up to and including the current one (for which we want to predict the emotion) and the next sentence through our pre-trained encoder to obtain their embeddings. If the current sentence in the conversation has more than three previous sentences, only the last three are considered, making the model focus on the most recent context. These embeddings are then passed through a stacked GRU, consisting of two GRUs with a hidden dimension of 256 and a dropout rate of 0.25. Both the current and next sentences went through a transformation via a linear layer and a dropout layer to generate output encodings in a common 256-dimensional space. The last two hidden layers of the GRU are concatenated and passed through a multi-head self-attention mechanism, similar to our previous models.\n\nThe output of the last layer of the GRU, the output of the attention mechanism, and the trans-",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Experimental Setup",
      "text": "We utilized the official dataset provided for the task as the only data source for our system. The default split provided for the task was also used.\n\nDuring the development phase, the validation set was exclusively used for evaluating various steps and experimental configurations. For the final submission, models were fine-tuned on both the training and validation splits. For evaluation purposes, our primary metric was Weighted F1. However, to provide a more comprehensive analysis, we also reported three additional metrics, as detailed in Table 1. Our training process primarily employed the PyTorch and Transformers libraries. All base models were trained using the early stopping method and the AdamW  (Loshchilov and Hutter, 2019)  optimizer. A learning rate scheduler was used, with a lower learning rate set for the pre-trained encoder (5e-6) compared to other parameters (1e-4). The batch size was set to 1 for the Context-Aware GRU-Based model and 4 for other models during training. The cross-entropy loss function was used for the training.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Results",
      "text": "Table  1  presents SubTask 1 results. We compare our approach with four baseline models. The first baseline is GPT 3.5 Turbo, for which we used its API key to input the entire conversation and predict the emotion for each sentence. The results of this baseline model illustrate that this task is much more challenging than general sentence emotion recognition because it is domain-specific. The next two models are traditional ones, namely Linear Regression and Decision Tree, that utilize embeddings extracted from the LaBSE sentence encoder  (Feng et al., 2022) . The LaBSE model serves as a powerful encoder for our text data, enabling us to achieve comprehensive and multilingual text embeddings. The final baseline model is similar to a Simple History-Based model. It employs our pretrained encoder but does not use any context, such as the previous sentence, and relies solely on the current sentence.\n\nMoving on to the comparison of our models, we first consider the Simple History-Based model. By comparing its results with the Full History-Based model, we find that most of the information for predicting the emotion is contained in the current and the previous sentence. Therefore, information from all of the previous sentences is not as useful for predicting emotion. Our second model, which uses data augmentation, does not perform well. This is likely due to overfitting and the domain-specific nature of the conversations, making data augmentation less effective. As can be seen in our models, the Context-Aware GRU-Based model outperforms the others. This is because it incorporates information from both the preceding and succeeding sentences and the GRU can leverage the sequential information in the conversation. The closeness of the results between the Context-Aware GRU-Based model and the Simple History-Based model reinforces our assumption that most information for predicting emotion is in the current and previous sentence. All of our models outperform the baselines. For our final model, we create an ensemble of these four models using majority voting. This ensemble model outperforms each individual model, achieving an F1-score of 0.4080.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Conclusion",
      "text": "In this paper, we proposed a novel method to address the Code-Mixed Emotion Recognition in Conversations (ERC) challenge. Our approach leverages the power of pre-trained large models and incorporates both previous and future context information of the current utterance, as well as sequential information of the conversation up to that point, to recognize each utterance's emotion. In addition to our primary model, we utilized other base models with different architectures based on various Deep Learning components to tackle this problem. By ensembling all of these models, we developed a final system that outperforms previous models.\n\nDespite these advancements, Code-Mixed ERC remains a challenging task with significant potential for further investigation. Future research directions could include designing robust encoders capable of processing code-mixed dialogues and predicting emotions in an end-to-end manner. Moreover, collecting more data on these code-mixed dialogues is necessary to improve the performance of models. Furthermore, we can explore more complex models that incorporate different information from various modalities to achieve better performance. This work serves as a stepping stone towards more sophisticated emotion recognition systems for code-mixed dialogues.",
      "page_start": 7,
      "page_end": 7
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Three proposed base model architectures for predicting the emotion of the current sentence. (a): This model",
      "page": 4
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "{mahdi.abootorabi,\nnona.ghazizadeh,"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "a.ghahramani, mahshid.dehghani}@sharif.edu"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "easgari@hbku.edu.qa"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "Abstract"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "In this study, we introduce a solution to the Se-"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "mEval 2024 Task 10 on subtask 1, dedicated to"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "Emotion Recognition in Conversation (ERC) in"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "code-mixed Hindi-English conversations. ERC"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "in code-mixed conversations presents unique"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "challenges,\nas existing models are typically"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "trained on monolingual datasets and may not"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "perform well on code-mixed data. To address"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "this, we propose a series of models that incorpo-"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "rate both the previous and future context of the"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "current utterance, as well as the sequential in-"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "formation of the conversation. To facilitate the"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "processing of code-mixed data, we developed"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "a Hinglish-to-English translation pipeline to"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "translate the code-mixed conversations into En-"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "glish. We designed four different base models,"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "each utilizing powerful pre-trained encoders to"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "extract features from the input but with vary-"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "ing architectures. By ensembling all of these"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "models, we developed a final model\nthat out-"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "performs all other baselines."
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "1\nIntroduction"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "The first subtask of SemEval 2024 Task 10 focuses"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "on Emotion Recognition in Conversation (ERC)"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "(Kumar et al., 2023). This subtask requires the de-"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "sign of a model capable of predicting an emotion"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "for each utterance. Our final system is an ensemble"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "of four high-performing models we developed in"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "this paper. Our primary strategy involves leverag-"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "ing powerful pre-trained models and utilizing the"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": ""
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "context of preceding and succeeding utterances in"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "the conversation. We also consider the sequential"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "information of the conversation to accurately pre-"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "dict emotions. The final system is designed to work"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "with Hindi-English code-mixed conversations. A"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "detailed description of the task is available in (Ku-"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "mar et al., 2024)."
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "ERC is an emerging research frontier in Natu-"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "ral Language Processing (NLP), that aims to iden-"
        },
        {
          "§ Qatar Computing Research Institute, Doha, Qatar": "tify emotions in conversational data. The ability"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "dress these challenges, but there are still many ar-": "eas for improvement. For instance, most current",
          "into Hindi using the indic-trans transliteration mod-": "ule (Bhat et al., 2015), a tool proficient\nin cross-"
        },
        {
          "dress these challenges, but there are still many ar-": "approaches to ERC focus on text-based data, over-",
          "into Hindi using the indic-trans transliteration mod-": "transliteration among all Indian languages. Follow-"
        },
        {
          "dress these challenges, but there are still many ar-": "looking the rich emotional information that can be",
          "into Hindi using the indic-trans transliteration mod-": "ing this, we employ SeamlessM4T Medium (Com-"
        },
        {
          "dress these challenges, but there are still many ar-": "gleaned from other modalities such as voice tone",
          "into Hindi using the indic-trans transliteration mod-": "munication et al., 2023)\nto translate these Hindi"
        },
        {
          "dress these challenges, but there are still many ar-": "and facial expressions (Kumar et al., 2023).",
          "into Hindi using the indic-trans transliteration mod-": "conversations into English. The English conversa-"
        },
        {
          "dress these challenges, but there are still many ar-": "With recent advances in Large Language Models",
          "into Hindi using the indic-trans transliteration mod-": "tions obtained from this process serve as our pre-"
        },
        {
          "dress these challenges, but there are still many ar-": "(LLMs), many works leverage the power of these",
          "into Hindi using the indic-trans transliteration mod-": "processed data."
        },
        {
          "dress these challenges, but there are still many ar-": "large models for ERC task (Tu et al., 2023).\n(Lei",
          "into Hindi using the indic-trans transliteration mod-": ""
        },
        {
          "dress these challenges, but there are still many ar-": "",
          "into Hindi using the indic-trans transliteration mod-": "3.2\nModel Architecture"
        },
        {
          "dress these challenges, but there are still many ar-": "et al., 2023) introduced a novel approach, which",
          "into Hindi using the indic-trans transliteration mod-": ""
        },
        {
          "dress these challenges, but there are still many ar-": "leverages LLMs to reformulate the ERC task from a",
          "into Hindi using the indic-trans transliteration mod-": "In this\nsection, we propose the model architec-"
        },
        {
          "dress these challenges, but there are still many ar-": "discriminative framework to a generative one. This",
          "into Hindi using the indic-trans transliteration mod-": "tures that were used to construct our final ensemble"
        },
        {
          "dress these challenges, but there are still many ar-": "approach has shown significant improvements over",
          "into Hindi using the indic-trans transliteration mod-": "model. We designed three distinct architectures,"
        },
        {
          "dress these challenges, but there are still many ar-": "previous models on several ERC datasets. While",
          "into Hindi using the indic-trans transliteration mod-": "and the final model is an ensemble of four models"
        },
        {
          "dress these challenges, but there are still many ar-": "considerable research has focused on discerning",
          "into Hindi using the indic-trans transliteration mod-": "trained based on these architectures. The second"
        },
        {
          "dress these challenges, but there are still many ar-": "the emotions of individual speakers in monolingual",
          "into Hindi using the indic-trans transliteration mod-": "model follows the same architecture as the first, but"
        },
        {
          "dress these challenges, but there are still many ar-": "dialogues, understanding the emotional dynamics",
          "into Hindi using the indic-trans transliteration mod-": "it is trained on an augmented dataset. Our system"
        },
        {
          "dress these challenges, but there are still many ar-": "in code-mixed conversations has received relatively",
          "into Hindi using the indic-trans transliteration mod-": "predicts the emotion of the current sentence using"
        },
        {
          "dress these challenges, but there are still many ar-": "less attention. This is the gap our study aims to ad-",
          "into Hindi using the indic-trans transliteration mod-": "majority voting based on the predicted emotions"
        },
        {
          "dress these challenges, but there are still many ar-": "dress. (Kumar et al., 2023) proposed an innovative",
          "into Hindi using the indic-trans transliteration mod-": "from four base models."
        },
        {
          "dress these challenges, but there are still many ar-": "approach that integrates commonsense information",
          "into Hindi using the indic-trans transliteration mod-": "Given the specific domain of the task and the lim-"
        },
        {
          "dress these challenges, but there are still many ar-": "with dialogue context to interpret emotions more",
          "into Hindi using the indic-trans transliteration mod-": "ited number of samples in the dataset, it is crucial"
        },
        {
          "dress these challenges, but there are still many ar-": "accurately in code-mixed dialogues. They devel-",
          "into Hindi using the indic-trans transliteration mod-": "to strike a balance between model complexity and"
        },
        {
          "dress these challenges, but there are still many ar-": "oped a pipeline based on a knowledge graph to",
          "into Hindi using the indic-trans transliteration mod-": "performance. Overly complex models may lead to"
        },
        {
          "dress these challenges, but there are still many ar-": "extract relevant commonsense facts and fuse them",
          "into Hindi using the indic-trans transliteration mod-": "overfitting, especially given the unique distribution"
        },
        {
          "dress these challenges, but there are still many ar-": "with the dialogue representation. (Wadhawan and",
          "into Hindi using the indic-trans transliteration mod-": "of our dataset. Conversely, overly simple models"
        },
        {
          "dress these challenges, but there are still many ar-": "Aggarwal, 2021),\nthe closest work to ours,\nintro-",
          "into Hindi using the indic-trans transliteration mod-": "may not capture the complexity of this particular"
        },
        {
          "dress these challenges, but there are still many ar-": "duced a new Hinglish dataset for emotion detec-",
          "into Hindi using the indic-trans transliteration mod-": "task. Therefore, we aimed to find a balance, ensur-"
        },
        {
          "dress these challenges, but there are still many ar-": "tion in Hindi-English code-mixed tweets.\nThey",
          "into Hindi using the indic-trans transliteration mod-": "ing adequate model complexity to learn effectively"
        },
        {
          "dress these challenges, but there are still many ar-": "trained various deep learning approaches, including",
          "into Hindi using the indic-trans transliteration mod-": "from the data without\nleading to overfitting. Fur-"
        },
        {
          "dress these challenges, but there are still many ar-": "transformer-based models, for emotion recognition",
          "into Hindi using the indic-trans transliteration mod-": "thermore, due to the limited dataset for this task"
        },
        {
          "dress these challenges, but there are still many ar-": "task performance on this dataset.",
          "into Hindi using the indic-trans transliteration mod-": "and the special domain and emotions that are used,"
        },
        {
          "dress these challenges, but there are still many ar-": "This paper aims to delve deeper into the current",
          "into Hindi using the indic-trans transliteration mod-": "such as contempt, we leveraged the encoder compo-"
        },
        {
          "dress these challenges, but there are still many ar-": "state of ERC and propose models to take a step",
          "into Hindi using the indic-trans transliteration mod-": "nent of a pre-trained RoBERTa-based model (Liu"
        },
        {
          "dress these challenges, but there are still many ar-": "toward solving these challenges. Our method dif-",
          "into Hindi using the indic-trans transliteration mod-": "et al., 2019)\nfor\nthe emotion recognition task in"
        },
        {
          "dress these challenges, but there are still many ar-": "fers from existing approaches in that it incorporates",
          "into Hindi using the indic-trans transliteration mod-": "sentences, and fine-tuned it for our specific task"
        },
        {
          "dress these challenges, but there are still many ar-": "both context and sequential information to improve",
          "into Hindi using the indic-trans transliteration mod-": "and domain. This model was trained on the GoE-"
        },
        {
          "dress these challenges, but there are still many ar-": "emotion prediction performance.",
          "into Hindi using the indic-trans transliteration mod-": "motions dataset (Demszky et al., 2020), allowing"
        },
        {
          "dress these challenges, but there are still many ar-": "",
          "into Hindi using the indic-trans transliteration mod-": "us to employ the capabilities of pre-trained models"
        },
        {
          "dress these challenges, but there are still many ar-": "3\nSystem Overview",
          "into Hindi using the indic-trans transliteration mod-": "for our task. This encoder was incorporated into"
        },
        {
          "dress these challenges, but there are still many ar-": "",
          "into Hindi using the indic-trans transliteration mod-": "all of our base models for sentence encoding.\nIn"
        },
        {
          "dress these challenges, but there are still many ar-": "3.1\nPreprocessing Data",
          "into Hindi using the indic-trans transliteration mod-": ""
        },
        {
          "dress these challenges, but there are still many ar-": "",
          "into Hindi using the indic-trans transliteration mod-": "the following parts, each of our base models is ex-"
        },
        {
          "dress these challenges, but there are still many ar-": "In the preprocessing stage, we implement a two-",
          "into Hindi using the indic-trans transliteration mod-": "plained in detail. An overview of architectures is"
        },
        {
          "dress these challenges, but there are still many ar-": "step translation process due to the unique nature",
          "into Hindi using the indic-trans transliteration mod-": "shown in Figure 1."
        },
        {
          "dress these challenges, but there are still many ar-": "of our data, which comprises Hindi-English mixed",
          "into Hindi using the indic-trans transliteration mod-": ""
        },
        {
          "dress these challenges, but there are still many ar-": "",
          "into Hindi using the indic-trans transliteration mod-": "3.2.1\nSimple History-Based Model"
        },
        {
          "dress these challenges, but there are still many ar-": "conversations. At present, there are no robust mod-",
          "into Hindi using the indic-trans transliteration mod-": ""
        },
        {
          "dress these challenges, but there are still many ar-": "els trained specifically in this mixed language, nor",
          "into Hindi using the indic-trans transliteration mod-": "This model leverages both the current sentence, for"
        },
        {
          "dress these challenges, but there are still many ar-": "are there translators capable of directly translating",
          "into Hindi using the indic-trans transliteration mod-": "which we aim to predict the emotion, and the pre-"
        },
        {
          "dress these challenges, but there are still many ar-": "Hindi-English mixed text to English with accept-",
          "into Hindi using the indic-trans transliteration mod-": "ceding sentence along with its associated emotion"
        },
        {
          "dress these challenges, but there are still many ar-": "able performance. As a result, we first need to",
          "into Hindi using the indic-trans transliteration mod-": "as historical\ninformation to enhance the model’s"
        },
        {
          "dress these challenges, but there are still many ar-": "translate our data to English.\nIn the first step, we",
          "into Hindi using the indic-trans transliteration mod-": "prediction. Both the current and previous sentences"
        },
        {
          "dress these challenges, but there are still many ar-": "transform our Hindi-English mixed conversations",
          "into Hindi using the indic-trans transliteration mod-": "are processed through our pre-trained encoder to"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "obtain their respective embeddings. We then em-": "ployed a multi-head attention mechanism (Vaswani",
          "transforms the 768-dimensional\ninput\ninto a 128-": "dimensional space."
        },
        {
          "obtain their respective embeddings. We then em-": "et al., 2017) with 8 heads. In this mechanism, the",
          "transforms the 768-dimensional\ninput\ninto a 128-": "The processing for the current sentence, previ-"
        },
        {
          "obtain their respective embeddings. We then em-": "keys are derived from the embeddings of the previ-",
          "transforms the 768-dimensional\ninput\ninto a 128-": "ous sentence, and previous emotion remains the"
        },
        {
          "obtain their respective embeddings. We then em-": "ous sentence, while the queries and values are de-",
          "transforms the 768-dimensional\ninput\ninto a 128-": "same as in the Simple History-Based Model. For"
        },
        {
          "obtain their respective embeddings. We then em-": "rived from the current sentence. The use of 8 heads",
          "transforms the 768-dimensional\ninput\ninto a 128-": "the classifier network, we concatenated the output"
        },
        {
          "obtain their respective embeddings. We then em-": "in the attention mechanism enables the model\nto",
          "transforms the 768-dimensional\ninput\ninto a 128-": "of the feed-forward network for previous sentences"
        },
        {
          "obtain their respective embeddings. We then em-": "capture information from different representational",
          "transforms the 768-dimensional\ninput\ninto a 128-": "with the output of\nthe attention mechanism and"
        },
        {
          "obtain their respective embeddings. We then em-": "spaces at various levels of abstraction.\nThis de-",
          "transforms the 768-dimensional\ninput\ninto a 128-": "the emotion embedding. This concatenated vector"
        },
        {
          "obtain their respective embeddings. We then em-": "sign allows the model to focus on the most relevant",
          "transforms the 768-dimensional\ninput\ninto a 128-": "is then passed to the classifier to predict\nthe cur-"
        },
        {
          "obtain their respective embeddings. We then em-": "parts of the current sentence based on the context",
          "transforms the 768-dimensional\ninput\ninto a 128-": "rent emotion. The classifier comprises three linear"
        },
        {
          "obtain their respective embeddings. We then em-": "provided by the previous sentence.",
          "transforms the 768-dimensional\ninput\ninto a 128-": "layers, a batch normalization layer,\ntwo dropout"
        },
        {
          "obtain their respective embeddings. We then em-": "For emotion representation, we utilized a 50-",
          "transforms the 768-dimensional\ninput\ninto a 128-": "layers, a LeakyReLU activation function, a ReLU"
        },
        {
          "obtain their respective embeddings. We then em-": "dimensional\nembedding\nspace\nlearned\nby\nour",
          "transforms the 768-dimensional\ninput\ninto a 128-": "activation function, and a Softmax layer for output"
        },
        {
          "obtain their respective embeddings. We then em-": "model. The embedding of the previous emotion and",
          "transforms the 768-dimensional\ninput\ninto a 128-": "normalization."
        },
        {
          "obtain their respective embeddings. We then em-": "the output of the attention mechanism are concate-",
          "transforms the 768-dimensional\ninput\ninto a 128-": ""
        },
        {
          "obtain their respective embeddings. We then em-": "",
          "transforms the 768-dimensional\ninput\ninto a 128-": "3.2.4\nContext-Aware GRU-Based Model"
        },
        {
          "obtain their respective embeddings. We then em-": "nated and passed through a feed-forward classifier",
          "transforms the 768-dimensional\ninput\ninto a 128-": ""
        },
        {
          "obtain their respective embeddings. We then em-": "to predict the emotion. This classifier consists of",
          "transforms the 768-dimensional\ninput\ninto a 128-": "This model, more complex than its predecessors,"
        },
        {
          "obtain their respective embeddings. We then em-": "two linear layers, a LeakyReLU activation function,",
          "transforms the 768-dimensional\ninput\ninto a 128-": "introduces several key modifications. Firstly, it in-"
        },
        {
          "obtain their respective embeddings. We then em-": "and a Softmax layer for output normalization.",
          "transforms the 768-dimensional\ninput\ninto a 128-": "corporates information from both the preceding and"
        },
        {
          "obtain their respective embeddings. We then em-": "",
          "transforms the 768-dimensional\ninput\ninto a 128-": "succeeding sentences in a conversation, allowing"
        },
        {
          "obtain their respective embeddings. We then em-": "3.2.2\nSimple History-Based Model + Data",
          "transforms the 768-dimensional\ninput\ninto a 128-": ""
        },
        {
          "obtain their respective embeddings. We then em-": "",
          "transforms the 768-dimensional\ninput\ninto a 128-": "the model\nto leverage both past and future con-"
        },
        {
          "obtain their respective embeddings. We then em-": "Augmentation",
          "transforms the 768-dimensional\ninput\ninto a 128-": ""
        },
        {
          "obtain their respective embeddings. We then em-": "",
          "transforms the 768-dimensional\ninput\ninto a 128-": "texts. Secondly,\nin contrast\nto previous architec-"
        },
        {
          "obtain their respective embeddings. We then em-": "This model architecture is\nidentical\nto the base",
          "transforms the 768-dimensional\ninput\ninto a 128-": "tures that use the emotion of the previous sentence,"
        },
        {
          "obtain their respective embeddings. We then em-": "model described earlier. The key difference lies",
          "transforms the 768-dimensional\ninput\ninto a 128-": "this model omits this feature to prevent error prop-"
        },
        {
          "obtain their respective embeddings. We then em-": "in the training data. We used a Pegasus paraphrase",
          "transforms the 768-dimensional\ninput\ninto a 128-": "agation during the inference phase.\nIf a model"
        },
        {
          "obtain their respective embeddings. We then em-": "model (Zhang et al., 2019) to augment our dataset",
          "transforms the 768-dimensional\ninput\ninto a 128-": "incorrectly predicts the emotion of one sentence,"
        },
        {
          "obtain their respective embeddings. We then em-": "and increase its size. We expanded our dataset by",
          "transforms the 768-dimensional\ninput\ninto a 128-": "it could potentially use this incorrect information"
        },
        {
          "obtain their respective embeddings. We then em-": "randomly selecting three sentences from the first",
          "transforms the 768-dimensional\ninput\ninto a 128-": "when predicting the emotion of the next sentence,"
        },
        {
          "obtain their respective embeddings. We then em-": "ten paraphrases of each original sentence. Given",
          "transforms the 768-dimensional\ninput\ninto a 128-": "leading to further errors. Lastly,\nthis model em-"
        },
        {
          "obtain their respective embeddings. We then em-": "the limited size of the original dataset, this augmen-",
          "transforms the 768-dimensional\ninput\ninto a 128-": "ploys a Gated Recurrent Unit (GRU) (Chung et al.,"
        },
        {
          "obtain their respective embeddings. We then em-": "tation method should enhance the model’s learning",
          "transforms the 768-dimensional\ninput\ninto a 128-": "2014; Cho et al., 2014), enabling it to leverage the"
        },
        {
          "obtain their respective embeddings. We then em-": "capability by exposing it to a wider range of data.",
          "transforms the 768-dimensional\ninput\ninto a 128-": "sequential information in the conversation."
        },
        {
          "obtain their respective embeddings. We then em-": "",
          "transforms the 768-dimensional\ninput\ninto a 128-": "The model processes all sentences up to and"
        },
        {
          "obtain their respective embeddings. We then em-": "3.2.3\nFull History-Based Model",
          "transforms the 768-dimensional\ninput\ninto a 128-": ""
        },
        {
          "obtain their respective embeddings. We then em-": "",
          "transforms the 768-dimensional\ninput\ninto a 128-": "including the current one (for which we want\nto"
        },
        {
          "obtain their respective embeddings. We then em-": "This model, which is an extension of the Simple",
          "transforms the 768-dimensional\ninput\ninto a 128-": "predict the emotion) and the next sentence through"
        },
        {
          "obtain their respective embeddings. We then em-": "History-Based model, aims to leverage more his-",
          "transforms the 768-dimensional\ninput\ninto a 128-": "our pre-trained encoder to obtain their embeddings."
        },
        {
          "obtain their respective embeddings. We then em-": "torical information for improved performance. In",
          "transforms the 768-dimensional\ninput\ninto a 128-": "If the current sentence in the conversation has more"
        },
        {
          "obtain their respective embeddings. We then em-": "addition to the current sentence, previous sentence,",
          "transforms the 768-dimensional\ninput\ninto a 128-": "than three previous sentences, only the last three are"
        },
        {
          "obtain their respective embeddings. We then em-": "and previous emotion, we also incorporated the",
          "transforms the 768-dimensional\ninput\ninto a 128-": "considered, making the model focus on the most"
        },
        {
          "obtain their respective embeddings. We then em-": "concatenated string of all previous sentences in the",
          "transforms the 768-dimensional\ninput\ninto a 128-": "recent context. These embeddings are then passed"
        },
        {
          "obtain their respective embeddings. We then em-": "conversation into our model. The rationale behind",
          "transforms the 768-dimensional\ninput\ninto a 128-": "through a stacked GRU, consisting of two GRUs"
        },
        {
          "obtain their respective embeddings. We then em-": "this is to enable the model to access additional in-",
          "transforms the 768-dimensional\ninput\ninto a 128-": "with a hidden dimension of 256 and a dropout rate"
        },
        {
          "obtain their respective embeddings. We then em-": "formation and gain a better understanding of the",
          "transforms the 768-dimensional\ninput\ninto a 128-": "of 0.25. Both the current and next sentences went"
        },
        {
          "obtain their respective embeddings. We then em-": "context of the current sentence within the conversa-",
          "transforms the 768-dimensional\ninput\ninto a 128-": "through a transformation via a linear\nlayer and"
        },
        {
          "obtain their respective embeddings. We then em-": "tion. The concatenated string of all previous sen-",
          "transforms the 768-dimensional\ninput\ninto a 128-": "a dropout\nlayer\nto generate output encodings in"
        },
        {
          "obtain their respective embeddings. We then em-": "tences is processed through our pre-trained encoder",
          "transforms the 768-dimensional\ninput\ninto a 128-": "a common 256-dimensional space. The last\ntwo"
        },
        {
          "obtain their respective embeddings. We then em-": "to obtain the history embedding. This encoding is",
          "transforms the 768-dimensional\ninput\ninto a 128-": "hidden layers of\nthe GRU are concatenated and"
        },
        {
          "obtain their respective embeddings. We then em-": "then passed through a simple feed-forward neu-",
          "transforms the 768-dimensional\ninput\ninto a 128-": "passed through a multi-head self-attention mecha-"
        },
        {
          "obtain their respective embeddings. We then em-": "ral network, which consists of two linear layers,",
          "transforms the 768-dimensional\ninput\ninto a 128-": "nism, similar to our previous models."
        },
        {
          "obtain their respective embeddings. We then em-": "a batch normalization layer, a dropout\nlayer, and",
          "transforms the 768-dimensional\ninput\ninto a 128-": "The output of\nthe last\nlayer of\nthe GRU,\nthe"
        },
        {
          "obtain their respective embeddings. We then em-": "a LeakyReLU activation function. This network",
          "transforms the 768-dimensional\ninput\ninto a 128-": "output of the attention mechanism, and the trans-"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Figure 1: Three proposed base model architectures for predicting the emotion of the current sentence. (a): This model": "utilizes only the basic historical information from the conversation. (b): This model leverages information from all"
        },
        {
          "Figure 1: Three proposed base model architectures for predicting the emotion of the current sentence. (a): This model": "past sentences, in addition to the information used in the previous architecture. (c): This model employs GRU to"
        },
        {
          "Figure 1: Three proposed base model architectures for predicting the emotion of the current sentence. (a): This model": "leverage sequential information and incorporates future information to gain a more comprehensive understanding of"
        },
        {
          "Figure 1: Three proposed base model architectures for predicting the emotion of the current sentence. (a): This model": "the context of the current sentence."
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 1: presents SubTask 1 results. We compare sentencesandtheGRUcanleveragethesequential",
      "data": [
        {
          "Weighted": ""
        },
        {
          "Weighted": "Recall"
        },
        {
          "Weighted": "0.3070"
        },
        {
          "Weighted": "0.2937"
        },
        {
          "Weighted": "0.4405"
        },
        {
          "Weighted": "0.4506"
        },
        {
          "Weighted": "0.4380"
        },
        {
          "Weighted": "0.4253"
        },
        {
          "Weighted": "0.4285"
        },
        {
          "Weighted": "0.4373"
        },
        {
          "Weighted": "0.4430"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table 1: presents SubTask 1 results. We compare sentencesandtheGRUcanleveragethesequential",
      "data": [
        {
          "Full History-Based Model": "Context-Aware GRU-Based Model",
          "0.3992\n0.4285\n0.3963\n0.4285": "0.4058\n0.4373\n0.4024\n0.4373"
        },
        {
          "Full History-Based Model": "Final Model (Ensemble)",
          "0.3992\n0.4285\n0.3963\n0.4285": "0.4080\n0.4430\n0.4090\n0.4430"
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "Table 1: Performance of various models on the test dataset. The first group of models represents the baselines."
        },
        {
          "Full History-Based Model": "The second group consists of models based on our proposed architectures. The final model, an ensemble of four",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "proposed models, represents the performance of our final system.",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "formed outputs of the current and next sentences",
          "0.3992\n0.4285\n0.3963\n0.4285": "baseline is GPT 3.5 Turbo, for which we used its"
        },
        {
          "Full History-Based Model": "are concatenated and passed to a feed-forward clas-",
          "0.3992\n0.4285\n0.3963\n0.4285": "API key to input\nthe entire conversation and pre-"
        },
        {
          "Full History-Based Model": "sifier to predict\nthe current emotion. The classi-",
          "0.3992\n0.4285\n0.3963\n0.4285": "dict the emotion for each sentence. The results of"
        },
        {
          "Full History-Based Model": "fier comprises two linear layers, a dropout\nlayer,",
          "0.3992\n0.4285\n0.3963\n0.4285": "this baseline model illustrate that this task is much"
        },
        {
          "Full History-Based Model": "a LeakyReLU activation function, and a Softmax",
          "0.3992\n0.4285\n0.3963\n0.4285": "more challenging than general sentence emotion"
        },
        {
          "Full History-Based Model": "layer for output normalization.",
          "0.3992\n0.4285\n0.3963\n0.4285": "recognition because it is domain-specific. The next"
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "two models are traditional ones, namely Linear"
        },
        {
          "Full History-Based Model": "4\nExperimental Setup",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "Regression and Decision Tree, that utilize embed-"
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "dings extracted from the LaBSE sentence encoder"
        },
        {
          "Full History-Based Model": "We utilized the official dataset provided for\nthe",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "(Feng et al., 2022). The LaBSE model serves as a"
        },
        {
          "Full History-Based Model": "task as the only data source for our system. The",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "powerful encoder for our text data, enabling us to"
        },
        {
          "Full History-Based Model": "default split provided for the task was also used.",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "achieve comprehensive and multilingual text em-"
        },
        {
          "Full History-Based Model": "During the development phase, the validation set",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "beddings. The final baseline model is similar to a"
        },
        {
          "Full History-Based Model": "was exclusively used for evaluating various steps",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "Simple History-Based model. It employs our pre-"
        },
        {
          "Full History-Based Model": "and experimental configurations. For the final sub-",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "trained encoder but does not use any context, such"
        },
        {
          "Full History-Based Model": "mission, models were fine-tuned on both the train-",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "as the previous sentence, and relies solely on the"
        },
        {
          "Full History-Based Model": "ing and validation splits. For evaluation purposes,",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "current sentence."
        },
        {
          "Full History-Based Model": "our primary metric was Weighted F1. However, to",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "provide a more comprehensive analysis, we also",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "Moving on to the comparison of our models, we"
        },
        {
          "Full History-Based Model": "reported three additional metrics, as detailed in Ta-",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "first consider the Simple History-Based model. By"
        },
        {
          "Full History-Based Model": "ble 1. Our training process primarily employed the",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "comparing its results with the Full History-Based"
        },
        {
          "Full History-Based Model": "PyTorch and Transformers libraries. All base mod-",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "model, we find that most of the information for pre-"
        },
        {
          "Full History-Based Model": "els were trained using the early stopping method",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "dicting the emotion is contained in the current and"
        },
        {
          "Full History-Based Model": "and the AdamW (Loshchilov and Hutter, 2019) op-",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "the previous sentence. Therefore, information from"
        },
        {
          "Full History-Based Model": "timizer. A learning rate scheduler was used, with a",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "all of the previous sentences is not as useful for"
        },
        {
          "Full History-Based Model": "lower learning rate set for the pre-trained encoder",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "predicting emotion. Our second model, which uses"
        },
        {
          "Full History-Based Model": "(5e-6) compared to other parameters (1e-4). The",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "data augmentation, does not perform well. This is"
        },
        {
          "Full History-Based Model": "batch size was set to 1 for the Context-Aware GRU-",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "likely due to overfitting and the domain-specific"
        },
        {
          "Full History-Based Model": "Based model and 4 for other models during training.",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "nature of the conversations, making data augmen-"
        },
        {
          "Full History-Based Model": "The cross-entropy loss function was used for the",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "tation less effective. As can be seen in our models,"
        },
        {
          "Full History-Based Model": "training.",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "the Context-Aware GRU-Based model outperforms"
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "the others. This is because it\nincorporates infor-"
        },
        {
          "Full History-Based Model": "5\nResults",
          "0.3992\n0.4285\n0.3963\n0.4285": ""
        },
        {
          "Full History-Based Model": "",
          "0.3992\n0.4285\n0.3963\n0.4285": "mation from both the preceding and succeeding"
        },
        {
          "Full History-Based Model": "Table 1 presents SubTask 1 results. We compare",
          "0.3992\n0.4285\n0.3963\n0.4285": "sentences and the GRU can leverage the sequential"
        },
        {
          "Full History-Based Model": "our approach with four baseline models. The first",
          "0.3992\n0.4285\n0.3963\n0.4285": "information in the conversation. The closeness of"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "the results between the Context-Aware GRU-Based": "",
          "Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tam-": "mewar, Riyaz Ahmad Bhat, and Manish Shrivastava."
        },
        {
          "the results between the Context-Aware GRU-Based": "model and the Simple History-Based model rein-",
          "Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tam-": ""
        },
        {
          "the results between the Context-Aware GRU-Based": "",
          "Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tam-": "2015.\nIiit-h system submission for fire2014 shared"
        },
        {
          "the results between the Context-Aware GRU-Based": "forces our assumption that most\ninformation for",
          "Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tam-": ""
        },
        {
          "the results between the Context-Aware GRU-Based": "",
          "Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tam-": "task on transliterated search.\nIn Proceedings of the"
        },
        {
          "the results between the Context-Aware GRU-Based": "predicting emotion is in the current and previous",
          "Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tam-": ""
        },
        {
          "the results between the Context-Aware GRU-Based": "",
          "Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tam-": "Forum for Information Retrieval Evaluation, FIRE"
        },
        {
          "the results between the Context-Aware GRU-Based": "sentence. All of our models outperform the base-",
          "Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tam-": "’14, pages 48–53, New York, NY, USA. ACM."
        },
        {
          "the results between the Context-Aware GRU-Based": "lines. For our final model, we create an ensemble",
          "Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tam-": ""
        },
        {
          "the results between the Context-Aware GRU-Based": "",
          "Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tam-": "Kyunghyun Cho, Bart van Merrienboer, Caglar Gul-"
        },
        {
          "the results between the Context-Aware GRU-Based": "of these four models using majority voting. This en-",
          "Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tam-": ""
        },
        {
          "the results between the Context-Aware GRU-Based": "",
          "Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tam-": "cehre, Dzmitry Bahdanau, Fethi Bougares, Holger"
        },
        {
          "the results between the Context-Aware GRU-Based": "semble model outperforms each individual model,",
          "Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tam-": ""
        },
        {
          "the results between the Context-Aware GRU-Based": "",
          "Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tam-": "Schwenk,\nand Yoshua Bengio. 2014.\nLearning"
        },
        {
          "the results between the Context-Aware GRU-Based": "achieving an F1-score of 0.4080.",
          "Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tam-": ""
        },
        {
          "the results between the Context-Aware GRU-Based": "",
          "Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tam-": "phrase representations using rnn encoder-decoder for"
        },
        {
          "the results between the Context-Aware GRU-Based": "",
          "Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tam-": "statistical machine translation."
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "moy Chakraborty. 2023. From multilingual complex-"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "ity to emotional clarity: Leveraging commonsense"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "to unveil emotions in code-mixed dialogues.\nIn Pro-"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "ceedings of the 2023 Conference on Empirical Meth-"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "ods in Natural Language Processing, pages 9638–"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "9652, Singapore. Association for Computational Lin-"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "guistics."
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "Shanglin Lei, Guanting Dong, Xiaoping Wang, Keheng"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "Wang, and Sirui Wang. 2023.\nInstructerc: Reforming"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "emotion recognition in conversation with a retrieval"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "multi-task llms framework."
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "dar\nJoshi, Danqi Chen, Omer Levy, Mike Lewis,"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "Luke Zettlemoyer,\nand Veselin\nStoyanov.\n2019."
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "Roberta: A robustly optimized bert pretraining ap-"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "proach."
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "Ilya Loshchilov and Frank Hutter. 2019. Decoupled"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "weight decay regularization."
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "Soujanya Poria, Navonil Majumder, Rada Mihalcea,"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "and Eduard Hovy. 2019. Emotion recognition in con-"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "versation: Research challenges, datasets, and recent"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "advances."
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "Geng Tu, Bin Liang, Bing Qin, Kam-Fai Wong, and"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "Ruifeng Xu. 2023.\nAn empirical study on multi-"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "ple knowledge from ChatGPT for emotion recogni-"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "tion in conversations.\nIn Findings of the Association"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "for Computational Linguistics: EMNLP 2023, pages"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "12160–12173, Singapore. Association for Computa-"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "tional Linguistics."
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "Kaiser, and Illia Polosukhin. 2017. Attention is all"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "you need.\nIn Advances in Neural Information Pro-"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "cessing Systems, volume 30. Curran Associates, Inc."
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "Anshul Wadhawan and Akshita Aggarwal. 2021. To-"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "wards emotion recognition in Hindi-English code-"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "mixed data: A transformer based approach.\nIn Pro-"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "ceedings of the Eleventh Workshop on Computational"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "Approaches to Subjectivity, Sentiment and Social Me-"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "dia Analysis, pages 195–202, Online. Association for"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "Computational Linguistics."
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Pe-"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "ter J. Liu. 2019. Pegasus: Pre-training with extracted"
        },
        {
          "Shivani Kumar, Ramaneswaran S, Md Akhtar, and Tan-": "gap-sentences for abstractive summarization."
        }
      ],
      "page": 7
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Emotion recognition-based mental healthcare chat-bots: A survey",
      "authors": [
        "Col Cj",
        "B Pariyath",
        "Noorfatimah Siti",
        "Azharuddin Safar",
        "Nair Sahil",
        "Ar"
      ],
      "year": "2021",
      "venue": "Emotion recognition-based mental healthcare chat-bots: A survey"
    },
    {
      "citation_id": "2",
      "title": "Multi-modal sarcasm detection and humor classification in code-mixed conversations",
      "authors": [
        "M Bedi",
        "S Kumar",
        "M Akhtar",
        "T Chakraborty"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/TAFFC.2021.3083522"
    },
    {
      "citation_id": "3",
      "title": "Iiit-h system submission for fire2014 shared task on transliterated search",
      "year": "2015",
      "venue": "Proceedings of the Forum for Information Retrieval Evaluation, FIRE '14",
      "doi": "10.1145/2824864.2824872"
    },
    {
      "citation_id": "4",
      "title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation",
      "authors": [
        "Kyunghyun Cho",
        "Bart Van Merrienboer",
        "Caglar Gulcehre",
        "Dzmitry Bahdanau",
        "Fethi Bougares",
        "Holger Schwenk",
        "Yoshua Bengio"
      ],
      "year": "2014",
      "venue": "Learning phrase representations using rnn encoder-decoder for statistical machine translation"
    },
    {
      "citation_id": "5",
      "title": "Empirical evaluation of gated recurrent neural networks on sequence modeling",
      "authors": [
        "Junyoung Chung",
        "Caglar Gulcehre",
        "Kyunghyun Cho",
        "Yoshua Bengio"
      ],
      "year": "2014",
      "venue": "Empirical evaluation of gated recurrent neural networks on sequence modeling"
    },
    {
      "citation_id": "6",
      "title": "",
      "authors": [
        "Seamless Communication",
        "Loïc Barrault",
        "Yu-An Chung",
        "Cora Meglioli",
        "David Dale",
        "Ning Dong",
        "Paul-Ambroise Duquenne",
        "Hady Elsahar",
        "Hongyu Gong",
        "Kevin Heffernan",
        "John Hoffman",
        "Christopher Klaiber",
        "Pengwei Li",
        "Daniel Licht",
        "Jean Maillard",
        "Alice Rakotoarison",
        "Ram Kaushik",
        "Guillaume Sadagopan",
        "Ethan Wenzek",
        "Bapi Ye",
        "Peng-Jen Akula",
        "Naji Chen",
        "Brian Hachem",
        "Gabriel Ellis",
        "Justin Gonzalez",
        "Prangthip Haaheim",
        "Russ Hansanti",
        "Bernie Howes",
        "Min-Jae Huang",
        "Hirofumi Hwang",
        "Somya Inaguma",
        "Elahe Jain",
        "Amanda Kalbassi",
        "Ilia Kallet",
        "Janice Kulikov",
        "Daniel Lam",
        "Xutai Li",
        "Ruslan Ma",
        "Benjamin Mavlyutov",
        "Mohamed Peloquin",
        "Abinesh Ramadan",
        "Anna Ramakrishnan",
        "Kevin Sun",
        "Tuan Tran",
        "Igor Tran",
        "Vish Tufanov",
        "Carleigh Vogeti",
        "Yilin Wood",
        "Bokai Yang",
        "Pierre Yu",
        "Can Andrews",
        "Marta Balioglu",
        "Onur Costa-Jussà",
        "Maha Celebi",
        "Cynthia Elbayad",
        "Francisco Gao",
        "Justine Guzmán",
        "Ann Kao",
        "Alexandre Lee",
        "Juan Mourachko",
        "Sravya Pino",
        "Christophe Popuri",
        "Safiyyah Ropers",
        "Holger Saleem",
        "Schwenk"
      ],
      "venue": ""
    },
    {
      "citation_id": "7",
      "title": "Goemotions: A dataset of fine-grained emotions",
      "authors": [
        "Dorottya Demszky",
        "Dana Movshovitz-Attias",
        "Jeongwoo Ko",
        "Alan Cowen",
        "Gaurav Nemade",
        "Sujith Ravi"
      ],
      "year": "2020",
      "venue": "Goemotions: A dataset of fine-grained emotions"
    },
    {
      "citation_id": "8",
      "title": "Language-agnostic BERT sentence embedding",
      "authors": [
        "Fangxiaoyu Feng",
        "Yinfei Yang",
        "Daniel Cer",
        "Naveen Arivazhagan",
        "Wei Wang"
      ],
      "year": "2022",
      "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2022.acl-long.62"
    },
    {
      "citation_id": "9",
      "title": "Semeval 2024 -task 10: Emotion discovery and reasoning its flip in conversation (ediref)",
      "authors": [
        "Shivani Kumar",
        "Shad Md",
        "Erik Akhtar",
        "Tanmoy Cambria",
        "Chakraborty"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics"
    },
    {
      "citation_id": "10",
      "title": "From multilingual complexity to emotional clarity: Leveraging commonsense to unveil emotions in code-mixed dialogues",
      "authors": [
        "Shivani Kumar",
        "S Ramaneswaran",
        "Md Akhtar",
        "Tanmoy Chakraborty"
      ],
      "year": "2023",
      "venue": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2023.emnlp-main.598"
    },
    {
      "citation_id": "11",
      "title": "Instructerc: Reforming emotion recognition in conversation with a retrieval multi-task llms framework",
      "authors": [
        "Shanglin Lei",
        "Guanting Dong",
        "Xiaoping Wang",
        "Keheng Wang",
        "Sirui Wang"
      ],
      "year": "2023",
      "venue": "Instructerc: Reforming emotion recognition in conversation with a retrieval multi-task llms framework"
    },
    {
      "citation_id": "12",
      "title": "",
      "authors": [
        "Yinhan Liu",
        "Myle Ott",
        "Naman Goyal",
        "Jingfei Du",
        "Mandar Joshi",
        "Danqi Chen",
        "Omer Levy",
        "Mike Lewis",
        "Luke Zettlemoyer",
        "Veselin Stoyanov"
      ],
      "year": "2019",
      "venue": ""
    },
    {
      "citation_id": "13",
      "title": "Decoupled weight decay regularization",
      "authors": [
        "Ilya Loshchilov",
        "Frank Hutter"
      ],
      "year": "2019",
      "venue": "Decoupled weight decay regularization"
    },
    {
      "citation_id": "14",
      "title": "Emotion recognition in conversation: Research challenges, datasets, and recent advances",
      "authors": [
        "Soujanya Poria",
        "Navonil Majumder",
        "Rada Mihalcea",
        "Eduard Hovy"
      ],
      "year": "2019",
      "venue": "Emotion recognition in conversation: Research challenges, datasets, and recent advances"
    },
    {
      "citation_id": "15",
      "title": "An empirical study on multiple knowledge from ChatGPT for emotion recognition in conversations",
      "authors": [
        "Geng Tu",
        "Bin Liang",
        "Bing Qin",
        "Kam-Fai Wong",
        "Ruifeng Xu"
      ],
      "year": "2023",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2023",
      "doi": "10.18653/v1/2023.findings-emnlp.813"
    },
    {
      "citation_id": "16",
      "title": "Attention is all you need",
      "authors": [
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan Gomez",
        "Ł Ukasz Kaiser",
        "Illia Polosukhin"
      ],
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "17",
      "title": "Towards emotion recognition in Hindi-English codemixed data: A transformer based approach",
      "authors": [
        "Anshul Wadhawan",
        "Akshita Aggarwal"
      ],
      "year": "2021",
      "venue": "Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis"
    },
    {
      "citation_id": "18",
      "title": "Pegasus: Pre-training with extracted gap-sentences for abstractive summarization",
      "authors": [
        "Jingqing Zhang",
        "Yao Zhao",
        "Mohammad Saleh",
        "Peter Liu"
      ],
      "year": "2019",
      "venue": "Pegasus: Pre-training with extracted gap-sentences for abstractive summarization"
    }
  ]
}