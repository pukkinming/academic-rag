{
  "paper_id": "2004.12103v1",
  "title": "How To Read Faces Without Looking At Them",
  "published": "2020-04-25T10:17:38Z",
  "authors": [
    "Suyash Shandilya",
    "Waris Quamer"
  ],
  "keywords": [
    "Compressive analysis",
    "Privacy",
    "Emotion detection",
    "Compressed sensing",
    "Machine Learning"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Face reading is the most intuitive aspect of emotion recognition. Unfortunately, digital analysis of facial expression requires digitally recording personal faces. As emotional analysis is particularly required in more poised scenario, capturing faces becomes a gross violation of privacy. In this paper, we use the concept of compressive analysis introduced in [1] to conceptualise a system which compressively acquires faces in order to ascertain unusable reconstruction, while allowing for acceptable (and adjustable) accuracy in inference.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Need for EQ As we move towards advancing artificial intelligence, we need to realise that intelligence is more than logical intellect. It is the ability to accurately perceive a data in a given context, and return an apposite response. Faster machines will render faster results, smarter machines will render smarter result. But the hoi polloi doesn't always seek an optical solution to a complex computational problem. Intuition entices more than intelligence. An 'IQ' alone cannot suffice to build human-like intuition. Emotional Quotient (EQ) is a major pillar for the foundation of future technology. Advances in deep learning have already shown good promise in the domain; what is required is an intent to accomplish it.\n\nNeed for Privacy Reading faces is one of the most trivial ways humans perceive each other's emotions. Our ability to express and read emotions via face and other physical cues is what advanced our species in communication. Other physiological signals like pulse rate, breathing pattern, also convey a more objective emotional analysis. EEG signals would probably top all of them but none of these can be as conveniently acquired as capturing facial expression. Nevertheless, all of these are privacy invasive. There is no prima facie way to infer something as personal as emotion, without invading some amount of privacy. The concept of compressive analysis allows one to seek a trade-of between privacy and personalisation.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Compressive Analysis",
      "text": "Compressive Sensing  [2, 3]  is a recent idea which includes compression as a part of acquisition itself by acquiring random linear measurements instead of uniform samples. It further defines a lower bound on the number of compressed samples one needs to acquire to reconstruct the original data accurately; or to an accuracy limited only by the level of noise in acquisition. Interested readers are recommended to read the excellent introduction on the topic given by Candes and Wakin  [4] . As the number of acquired measurements are reduced further, the reconstruction quality degrades to a level of unusability very soon. Even from such an irretrievable state, one can expect -given the art of compressive sampling -certain key structures to be preserved deep in the randomness of the compression. The idea of compressive analysis is to analyse this compressed representation (similar to a non-cryptographic digest) of the original image instead of the image itself. For a sufficient degree of compression, a reconstruction may not render a sensible image but still be utilisable for certain important analysis (emotion detection, in this work). It maybe noted that since the analysis is performed only on the compressed version of the image, any reconstruction requires the knowledge of the sensing matrix φ which is (in our case) a binary gaussian random matrix of size M × N where M are the number of compressed samples and N is the length of the image vector (concatenated image matrix). Thus even if the reconstruction may render a 'sensitive' information in some sense, it can only be recovered by someone who has the knowledge of the matrix φ.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Previous Work",
      "text": "This is a more advanced demonstration of the idea of compressive analysis first broached in  [1] . As stated there, the concept of compressive classification was posited along with the single-pixel camera  [5]  by the name of smashed filters  [6] .  [7]  demonstrates privacy preserving face recognition using secure multiparty computation. The idea in the paper was to have privacy preserving biometric verification system. Homomorphic encryption is a common idea in  [7, 8]  and many similar approaches to the idea. To the best of our research, this is the only paper so far, that assures privacy preserving emotion recognition from pure image analysis.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Paper Layout",
      "text": "The rest of the paper is covered as follows. Section 2 details the specifics of the methodology employed including the chosen dataset followed by the preprocessing (encryption/compression in our case) specifications. Section 3 presents the results of the chosen classification models and analyses their performances. Section 4 describes the reconstruction from the compressed images. Section 5 puts forward the conclusion and lays down the future scope of our research. The Japanese Female Facial Expression (JAFFE) database contains 213 images of 7 facial expressions (6 basic facial expressions + 1 neutral) posed by 10 Japanese female models. Each image has been rated on 6 emotion adjectives by 60 Japanese subjects.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Methodology 2.1 Dataset",
      "text": "",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Image Encryption",
      "text": "Compressive Sensing requires that the vector being recovered should be sparse in some domain. The  wavelets were chosen for a sparse representation of the images here. The images underwent a 2D wavelet transformation before being concatenated to a column vector. As earlier in  [1] , binary gaussian matrix was chosen as a sensing matrix φ ∈ {0, 1} M ×N to simulate the DMD in the single-pixel camera  [5] . For M = 2000, some reconstructions showed some characterisable facial features, thus it was decided that M must be less than 2000. For respectable classification accuracy, the lower bound for M was chosen as 50. To observe of the behaviour of the model for even lower values of M, the final values were chosen as: 800,500,200,100,50,20,10,5,2,1. M = 50 is equivalent to a compression ratio of 0.31% (800 ≡ 5%).",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Experimental Procedure",
      "text": "Each image from the dataset was read as 128x128 matrix. Fast Wavelet Transform (FWT) was then applied on the images obtaining the discrete wavelet coefficients at the maximum decomposition level (5 in this case) for the db2 wavelet filter-bank. The coefficients were stacked to form the image vector of size N × 1, which was multiplied with 2) to obtain the compressed vector of the image. This compressed vector was used as the feature set for the classification models as well as the image reconstruction (see section 4). The systematic representation of our proposed work is explained in Figure  2 .",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Results And Analysis",
      "text": "For our analysis, the JAFFE dataset was classified into three broad emotional categories, as Positive, Neutral and Negative. Different classification models namely, Multilayer Perceptrons(MLPs), k-nearest neighbor, Decision tree, Support vector machines among others, were tested with various different parameter values. For evaluating the performance of the classifiers, a 5-fold cross validation accuracy score was used for the value of M = 500. The performances of different models for their optimised parameter values are shown in Table  1 . With the ability to dynamically model non-linear and complex prediction functions, MLPs can learn hidden relationships without imposing any restrictions on the data. It is evident from the results that Multilayer Perceptron (MLP) was the best performing model whereas the rest of the classifiers had notably low accuracies as compared to that of the neural nets. Therefore, it was concluded that the MLPs have a better learning capacity and thus better suited for this problem. The performance of MLP was then further analysed for different values of M, the results of which are depicted in Table  2  and Figure  3 . It can be observed that the accuracy of the model increases when the value of M is reduced from 800 to 500. One of the probable reasons for this behaviour could be a high correlation between attributes values for M = 800. For the lower values of M (i.e M ∈ {1, 2, 5}), the model seemed to be biased towards a particular class. There must have been too much loss in data for the model to be able to differentiate between classes.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Model Accuracy",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Image Reconstruction",
      "text": "Typically, Matching Pursuit algorithms  [10]  are more popular in use because of the speed and ease in execution. Given our objective here is to ensure maximum security of the target data, we have stuck to using basis pursuit  [11]  for all our comparative reconstruction because of stronger guarantees of accuracy, albeit at the cost of computation capital. The SPGL1  [12]  library was used to reconstruct the images. Since noise will only obfuscate reconstruction accuracy, and a well trained classifier can typically work as good in its presence, we did not consider any acquisition noise in our experiments. It was also noted that CVX  [13, 14]  gave slightly better reconstruction but was about 4 times slower. The images in Fig  4  may seem as a glitch to a passing reader but they are the best possible reconstruction we have been able to present. No single colormap could produce a more comprehensible image. One of the other shortcomings of Compressed sensing in general is that it will require very high bit depth to better portray the computation results. The checkered artefacts (more prominent in the bottom 2 rows) evince a very sparse vector in the wavelet basis. One may argue that better reconstruction is possible if we regularise the objective function with the l 2 -norm. That may be true but it seemed practically impossible for us in our experiments. Moreover, the regularisation manifests more as noise than as clarity (if any). Nevertheless, there is a considerable room for improvement which seems more befitting to be mentioned in the next section.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Conclusion And Future Works",
      "text": "We have successfully demonstrated how -using a well trained classifier -extremely compressed samples which are unusable for a recognisable reconstruction, can be used to for classification even in subtle privacy sensitive applications like recognising facial expressions. Although only MLPs performed up to the mark in our analysis, other simple models can be reasonably effective if the degree of compression is reduced. The dataset used in our analysis has been made out of good and earnest efforts. The consistency of images makes computation easy. Unfortunately the real life scenario may be far from it. Our aim here was to prove the concept for face portraits. In future work, we will attempt to develop systems which are able to be at least as efficient on a more diverse and larger dataset. Significant improvement in reconstruction can be achieved by changing the basis of image representation to other more compatible bases. Intuitively it can be understood, how Ridgelets, or Curvelets  [15]  will be more compliant with portrait images than wavelets per se. More sophisticated splines can be developed to achieve an even better transformation. The intuition is to capture more structure of the image in the individual basis vectors. The same idea can be extended to the optimisation problem by utilising the block sparsity of the image vector in the wavelet basis. Visualising way ahead in time, if such a unit is deployed on a large scale, it could lead to having multiple different measurements of a person with the same expression. An unwanted adversary, who somehow manages to assimilate all these different measurements along with the sensing matrices may attempt to reconstruct certain faces. Even if a reconstruction seems very overreaching, a detection from a known subset of people could be feasible. In future we wish to analyse whether, and to what extent, such classifications are possible from compressed samples.",
      "page_start": 5,
      "page_end": 5
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Samples from the Japanese Female Facial Expression (JAFFE) dataset",
      "page": 2
    },
    {
      "caption": "Figure 2: Systematic representation of our proposed work",
      "page": 3
    },
    {
      "caption": "Figure 3: Accuracy of MLP Model Vs different Values of M",
      "page": 4
    },
    {
      "caption": "Figure 4: The ﬁrst row consists of samples from our dataset for different labels (L to R - neutral, positive, negative,",
      "page": 4
    },
    {
      "caption": "Figure 4: may seem as a glitch to a passing reader but they are the best possible reconstruction we have been",
      "page": 5
    }
  ],
  "tables": [
    {
      "caption": "Table 1: With the ability to",
      "data": [
        {
          "Model": "K-Nearest Neighbors",
          "Accuracy": "0.49"
        },
        {
          "Model": "SVM (Linear kernal)",
          "Accuracy": "0.42"
        },
        {
          "Model": "SVM (RBF kernal)",
          "Accuracy": "0.42"
        },
        {
          "Model": "Gaussian Process",
          "Accuracy": "0.44"
        },
        {
          "Model": "Decision Tree",
          "Accuracy": "0.28"
        },
        {
          "Model": "Random Forest",
          "Accuracy": "0.26"
        },
        {
          "Model": "Multilayer Perceptron",
          "Accuracy": "0.79"
        },
        {
          "Model": "AdaBoost",
          "Accuracy": "0.44"
        },
        {
          "Model": "Naive Bayes",
          "Accuracy": "0.30"
        },
        {
          "Model": "QDA",
          "Accuracy": "0.30"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "M": "800",
          "Compression Ratio(%)": "4.89",
          "Train Accuracy": "0.90",
          "Test Accuracy": "0.73"
        },
        {
          "M": "500",
          "Compression Ratio(%)": "3.05",
          "Train Accuracy": "0.97",
          "Test Accuracy": "0.79"
        },
        {
          "M": "200",
          "Compression Ratio(%)": "1.22",
          "Train Accuracy": "0.96",
          "Test Accuracy": "0.78"
        },
        {
          "M": "100",
          "Compression Ratio(%)": "0.61",
          "Train Accuracy": "0.95",
          "Test Accuracy": "0.71"
        },
        {
          "M": "50",
          "Compression Ratio(%)": "0.31",
          "Train Accuracy": "0.91",
          "Test Accuracy": "0.70"
        },
        {
          "M": "20",
          "Compression Ratio(%)": "0.12",
          "Train Accuracy": "0.74",
          "Test Accuracy": "0.56"
        },
        {
          "M": "10",
          "Compression Ratio(%)": "0.06",
          "Train Accuracy": "0.62",
          "Test Accuracy": "0.50"
        },
        {
          "M": "5",
          "Compression Ratio(%)": "0.03",
          "Train Accuracy": "0.52",
          "Test Accuracy": "0.40"
        },
        {
          "M": "2",
          "Compression Ratio(%)": "0.01",
          "Train Accuracy": "0.43",
          "Test Accuracy": "0.40"
        },
        {
          "M": "1",
          "Compression Ratio(%)": "0.006",
          "Train Accuracy": "0.43",
          "Test Accuracy": "0.39"
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Minimizing acquisition maximizing inference -a demonstration on print error detection",
      "authors": [
        "Suyash Shandilya"
      ],
      "year": "2019",
      "venue": "Algorithms for Intelligent Systems"
    },
    {
      "citation_id": "2",
      "title": "Compressed sensing",
      "authors": [
        "D Donoho"
      ],
      "year": "2006",
      "venue": "IEEE Transactions on Information Theory"
    },
    {
      "citation_id": "3",
      "title": "Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information",
      "authors": [
        "E Candes",
        "J Romberg",
        "T Tao"
      ],
      "year": "2006",
      "venue": "IEEE Transactions on Information Theory"
    },
    {
      "citation_id": "4",
      "title": "An introduction to compressive sampling",
      "authors": [
        "E Candes",
        "M Wakin"
      ],
      "year": "2008",
      "venue": "IEEE Signal Processing Magazine"
    },
    {
      "citation_id": "5",
      "title": "Single-pixel imaging via compressive sampling",
      "authors": [
        "M Duarte",
        "M Davenport",
        "D Takhar",
        "J Laska",
        "T Sun",
        "K Kelly",
        "R Baraniuk"
      ],
      "year": "2008",
      "venue": "IEEE Signal Processing Magazine"
    },
    {
      "citation_id": "6",
      "title": "The smashed filter for compressive classification and target recognition",
      "authors": [
        "A Mark",
        "Marco Davenport",
        "Duarte",
        "Jason Michael B Wakin",
        "Dharmpal Laska",
        "Kevin Takhar",
        "Richard Kelly",
        "Baraniuk"
      ],
      "year": "2007",
      "venue": "Computational Imaging V"
    },
    {
      "citation_id": "7",
      "title": "Privacypreserving face recognition",
      "authors": [
        "Zekeriya Erkin",
        "Martin Franz",
        "Jorge Guajardo",
        "Stefan Katzenbeisser",
        "Inald Lagendijk",
        "Tomas Toft"
      ],
      "year": "2009",
      "venue": "Privacy Enhancing Technologies"
    },
    {
      "citation_id": "8",
      "title": "Efficient privacy-preserving face recognition",
      "authors": [
        "Ahmad-Reza Sadeghi",
        "Thomas Schneider",
        "Immo Wehrenberg"
      ],
      "year": "2009",
      "venue": "International Conference on Information Security and Cryptology"
    },
    {
      "citation_id": "9",
      "title": "Ten lectures on wavelets",
      "authors": [
        "Ingrid Daubechies"
      ],
      "year": "1992",
      "venue": "Ten lectures on wavelets"
    },
    {
      "citation_id": "10",
      "title": "Performance evaluation of greedy reconstruction algorithms in compressed sensing",
      "authors": [
        "Hongbo Bi",
        "Chunhui Zhao",
        "Ying Liu",
        "Ning Li"
      ],
      "year": "2016",
      "venue": "2016 9th International Congress on Image and Signal Processing"
    },
    {
      "citation_id": "11",
      "title": "Algorithms for multiple basis pursuit denoising",
      "authors": [
        "Alain Rakotomamonjy"
      ],
      "year": "2009",
      "venue": "Algorithms for multiple basis pursuit denoising"
    },
    {
      "citation_id": "12",
      "title": "Probing the pareto frontier for basis pursuit solutions",
      "authors": [
        "Ewout Van",
        "Den Berg",
        "Michael Friedlander"
      ],
      "year": "2008",
      "venue": "SIAM Journal on Scientific Computing"
    },
    {
      "citation_id": "13",
      "title": "CVX: Matlab software for disciplined convex programming",
      "authors": [
        "Michael Grant",
        "Stephen Boyd"
      ],
      "year": "2014",
      "venue": "CVX: Matlab software for disciplined convex programming"
    },
    {
      "citation_id": "14",
      "title": "Graph implementations for nonsmooth convex programs",
      "authors": [
        "Michael Grant",
        "Stephen Boyd"
      ],
      "year": "2008",
      "venue": "Recent Advances in Learning and Control"
    },
    {
      "citation_id": "15",
      "title": "Curvelets and Ridgelets",
      "authors": [
        "Jalal Fadili",
        "Jean-Luc Starck"
      ],
      "year": "2012",
      "venue": "Curvelets and Ridgelets"
    }
  ]
}