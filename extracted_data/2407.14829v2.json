{
  "paper_id": "2407.14829v2",
  "title": "Overview Of Ai-Debater 2023: The Challenges Of Argument Generation Tasks",
  "published": "2024-07-20T10:13:54Z",
  "authors": [
    "Jiayu Lin",
    "Guanrong Chen",
    "Bojun Jin",
    "Chenyang Li",
    "Shutong Jia",
    "Wancong Lin",
    "Yang Sun",
    "Yuhang He",
    "Caihua Yang",
    "Jianzhu Bao",
    "Jipeng Wu",
    "Wen Su",
    "Jinglu Chen",
    "Xinyi Li",
    "Tianyu Chen",
    "Mingjie Han",
    "Shuaiwen Du",
    "Zijian Wang",
    "Jiyin Li",
    "Fuzhong Suo",
    "Hao Wang",
    "Nuanchen Lin",
    "Xuanjing Huang",
    "Changjian Jiang",
    "RuiFeng Xu",
    "Long Zhang",
    "Jiuxin Cao",
    "Ting Jin",
    "Zhongyu Wei"
  ],
  "keywords": [
    "Computational Argumentation",
    "AI-Debater",
    "Natural Language Processing"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "In this paper we present the results of the AI-Debater 2023 Challenge held by the Chinese Conference on Affect Computing (CCAC 2023), and introduce the related datasets. We organize two tracks to handle the argumentative generation tasks in different scenarios, namely, Counter-Argument Generation (Track 1) and Claim-based Argument Generation (Track 2). Each track is equipped with its distinct dataset and baseline model respectively. In total, 32 competing teams register for the challenge, from which we received 11 successful submissions. In this paper, we will present the results of the challenge and a summary of the systems, highlighting commonalities and innovations among participating systems. Datasets and baseline models of the AI-Debater 2023 Challenge have been already released and can be accessed through the official website 3 of the challenge.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Track 1: Counter-Argument Generation",
      "text": "Task Formulation We formulate our task according to Lin et al.  [17] 's setting. For a given topic τ and original argumentx, the participating model automatically generates one sentence y that refutes the original argument (referred to as a counter-argument).\n\nData Construction We created ArgTersely dataset for counter-argument generation task by extracting data from the ChangeMyView (CMV) debate forum and manually annotating them. The process began with data preprocessing to segment replies into sentences and remove invalid content. Annotators then selected sentences that countered the original arguments during trial annotation, which also served as training and consistency testing with reference annotations. The formal annotation phase used a cross-annotation strategy with two annotators per triplet and a third to resolve disagreements, ensuring dataset quality. During AI-Debater 2023 challenge, we used a subset of this dataset with 10,000 training and 4,000 test samples.\n\nScoring Metric We use ROUGE-L score as the automatic evaluation metrics.\n\nBaseline Model We fine-tuned GPT-2  [25]  as a baseline model. Specifically, we concatenated the debate topic, original argument, and counter-argument into a continuous text, applied mask processing to the debate topic and original argument, and then conducted auto-regressive training targeting the counter-argument part with a cross-entropy loss function.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Track 2: Claim-Based Argument Generation",
      "text": "Task Formulation In this task, for the given claim c, the participating model automatically generates 5 independent arguments, Z = [z 1 , z 2 , ..., z 5 ] that fit the claim. Scoring Metric We use ROUGE-L score as the automatic evaluation metrics.",
      "page_start": 1,
      "page_end": 3
    },
    {
      "section_name": "Baseline Model",
      "text": "We fine-tuned Mengzi-T5-base  [26]  as a baseline model. Specifically, we concatenated the claim and the argument into a continuous text, applied mask processing to the debate topic, and then conducted auto-regressive training targeting the argument part with a cross-entropy loss function.\n\n4 Technical Approaches",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Analysis Of The Problem",
      "text": "The competition's objective is to create a model capable of automatically generating counter-arguments for a given topic and original argument. The training data set presents challenges such as duplicate topics and sources, and a skewed distribution of counter-arguments in length and frequency.\n\nThe original arguments typically range from 30 to 200 words, averaging 108.9877 words, while counter-arguments range from 30 to 250 words, averaging 118.8507 words. The counter-argument length distribution is notably uneven, with a few excessively long sentences that can introduce noise into the training process.\n\nAdditionally, very short sentences can impede the model's ability to learn complex logical expressions. The topic distribution is also uneven, with the majority of topics having more than forty counter-arguments, and the least having only a few.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Methodology",
      "text": "As is shown in figure  1 , our methodology encompasses a two-part approach: a data augmentation module and a generative language model based on instruction tuning. The data augmentation module addresses the imbalance in the training data through two-tiered expansion. Firstly, we utilized ChatGPT  [27]  to generate novel counter-arguments for existing topics, adding 6171 new data points after filtering. Secondly, we incorporated human debate data from the Kialo forum, manually curating and labeling topics to add 9987 new data points and 98 new topics. We also refined the data by removing extreme lengths and low-quality text, such as profanity and non-argumentative sentences, to enhance model performance.\n\nFor the generative language model, we employed instruction tuning on a pre-trained model, selecting Tk-INSTRUCT  [28]  over Flan-T5  [29]  for its superior performance. Tk-INSTRUCT was fine-tuned using a dataset covering 1616 diverse NLP tasks. As is shown in figure  2 , we crafted instruction templates tailored to the counterargument task, consisting of a task definition, positive example demonstrations, and reasoning cases. The instruction template was designed with two positive cases, and we explored the use of connective adverbs to promote syntactic diversity in the output.\n\nFigure  1 : The overall architecture of the proposed method.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Experiments",
      "text": "In our experiments, the validation set was structured to reflect the original dataset's length distribution. We experimented with theme-based division but found it less effective due to the uneven distribution of themes and counter-arguments.\n\nThe model implementation utilized tk-instruct-large-def-pos, a model with 770 million parameters, and applied a minimum generation length of 50 words and a maximum of 256 words to prevent the generation of overly short sentences that could reduce model performance. We employed Beam Search with three beams for decoding, balancing   1 : The impact of different data augmentation approaches.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Track 1: Pre-And Post-Processing In Counter-Argument Generation",
      "text": "This subsection will introduce the details of the model submitted by huashui team in Track 1.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Framework",
      "text": "Pre-processing and post-processing are pivotal in NLP, particularly for text generation where they encompass tokenization, template design, and decoding strategies. Despite the prevalence of pre-trained models fine-tuned for specific tasks, these methods fall short in low-resource or under-equipped settings. Our approach circumvents this by optimizing performance through strategic pre-processing and post-processing, without structural model changes. Experimental results validate the efficacy of our strategies against those reliant on extensive data or model modifications.\n\nThe overall framework of our study is as follows. Initially, the original text is transformed into an input that is more easily understood by the model through a predefined template. Subsequently, the tokenizer completes the basic word embedding and inputs it into the GPT-2 model to extract text features and predict the probability of generating words. Generally, greedy algorithms are used as the default decoding strategy in current research. However, the demand in this track is to allow the model to output multiple sentences simultaneously. Therefore, this study introduces diverse beam search  [30]  and contrastive search  [31]  into the model decoding process.\n\nDiverse beam search  [30]  improves upon the limitations of the \"single-point departure\" inherent in traditional beam search strategies. It draws on the ideas of breadth-first search (BFS), exploring paths from multiple different starting points, effectively enhancing the diversity of the model's generation. Contrastive search, a new concept proposed in 2022, involves judging the text similarity matrix at each decoding moment to incorporate a similarity penalty, resulting in non-repetitive yet coherent output.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Experiments",
      "text": "In our experimental setup, we used the GPT-2 base version as the foundational model. For diverse beam search, the beam width was set to 5, the number of groups to 5, and the diversity penalty to 1. For contrastive search, the penalty factor was set to 0.6, and the top-k value to 5. The experimental results are as follows: It can be observed that the two strategies adopted in this study have outperformed the method used by the baseline model, thereby proving the rationality of the starting point of this study.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Track 1: A Diffusion Framework For Counter-Argument Generation",
      "text": "This subsection will introduce the details of the model submitted by ZUT team in Track 1.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Controlled Text Generation Task Formulation",
      "text": "The problem addressed in this document can be defined as follows: Given control attributes (arguments, claims) w x and a target text (counter-argument) w y , train a language model to output high-quality w y that aligns with the control attributes upon input w x .\n\nThe controlled text generation task is formalized as sampling from a conditional distribution p(w y ′ |w x ), where w x represents control attributes, p(w y ′ ) ensuring fluency to complete the attribute control process p(w x |w y ′ ).",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Sequence Diffusion Process",
      "text": "Inspired by D3PM, we use a method for diffusing disorganized text by treating mask tokens as noise addition and decode tokens as noise removal during the diffusion process. The forward diffusion process involves progressively masking tokens, while the reverse diffusion process decodes the masked tokens back into text.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Model Integration",
      "text": "We introduces a combined sequence diffusion model that integrates a pretrained model (BERT) with a diffusion model. The model uses BERT's encoding and decoding capabilities in conjunction with the diffusion model's noise addition and removal processes. This integration allows for the establishment of a connection between control attributes and corresponding text within different feature spaces.\n\nThe diffusion process is guided by a posterior distribution, with specific steps outlined for optimization and regularization of fluency. The model aims to generate high-quality text with controlled attributes without the need for a separate attribute classifier, thus avoiding errors and reducing training time.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Experiments",
      "text": "The document presents experimental results comparing the proposed model with baseline models GPT-2. The performance is measured using the ROUGE-L metric, which evaluates the quality of generated text.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Track 2: Enhancing Argument Diversity For Claim-Based Argument Generation",
      "text": "This subsection will introduce the details of the model submitted by HITSZ-HLT team in Track 2.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Task Analysis",
      "text": "The competition's objective was to create an automated system capable of generating five relevant arguments for a given claim. The analysis of the competition data revealed that while claims were brief, the corresponding arguments were more extensive. The challenge lay in producing lengthy and varied texts from short inputs. With an average of 104.70 arguments per claim, the task was to efficiently utilize this wealth to generate five distinct arguments. Additionally, the dataset included some arguments that were short and lacked substance, necessitating a strategy to address these issues.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Methods",
      "text": "To overcome the identified challenges, a two-part framework (figure  7 ) was devised. The second component, Generation Enhancement Strategy Based on Keyword Guidance (KeyGuide), introduced keywords for each argument to guide the model during generation. These keywords, extracted using the TF-IDF algorithm, were concatenated to the argument's beginning and served as prompts. This approach resulted in a higher diversity and quality of generated arguments.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Experiments",
      "text": "The experimental phase began with data preprocessing, where TF-IDF was used to generate and append three keywords to each argument. The arguments for each claim were evenly divided into five subsets, creating five sub-training sets. The pre-trained models used for the generation task include Mengzi-T5  [26] , T5  [32] , BART  [33] , CPT  [34] , etc. And the bart-base-chinese model was selected for its performance in preliminary experiments. Each subset was then used to fine-tune a separate BART model, resulting in five distinct generation models.\n\nAfter obtaining the five subsets, each subset is processed into the form of \"source sequence to target sequence\" and then used separately to fine-tune five Bart models with different parameters, resulting in five fine-tuned generation models. During the inference phase, the given claims are inputted into the aforementioned five generation models separately, and each model generates one argument. The decoding strategy is beam search, with num_beams set to 5, maximum sequence length set to 128. Additionally, during decoding, repetition_penalty is set to 5.0 to alleviate repetition issues, and length_penalty is set to 5.0.\n\nOur framework achieved a performance of ROUGE-L=0.167 on the official unseen test set provided by the competition committee. Furthermore, to validate the necessity and effectiveness of each module in our framework, we conducted ablation experiments on the validation set, and the results are shown in Table  4 . It can be seen that compared to not using keywords as guidance, our proposed keyword-guided generation enhancement method leads to a significant improvement in performance. This is because the keywords generated by the model can guide the generation of subsequent arguments. Moreover, our proposed strategy of generating diversity based on subset partitioning shows some improvement in ROUGE-1 and ROUGE-2 scores. This experiment validates the effectiveness of the two modules we proposed.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Track 2: Longest Common Subsequence Search For Claim-Based Argument Generation",
      "text": "This subsection will introduce the details of the model submitted by tingzhidui team in Track 2.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Solution Description",
      "text": "The T5 model is used as the baseline model, with the input being \"Topic: claim,\" where the claim is replaced with a specific text. If the length of the argument is less than 128, other arguments are copied to increase the length. The loss function is the cross-entropy function, with a learning rate of 1e-4 and the optimizer being Adamw. Parameters were adjusted for the T5 and GPT-2 models to achieve the best configuration. After analyzing the experimental results, the GPT-2 model was chosen as the final model.\n\nOur team proposed a method based on two algorithms, a best score (BS) calculation algorithm based on longest common subsequence (LCS) and a best standard argument (BSA) calculation algorithm. Using these algorithms, the best score and the best standard argument for each claim can be obtained.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Experiments",
      "text": "Table  5  shows the Rouge-L scores of the T5 and GPT-2 models on the validation set and their performance under different parameter configurations.\n\nTable  6  shows some of the best arguments, the scores of the best arguments, the best subsequences, and their scores for certain claims.\n\nIt was found that the evaluation index did not reflect the differences between predicted arguments and proposed a method based on high-frequency words and keywords. The GPT-2 model was used for training and prediction, achieving a Rouge-L score of 0.2035, and the score after submission was 0.125.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Model Alc Mcl Mal Beam",
      "text": "",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Conclusion",
      "text": "The AI-Debater 2023 Challenge moves towards argument generation tasks. We set up counter-argument generation and claim-based argument generation tasks. In this challenge, we build and release a new counter-argument generation dataset, enriching argument generation tasks.\n\nThe winning approaches, which included data augmentation, instruction tuning, and diffusion model integration, have demonstrated the potential of current AI technologies to understand and construct arguments. These methods have not only improved the performance of the models but also provided insights into how AI can be further developed for complex language tasks.\n\nLooking ahead, the challenge has identified key areas for future research, including enhancing argument quality, addressing data imbalance, and improving coherence in generated texts. As the field progresses, it is expected that AI will increasingly contribute to nuanced debates, offering new possibilities for AI applications in various domains.",
      "page_start": 13,
      "page_end": 13
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: , our methodology encompasses a two-part approach: a data augmentation module and a",
      "page": 4
    },
    {
      "caption": "Figure 2: , we crafted instruction templates tailored to the counter-",
      "page": 4
    },
    {
      "caption": "Figure 1: The overall architecture of the proposed method.",
      "page": 4
    },
    {
      "caption": "Figure 2: Instruction fine-tuning template for generating counter-arguments.",
      "page": 5
    },
    {
      "caption": "Figure 3: Overall model framework.",
      "page": 6
    },
    {
      "caption": "Figure 4: Sequence diffusion generation model integrating pre-trained models.",
      "page": 7
    },
    {
      "caption": "Figure 5: Sequence diffusion process.",
      "page": 7
    },
    {
      "caption": "Figure 6: Integration process of diffusion model and pre-training model.",
      "page": 8
    },
    {
      "caption": "Figure 7: ) was devised.",
      "page": 9
    },
    {
      "caption": "Figure 7: Illustration of our method.",
      "page": 9
    },
    {
      "caption": "Figure 8: Illustration of subset division.",
      "page": 10
    }
  ],
  "tables": [
    {
      "caption": "Table 6: Best Subsequence and Best Standard Argument Results. The claim, best standard argument (BSA), best",
      "data": [
        {
          "Claim": "“佛 系”标 签\n对 青 年 人 成\n长弊大于利",
          "BSA": "“首先是在心理学层面，佛系标签不利\n于青年人成长的人格全面发展。”",
          "BSA score": "0.2115",
          "BS": "“佛系标签是\n的 ， 在 的 不\n的。”",
          "BS Score": "0.2449"
        },
        {
          "Claim": "“佛 系”标 签\n对 青 年 人 成\n长利大于弊",
          "BSA": "“综上佛系标签对青年人的成长利大于\n弊，谢谢。”",
          "BSA score": "0.2085",
          "BS": "“我 们 是 佛\n系 ， 是 的 ，\n的。”",
          "BS Score": "0.2419"
        },
        {
          "Claim": "短 视 频 的 火\n爆 是 精 神 文\n化 匮 乏 的 表\n现",
          "BSA": "“而体现二字，一方面指短视频火爆的\n成因是精神文化的匮乏，另一方面是说\n短视频本身的精神文化也是匮乏的。”",
          "BSA score": "0.2294",
          "BS": "“方精神文化\n的 ， 是 短 视\n频 的 精 神 文\n化是的。”",
          "BS Score": "0.2734"
        },
        {
          "Claim": "对 知 识 网 红\n的 崇 拜 让 我\n们 对 真 知 更\n远",
          "BSA": "“如果它是提供给你知识可以，可是如\n果他提供给你的知识方式是告诉你这是\n你思维的终点，提供知识的同时剥夺你\n的思维，这不可以。”",
          "BSA score": "0.2123",
          "BS": "“知 识 网 红\n是 ， 是 的 ，\n我。”",
          "BS Score": "0.2539"
        }
      ],
      "page": 12
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Team": "HITSZ-HLT",
          "Score": "25.2"
        },
        {
          "Team": "ZUT",
          "Score": "18.8"
        },
        {
          "Team": "huashui",
          "Score": "17.2"
        },
        {
          "Team": "tingzhidui",
          "Score": "16.3"
        },
        {
          "Team": "baseline",
          "Score": "14.3"
        }
      ],
      "page": 17
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Team": "HITSZ-HLT",
          "Score": "16.7"
        },
        {
          "Team": "ZUT",
          "Score": "15.4"
        },
        {
          "Team": "tingzhidui",
          "Score": "12.5"
        },
        {
          "Team": "baseline",
          "Score": "10.1"
        }
      ],
      "page": 17
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Elements of argumentation",
      "authors": [
        "Philippe Besnard",
        "Anthony Hunter"
      ],
      "year": "2008",
      "venue": "Elements of argumentation"
    },
    {
      "citation_id": "2",
      "title": "Argumentation and debate",
      "authors": [
        "James Milton",
        "O' Neill",
        "Craven Laycock",
        "Robert Scales"
      ],
      "year": "1927",
      "venue": "Argumentation and debate"
    },
    {
      "citation_id": "3",
      "title": "Reasonableness and effectiveness in argumentative discourse",
      "authors": [
        "H Frans",
        "Van Eemeren"
      ],
      "year": "2015",
      "venue": "Argumentation library"
    },
    {
      "citation_id": "4",
      "title": "An autonomous debating system",
      "authors": [
        "Noam Slonim",
        "Yonatan Bilu",
        "Carlos Alzate",
        "Roy Bar-Haim",
        "Ben Bogin",
        "Francesca Bonin",
        "Leshem Choshen",
        "Edo Cohen-Karlik",
        "Lena Dankin",
        "Lilach Edelstein"
      ],
      "year": "2021",
      "venue": "Nature"
    },
    {
      "citation_id": "5",
      "title": "Winning arguments. Law &",
      "authors": [
        "Julie Seaman"
      ],
      "year": "2016",
      "venue": "Psychol. Rev"
    },
    {
      "citation_id": "6",
      "title": "Is this post persuasive? ranking argumentative comments in online forum",
      "authors": [
        "Zhongyu Wei",
        "Yang Liu",
        "Yi Li"
      ],
      "year": "2016",
      "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "7",
      "title": "A structure-aware argument encoder for literature discourse analysis",
      "authors": [
        "Yinzi Li",
        "Wei Chen",
        "Zhongyu Wei",
        "Yujun Huang",
        "Chujun Wang",
        "Siyuan Wang",
        "Qi Zhang",
        "Xuanjing Huang",
        "Libo Wu ; Nicoletta",
        "Chu-Ren Calzolari",
        "Hansaem Huang",
        "James Kim",
        "Leo Pustejovsky",
        "Wanner",
        "Key-Sun",
        "Pum-Mo Choi",
        "Hsin-Hsi Ryu",
        "Lucia Chen",
        "Heng Donatelli",
        "Sadao Ji",
        "Patrizia Kurohashi",
        "Nianwen Paggio",
        "Seokhwan Xue",
        "Younggyun Kim",
        "Zhong Hahm",
        "He"
      ],
      "year": "2022",
      "venue": "Proceedings of the 29th International Conference on Computational Linguistics"
    },
    {
      "citation_id": "8",
      "title": "Leveraging argumentation knowledge graph for interactive argument pair identification",
      "authors": [
        "Jian Yuan",
        "Zhongyu Wei",
        "Donghua Zhao",
        "Qi Zhang",
        "Changjian Jiang"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021"
    },
    {
      "citation_id": "9",
      "title": "Exploring the integration of hierarchical argumentation graphs in language pretraining",
      "authors": [
        "Jingcong Liang",
        "Rong Ye",
        "Meng Han",
        "Qi Zhang",
        "Ruofei Lai",
        "Xinyu Zhang",
        "Zhao Cao",
        "Xuanjing Huang",
        "Zhongyu Wei",
        "Hi-Arg"
      ],
      "year": "2023",
      "venue": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "10",
      "title": "Sparks of artificial general intelligence: Early experiments with gpt-4",
      "authors": [
        "Sébastien Bubeck",
        "Varun Chandrasekaran",
        "Ronen Eldan",
        "Johannes Gehrke",
        "Eric Horvitz",
        "Ece Kamar",
        "Peter Lee",
        "Yin Tat Lee",
        "Yuanzhi Li",
        "Scott Lundberg"
      ],
      "year": "2023",
      "venue": "Sparks of artificial general intelligence: Early experiments with gpt-4",
      "arxiv": "arXiv:2303.12712"
    },
    {
      "citation_id": "11",
      "title": "Palm: Scaling language modeling with pathways",
      "authors": [
        "Aakanksha Chowdhery",
        "Sharan Narang",
        "Jacob Devlin",
        "Maarten Bosma",
        "Gaurav Mishra",
        "Adam Roberts",
        "Paul Barham",
        "Hyung Chung",
        "Charles Sutton",
        "Sebastian Gehrmann"
      ],
      "year": "2023",
      "venue": "Journal of Machine Learning Research"
    },
    {
      "citation_id": "12",
      "title": "Open and efficient foundation language models",
      "authors": [
        "Hugo Touvron",
        "Thibaut Lavril",
        "Gautier Izacard",
        "Xavier Martinet",
        "Marie-Anne Lachaux",
        "Timothée Lacroix",
        "Baptiste Rozière",
        "Naman Goyal",
        "Eric Hambro",
        "Faisal Azhar"
      ],
      "year": "2023",
      "venue": "Open and efficient foundation language models",
      "arxiv": "arXiv:2302.13971"
    },
    {
      "citation_id": "13",
      "title": "Llama 2: Open foundation and fine-tuned chat models",
      "authors": [
        "Hugo Touvron",
        "Louis Martin",
        "Kevin Stone",
        "Peter Albert",
        "Amjad Almahairi",
        "Yasmine Babaei",
        "Nikolay Bashlykov",
        "Soumya Batra",
        "Prajjwal Bhargava",
        "Shruti Bhosale"
      ],
      "year": "2023",
      "venue": "Llama 2: Open foundation and fine-tuned chat models",
      "arxiv": "arXiv:2307.09288"
    },
    {
      "citation_id": "14",
      "title": "Discrete argument representation learning for interactive argument pair identification",
      "authors": [
        "Lu Ji",
        "Zhongyu Wei",
        "Jing Li",
        "Qi Zhang",
        "Xuanjing Huang"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "15",
      "title": "Neural argument generation augmented with externally retrieved evidence",
      "authors": [
        "Xinyu Hua",
        "Lu Wang"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "16",
      "title": "High quality real-time structured debate generation",
      "authors": [
        "Eric Bolton",
        "Alex Calderwood",
        "Niles Christensen",
        "Jerome Kafrouni",
        "Iddo Drori"
      ],
      "year": "2020",
      "venue": "High quality real-time structured debate generation",
      "arxiv": "arXiv:2012.00209"
    },
    {
      "citation_id": "17",
      "title": "Argue with me tersely: Towards sentence-level counter-argument generation",
      "authors": [
        "Jiayu Lin",
        "Rong Ye",
        "Meng Han",
        "Qi Zhang",
        "Ruofei Lai",
        "Xinyu Zhang",
        "Zhao Cao",
        "Xuan-Jing Huang",
        "Zhongyu Wei"
      ],
      "year": "2023",
      "venue": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "18",
      "title": "Argument generation with retrieval, planning, and realization",
      "authors": [
        "Xinyu Hua",
        "Zhe Hu",
        "Lu Wang"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "19",
      "title": "Counter-argument generation by attacking weak premises",
      "authors": [
        "Milad Alshomary",
        "Shahbaz Syed",
        "Arkajit Dhar",
        "Martin Potthast",
        "Henning Wachsmuth"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021"
    },
    {
      "citation_id": "20",
      "title": "Aspect-controlled neural argument generation",
      "authors": [
        "Benjamin Schiller",
        "Johannes Daxenberger",
        "Iryna Gurevych"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "21",
      "title": "Conclusion-based counter-argument generation",
      "authors": [
        "Milad Alshomary",
        "Henning Wachsmuth"
      ],
      "year": "2023",
      "venue": "Proceedings of the 17th Conference of the European Chapter"
    },
    {
      "citation_id": "22",
      "title": "Belief-based generation of argumentative claims",
      "authors": [
        "Milad Alshomary",
        "Wei-Fan Chen",
        "Timon Gurcke",
        "Henning Wachsmuth"
      ],
      "year": "2021",
      "venue": "Proceedings of the 16th Conference of the European Chapter"
    },
    {
      "citation_id": "23",
      "title": "Americano: Argument generation with discourse-driven decomposition and agent interaction",
      "authors": [
        "Zhe Hu",
        "Hou Pong Chan",
        "Yu Yin"
      ],
      "year": "2023",
      "venue": "Americano: Argument generation with discourse-driven decomposition and agent interaction"
    },
    {
      "citation_id": "24",
      "title": "Rl-gan based toulmin argument generation",
      "authors": [
        "Fatima Alkhawaldeh",
        "Tommy Yuan",
        "Dimitar Kazakov"
      ],
      "year": "2020",
      "venue": "Rl-gan based toulmin argument generation"
    },
    {
      "citation_id": "25",
      "title": "Language models are unsupervised multitask learners",
      "authors": [
        "Alec Radford",
        "Jeffrey Wu",
        "Rewon Child",
        "David Luan",
        "Dario Amodei",
        "Ilya Sutskever"
      ],
      "year": "2019",
      "venue": "OpenAI blog"
    },
    {
      "citation_id": "26",
      "title": "Towards lightweight yet ingenious pre-trained models for chinese",
      "authors": [
        "Zhuosheng Zhang",
        "Hanqing Zhang",
        "Keming Chen",
        "Yuhang Guo",
        "Jingyun Hua",
        "Yulong Wang",
        "Ming Zhou",
        "Mengzi"
      ],
      "year": "2021",
      "venue": "Towards lightweight yet ingenious pre-trained models for chinese",
      "arxiv": "arXiv:2110.06696"
    },
    {
      "citation_id": "27",
      "title": "Chatgpt: Optimizing language models for dialogue. openai",
      "authors": [
        "Tb Openai"
      ],
      "year": "2022",
      "venue": "Chatgpt: Optimizing language models for dialogue. openai"
    },
    {
      "citation_id": "28",
      "title": "Super-NaturalInstructions: Generalization via declarative instructions on 1600+ NLP tasks",
      "authors": [
        "Yizhong Wang",
        "Swaroop Mishra",
        "Pegah Alipoormolabashi",
        "Yeganeh Kordi",
        "Amirreza Mirzaei",
        "Atharva Naik",
        "Arjun Ashok",
        "Arut Selvan Dhanasekaran",
        "Anjana Arunkumar",
        "David Stap",
        "Eshaan Pathak",
        "Giannis Karamanolakis",
        "Haizhi Lai",
        "Ishan Purohit",
        "Ishani Mondal",
        "Jacob Anderson",
        "Kirby Kuznia",
        "Krima Doshi"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "29",
      "title": "Scaling instruction-finetuned language models",
      "authors": [
        "Chung Hyung Won",
        "Le Hou",
        "Shayne Longpre",
        "Barret Zoph",
        "Yi Tay",
        "William Fedus",
        "Yunxuan Li",
        "Xuezhi Wang",
        "Mostafa Dehghani",
        "Siddhartha Brahma"
      ],
      "year": "2024",
      "venue": "Journal of Machine Learning Research"
    },
    {
      "citation_id": "30",
      "title": "Diverse beam search: Decoding diverse solutions from neural sequence models",
      "authors": [
        "K Ashwin",
        "Michael Vijayakumar",
        "Cogswell",
        "Qing Ramprasath R Selvaraju",
        "Stefan Sun",
        "David Lee",
        "Dhruv Crandall",
        "Batra"
      ],
      "year": "2016",
      "venue": "Diverse beam search: Decoding diverse solutions from neural sequence models",
      "arxiv": "arXiv:1610.02424"
    },
    {
      "citation_id": "31",
      "title": "A contrastive framework for neural text generation",
      "authors": [
        "Yixuan Su",
        "Tian Lan",
        "Yan Wang",
        "Dani Yogatama",
        "Lingpeng Kong",
        "Nigel Collier"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "32",
      "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
      "authors": [
        "Colin Raffel",
        "Noam Shazeer",
        "Adam Roberts",
        "Katherine Lee",
        "Sharan Narang",
        "Michael Matena",
        "Yanqi Zhou",
        "Wei Li",
        "Peter Liu"
      ],
      "year": "2020",
      "venue": "Journal of machine learning research"
    },
    {
      "citation_id": "33",
      "title": "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
      "authors": [
        "Mike Lewis",
        "Yinhan Liu",
        "Naman Goyal",
        "Marjan Ghazvininejad",
        "Abdelrahman Mohamed",
        "Omer Levy",
        "Veselin Stoyanov",
        "Luke Zettlemoyer"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "34",
      "title": "Cpt: A pre-trained unbalanced transformer for both chinese language understanding and generation",
      "authors": [
        "Yunfan Shao",
        "Zhichao Geng",
        "Yitao Liu",
        "Junqi Dai",
        "Hang Yan",
        "Fei Yang",
        "Zhe Li",
        "Hujun Bao",
        "Xipeng Qiu"
      ],
      "year": "2024",
      "venue": "Science China Information Sciences"
    }
  ]
}