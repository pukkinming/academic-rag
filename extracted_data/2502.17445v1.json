{
  "paper_id": "2502.17445v1",
  "title": "Interpretable Dual-Filter Fuzzy Neural Networks For Affective Brain-Computer Interfaces",
  "published": "2025-01-29T14:31:57Z",
  "authors": [
    "Xiaowei Jiang",
    "Yanan Chen",
    "Nikhil Ranjan Pal",
    "Yu-Cheng Chang",
    "Yunkai Yang",
    "Thomas Do",
    "Chin-Teng Lin"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Fuzzy logic provides a robust framework for enhancing explainability, particularly in domains requiring the interpretation of complex and ambiguous signals, such as braincomputer interface (BCI) systems. Despite significant advances in deep learning, interpreting human emotions remains a formidable challenge. In this work, we present iFuzzyAffectDuo, a novel computational model that integrates a dual-filter fuzzy neural network architecture for improved detection and interpretation of emotional states from neuroimaging data. The model introduces a new membership function (MF) based on the Laplace distribution, achieving superior accuracy and interpretability compared to traditional approaches. By refining the extraction of neural signals associated with specific emotions, iFuzzyAffectDuo offers a human-understandable framework that unravels the underlying decision-making processes. We validate our approach across three neuroimaging datasets using functional Near-Infrared Spectroscopy (fNIRS) and Electroencephalography (EEG), demonstrating its potential to advance affective computing. These findings open new pathways for understanding the neural basis of emotions and their application in enhancing human-computer interaction.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "E MOTIONS are fundamental to human existence, shaping diverse aspects of life and evolving over millions of years to form the cornerstone of social intelligence and group cohesion  [1] -  [3] . The ability to recognize and respond to emotional cues across varying contexts-such as how anger can enhance the detection of fear and vice versa-is crucial for survival and social functioning  [4] . Advances in neuroimaging have illuminated the neural pathways involved in processing affective stimuli, emphasizing the roles of appetitive and defensive systems rooted in primitive neural circuits  [5] . These systems coordinate responses ranging from attentional shifts Xiaowei Jiang, Yu-Cheng Chang, Thomas Do, and Chin-Teng Lin are with the GrapheneX-UTS Human-centric AI Centre, Australian AI Institute, School of Computer Science, Faculty of Engineering and Information Technology, University of Technology Sydney.\n\nYanan Chen and Yunkai Yang are with the Institute of Psychology and Behavior, Henan University.\n\nNikhil Ranjan Pal is with the Indian Statistical Institute, Kolkata, India This work was supported in part by the Australian Research Council (ARC) under discovery grant DP220100803 and DP250103612 and ITRH grant IH240100016, Australian National Health and Medical Research Council (NHMRC) Ideas Grant APP2021183, and the UTS Human-Centric AI Centre funding sponsored by  GrapheneX (2023 GrapheneX ( -2031)) . The research was also sponsored in part by the Humanities and Social Sciences project of Ministry of Education (22YJCZH021) and the Institute of Psychology, Chinese Academy of Sciences (Grant No. GJ202007).\n\n* Corresponding author: Chin-Teng Lin. Email: chin-teng.lin@uts.edu.au to physiological changes, highlighting their critical role in survival and the dynamic interplay between physiological states and psychological experiences  [6] -  [9] . Despite significant progress, mapping specific neural circuits to distinct emotions remains challenging, with only probabilistic patterns identified thus far  [8] . Understanding how the human brain processes emotions remains a priority, spurring the development of Affective Computing (AC) systems, particularly Affective Brain-Computer Interfaces (aBCIs). These systems aim to bridge the gap between human emotions and machine understanding by recognizing, interpreting, processing, and simulating emotional states across various modalities  [10] -  [13] .\n\nThe aBCIs system integrate data from diverse sources, including behavioral cues  [14] , peripheral nervous system (PNS) signals such as heart rate variability (HRV)  [15] , and central nervous system signals, including EEG  [16]  and fNIRS  [17] . These approaches offer a comprehensive perspective on the neural and physiological underpinnings of emotions  [18] . Recent advancements in aBCIs have demonstrated the effectiveness of Convolutional Neural Networks (ConvNets) for end-to-end emotional decoding from EEG data. For instance, EEGNet has set new benchmarks in performance  [19] , while the NLSTM model has showcased exceptional sensitivity and specificity across diverse EEG datasets, emphasizing its robustness and generalization capabilities in both controlled and real-world scenarios  [20] . Similarly, DBjNet has achieved remarkable decoding accuracy in distinguishing between negative and neutral emotions using fNIRS data  [21] . However, despite these advancements, the interpretability of these models remains a significant challenge, limiting the understanding of their decision-making processes and hindering their broader application in real-world contexts.\n\nAddressing this limitation, Fuzzy Neural Networks (FNNs) combine the adaptability of neural networks with the interpretability of fuzzy logic systems. FNNs leverage fuzzy rules and membership functions (MFs) to process inputs, providing an intuitive framework that contrasts sharply with the opacity of conventional deep learning models  [22] -  [24] . This transparency facilitates a clear understanding of how inputs are transformed into outputs, enhancing users' trust and interaction in aBCI systems  [25] -  [27] . FNNs have been successfully applied to pattern classification tasks  [28]  and extended to adaptively learn spatiotemporal knowledge through advanced architectures like Evolving Fuzzy Neural Networks (EFuNNs)  [29]  and the interpretable fuzzy transfer learning model (iFuzzyTL)  [26] .\n\nBuilding on this foundation, we introduce the Interpretable Dual-Filter Fuzzy Rule-Based Model for aBCIs (iFuzzyAffect-Duo), an evolution of the iFuzzyTL model originally designed for transfer learning in (Steady-state visually evoked potential) SSVEP-based EEG tasks. While iFuzzyTL demonstrate strong domain adaptation capabilities, it faces limitations in interpretability and complex pattern recognition due to the relatively simple neural patterns associated with SSVEP  [26] . iFuzzyAffectDuo overcomes these limitations by incorporating a dual-filter structure that combines spatial and temporal filters, inspired by EEGNet, to enhance feature extraction and pattern recognition  [30] , and transiting from Gaussian to Modified Laplace MFs, significantly improving performance.\n\nFurthermore, iFuzzyAffectDuo integrates a fuzzy attention mechanism, enabling the model to generalize central fuzzy rules while capturing domain-specific spatiotemporal dependencies in brain signals. This novel architecture supports robust feature extraction and excels in emotion classification tasks, making it particularly effective for aBCI applications  [31] ,  [32] . To validate its performance, we evaluate iFuzzyAffectDuo on three datasets: two fNIRS datasets (Picture Recognition and Picture Empathy) and one EEG dataset (FACED) for emotion recognition tasks. Experimental results demonstrate that iFuzzyAffectDuo achieves stateof-the-art accuracy and interpretability, effectively capturing affective neural patterns and advancing the performance of aBCI systems across both fNIRS and EEG modalities.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Ii. Methodology",
      "text": "",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "A. Fuzzy Inference Systems",
      "text": "Fuzzy Inference Systems (FISs) are widely used to model uncertainty and imprecision in various domains. A class of FIS, realized using neural architectures, is known as Fuzzy Neural networks (FNNs)  [22] , which generally use gradient descent optimization for training. This system uses the concept of membership, which quantifies the degree to which an element x belongs to a fuzzy set characterized by a membership function A(x). One prominent approach to fuzzy modeling is the Takagi-Sugeno-Kang (TSK) model  [33] , which utilizes a set of IF-THEN rules to define the relationship between inputs and outputs. For a Zero-th order TSK fuzzy system, the rules are expressed as:\n\nwhere\n\nvariables and A i,r ; i = 1, • • • , D are D fuzzy sets for the r th rule, which are defined by the membership functions\n\nThe firing strength µ r of the r th rule is typically computed as the product of the individual MFs, i.e.,\n\nThe final output of the TSK FIS is derived as:\n\nwhere R is the total number of rules, and y represents the aggregated output obtained through weighted aggregation of the rule outputs. If the system has multiple outputs, each rule will have multiple consequents.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "B. Enhancing Sensitivity To Scale Parameter With Modified-Laplace Membership Functions",
      "text": "Traditional Gaussian MFs often exhibit broad widths, which can lead to suboptimal feature representation within models  [25] . To mitigate this issue, we introduce a novel MF inspired by the Laplace Distribution, defined by:\n\nwhere m is the location parameter and b is the scale parameter. We modify this distribution as follows to better suit our fuzzy systems as Modified-Laplace MFs:\n\nwhere λ d is a width factor within the range of [0, +∞). Both λ d and m are trainable parameters. The firing strength µ r (x) in our TSK model is computed using the product of these Modified-Laplace MFs, following the eq. (  3 ):  The firing strength of a fuzzy rule in the TSK model, f M Li,r (x), is expressed as:",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "C. Sensitivity Analysis Of Modified-Laplace Membership Functions",
      "text": "To conduct the Sensitivity Analysis, we analyze the derivative of the Gaussian MFs with respect to the width parameter σ and the Modified-Laplace MF with respect to the width parameter λ to show how sensitive each MF is to changes in its respective width parameters.\n\nThe derivative of f G (x | m, σ) with respect to σ is given by:\n\nThe derivative of µ ML (x | m, λ) with respect to λ is given by:\n\nThe Gaussian MF is more sensitive to changes in its width parameter σ compared to the Modified-Laplace function's sensitivity to λ. This higher sensitivity arises because the Gaussian derivative scales with the square of the distance from the mean, (x -m) 2 , and inversely with σ 3 . In contrast, the ML derivative scales linearly with |x -m|. As a result, the Gaussian's sensitivity increases more rapidly as the input deviates from the mean and is more affected by small changes in σ.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "D. Ifuzzyaffectduo Main Structure",
      "text": "The proposed model, iFuzzyAffectDuo, is composed of three principal modules, as shown in Fig.  1(D ). The first is the Spatial Fuzzy Filter, which is designed to capture spatial patterns within the brain data. This filter facilitates the nuanced detection of region-specific neural activity, enabling a deeper understanding of spatial dynamics associated with emotional responses. The second module, the Temporal Fuzzy Filter, focuses on the dynamic aspects of brain signals. It identifies temporal patterns that correlate with emotional responses, adapting over time to changes in the emotional state of the subject.\n\nTo enhance information capture, we project x(t) using W V r as the value (representing Fuzzy Consequents), while the firing strength and membership degree are computed in the query space via the projection parameter W Q r . Following TSK fuzzy model, the output (Y r (t)) for rule r in these two proposed models is then expressed as:\n\nwhere Y r (t) is the output of the penultimate layer of the network. Both W Q r and W V r are of dimension D × D, where D is the dimension of the input. To ameliorate issues with gradient descent, we add a ln operation after Y r (t), which stabilizes the gradient flow by computing logarithms of probabilities.\n\nLastly, the Classifier, a single-layer linear network, links the outputs from the spatial and temporal filters to the output nodes. This configuration effectively integrates the processed signals into a structured format that is optimal for classification.\n\nThe classifier employs a Cross-Entropy loss L CE to measure the performance and guide the training process, which is defined as:\n\nwhere M is the number of classes, N is the number of samples, y o,c is the ground truth label for class c of the oth sample, and p o,c is the predicted probability for class c of the o-th sample.\n\nTogether, these modules form a cohesive system that not only classifies emotional states with improved accuracy but also provides insights into the underlying neural mechanisms.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Iii. Experiments And Results",
      "text": "A. Dataset The NIRScout 32×32 was used to record blood oxygenation at a sampling rate of 7.8125 Hz, covering the prefrontal cortex with a 20-channel setup. Data preprocessing and additional details can be found in  [34]  and  [25] . An example of these brain signals is shown in Fig.  1(A) .\n\n2) fNIRS Dataset 2: Picture Empathy: This dataset examined responses to empathy-inducing images across 180 female participants divided into groups of 90 for social and physiological empathy, approved by the Henan Province Key Laboratory of Psychology and Behavior (20200702002). Each session included eight blocks alternating between negative and neutral images, structured in an ABBA sequence to control for order effects. Ratings of perceived pain were recorded on a 1 to 9 Likert scale. The experiment setup and data processing were consistent with the Picture Recognition dataset.\n\n3) EEG Dataset 3: FACED: FACED involved eliciting emotional responses through 28 video clips(12 Negative videos, 12 Positive videos, and 4 Neutral videos). A total of 123 participants (average age 23.2 years) viewed videos varying in length while EEG data were collected. The analysis focused on the power spectral densities across five EEG frequency bands for 30-second epochs, generating 150 features per channel. Further methodological details are presented in  [35] .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "B. Comparative Analysis Of Other Models",
      "text": "This section presents a comparative analysis of the iFuzzyAffectDuo model against existing models such as DBJNet, EEGNET, NLSTM, and Transformer across three datasets, employing paired t-tests with two-sided alternative hypotheses and the False Discovery Rate Benjamini/Hochberg (FDR-BH) correction for multiple comparisons. The results, visualized in Fig.  3 , show that the iFuzzyAffectDuo model consistently outperforms the others. On the Picture Recognition dataset, it achieved an accuracy of 80.53% ± 1.55%, significantly higher than the compared models with p < 0.001. Similar superiority is observed in the FACED dataset with an accuracy of 77.19% ± 1.49%, and in the Picture Empathy dataset with 83.88% ± 3.04%, both also surpassing competing models at p < 0.001 levels. These findings illustrate the iFuzzyAffectDuo model's exceptional ability to manage and analyze diverse datasets, thereby asserting its versatility and effectiveness in complex machine learning landscapes, especially aBCI tasks. The consistently significant performance advantages across varied tasks not only validate the model's robust feature extraction and learning capabilities but also highlight its potential as a benchmark model in aBCI research.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "C. Comparison Of Modified-Laplace And Gaussian Membership Functions",
      "text": "In our comparative analysis using a model architecture with 5 rules, Modified-Laplace MFs consistently outperformed Gaussian MFs across various datasets. Specifically, within the FACED dataset, Modified-Laplace MFs achieved an accuracy of 77.19% ± 1.49%, significantly higher than the 74.55% ± 1.20% observed for Gaussian MFs, with a notable statistical difference (t(20) = 6.55, p < 0.001, Cohen ′ s d = 1.95). In the Picture Empathy dataset, Modified-Laplace MFs recorded 83.88%±3.04% accuracy, slightly outperforming the 82.92% ± 3.01% by Gaussian MFs (t(20) = 4.67, p < 0.001, Cohen ′ s d = 0.32). Finally, for the Picture Recognition task, Modified-Laplace MFs demonstrated 80.53% ± 1.55% accuracy, surpassing the 79.77% ± 2.11% achieved by Gaussian MFs (t(20) = 2.75, p < 0.05, Cohen ′ s d = 0.36). These findings underscore the effectiveness of Modified-Laplace MFs in enhancing classification accuracy across diverse settings.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "D. Fuzzy Set Membership And Feature Distribution Across Eeg Signals",
      "text": "The distributions of fuzzy set memberships depicted in Fig.  4  highlight the operational characteristics of Modified-Laplace MFs within the query space in FACED dataset. Notably, Channel 4 exhibits a broader diversity of rule centers (m), indicating a wide variation in feature representation. In contrast, Channel 11 demonstrates less diversity in rule centers, suggesting a more uniform feature response. Channel 30 reveals that while some rules appear similar, distinct patterns emerge, particularly between rules #1 and #5 versus rules #2, 3, and 4, underscoring the subtle complexities in neural processing across different EEG channels.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "E. Sample-Wise Interpretability Analysis",
      "text": "In the Picture Empathy dataset, to provide an intuitive illustration of how the fuzzy filter discerns picture types and elucidates the neural patterns of different empathy types from fNIRS data, we present four demonstrative samples from the top-performing model. These samples represent a 2 × 2 factorial design (Picture type: Neutral or Negative; Empathy type: Physiological or Social). From Table  I , it is evident that Rule #3 predominantly influences border firing strength in all four cases, while Rule #2 consistently plays a minor role. The learned patterns of channels show substantial variety across different rules. Notably, significant contributions are observed from several specific channels: Channel 11, which measures oxy-hemoglobin (HbO) in the Left Frontopolar Area (FPA); Channel 18, which measures deoxy-hemoglobin (HbR) in the Right Ventrolateral Prefrontal Cortex (VLPFC); Channel 5, which measures HbO in the Left Ventromedial Prefrontal Cortex (VmPFC); and Channel 3, which measures HbO in the VLPFC. These channels demonstrate significant contributions across the rules. Particularly, in cases where the Picture is Neutral and the Empathy is Physiological, channel 16 by Rule #5 and channel 20 by Rule #3 are highlighted. Channel 11 is highlighted by Rules #1 and #4, and Channel 18 also receives significant emphasis by these rules. All membership degrees and firing strengths for these cases are depicted in Fig.  5 . The demos for the decision-making processes in the Picture Recognition dataset are shown in Fig.  1 (E, F, G,  and H ). The orientation of the 3D Brain can be found in Fig.  1(C ).\n\nOverall, these findings highlight the nuanced roles of the prefrontal cortex (PFC) in modulating distinct empathetic responses, with heightened activity observed in response to affective cues, illustrating the intricate interplay between neural circuitry and emotional processing  [36] -  [39] .",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Iv. Conclusions",
      "text": "This study introduces iFuzzyAffectDuo, a novel Fuzzy logic-based model for aBCI tasks, utilizing fNIRS and EEG technologies. It advances interpretability in neural decoding, outperforming Gaussian MFs, CNN-based, and self-attention models in accuracy across two fNIRS and one EEG dataset. The Modified-Laplace distribution enhances the model's ability to detail neural activity patterns, making complex decisions understandable. The potential of iFuzzyAffectDuo extends to Functional Magnetic Resonance Imaging (fMRI) and Electrocorticography (ECoG) applications, potentially enriching theoretical frameworks in neuroscience. Future work will address the model's hyperparameter sensitivity and training duration, explore online testing, and integrate multi-modal technologies to broaden its application.",
      "page_start": 5,
      "page_end": 5
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Overview of the iFuzzyAffectDuo model and related components. (A) Example of the fNIRS signal recorded during exposure to affective stimuli,",
      "page": 2
    },
    {
      "caption": "Figure 2: Fig. 2. Modified-Laplace MFs m with different center parameters m and λ",
      "page": 3
    },
    {
      "caption": "Figure 1: (D). The first is",
      "page": 3
    },
    {
      "caption": "Figure 3: , show that the iFuzzyAffectDuo model",
      "page": 4
    },
    {
      "caption": "Figure 3: Comparative performance of the iFuzzyAffectDuo model against",
      "page": 4
    },
    {
      "caption": "Figure 4: highlight the operational characteristics of Modified-",
      "page": 5
    },
    {
      "caption": "Figure 5: The demos for the decision-making processes in the Picture",
      "page": 5
    },
    {
      "caption": "Figure 1: (E, F, G, and H). The",
      "page": 5
    },
    {
      "caption": "Figure 4: Dynamic Distribution of Fuzzy Set Membership and Feature Distributions Across the FACED Dataset at Key Time Intervals. This figure illustrates",
      "page": 6
    },
    {
      "caption": "Figure 5: Sample analysis: Visualization of membership degrees and firing",
      "page": 6
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Rule\nTop Channels with Strength\nTop1\nTop2\nTop3": "Picture: Neutral; Empathy: Physiological"
        },
        {
          "Rule\nTop Channels with Strength\nTop1\nTop2\nTop3": "1\n18: 0.26\n11: 0.25\n5: 0.19\n2\n12: 0.18\n1: 0.16\n4: 0.10\n3\n20: 0.96\n6: 0.96\n8: 0.87\n4\n11: 0.24\n18: 0.23\n3: 0.15\n5\n16: 0.94\n15: 0.91\n13: 0.87"
        },
        {
          "Rule\nTop Channels with Strength\nTop1\nTop2\nTop3": "Picture: Negative; Empathy: Physiological"
        },
        {
          "Rule\nTop Channels with Strength\nTop1\nTop2\nTop3": "1\n5: 0.29\n4: 0.27\n15: 0.26\n2\n1: 0.13\n8: 0.12\n16: 0.12\n3\n9: 0.91\n20: 0.69\n13: 0.62\n4\n12: 0.39\n6: 0.38\n11: 0.38\n5\n3: 0.85\n17: 0.78\n10: 0.72"
        },
        {
          "Rule\nTop Channels with Strength\nTop1\nTop2\nTop3": "Picture: Neutral; Empathy: Social"
        },
        {
          "Rule\nTop Channels with Strength\nTop1\nTop2\nTop3": "1\n18: 0.26\n17: 0.20\n15: 0.14\n2\n16: 0.09\n18: 0.09\n5: 0.09\n3\n3: 0.99\n11: 0.98\n19: 0.97\n4\n2: 0.39\n1: 0.37\n18: 0.16\n5\n9: 0.95\n10: 0.87\n15: 0.74"
        },
        {
          "Rule\nTop Channels with Strength\nTop1\nTop2\nTop3": "Picture: Negative; Empathy: Social"
        },
        {
          "Rule\nTop Channels with Strength\nTop1\nTop2\nTop3": "1\n18: 0.26\n12: 0.26\n14: 0.26\n2\n15: 0.14\n7: 0.14\n13: 0.14\n3\n9: 0.46\n13: 0.41\n10: 0.40\n4\n7: 0.23\n2: 0.20\n14: 0.20\n5\n3: 0.80\n5: 0.80\n8: 0.77"
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "II.-WHAT IS AN EMOTION ?",
      "authors": [
        "W James"
      ],
      "venue": "Mind"
    },
    {
      "citation_id": "2",
      "title": "Solving the emotion paradox: Categorization and the experience of emotion",
      "authors": [
        "L Barrett"
      ],
      "year": "2006",
      "venue": "Personality and Social Psychology Review"
    },
    {
      "citation_id": "3",
      "title": "A brief history of human society: The origin and role of emotion in social life",
      "authors": [
        "D Massey"
      ],
      "year": "2002",
      "venue": "American Sociological Review"
    },
    {
      "citation_id": "4",
      "title": "Social appraisal influences recognition of emotions",
      "authors": [
        "C Mumenthaler",
        "D Sander"
      ],
      "year": "2012",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "5",
      "title": "Emotion and Motivation: Attention, Perception, and Action",
      "authors": [
        "P Lang"
      ],
      "year": "2000",
      "venue": "Journal of Sport and Exercise Psychology"
    },
    {
      "citation_id": "6",
      "title": "[emotional stimuli: sensory processing and motor responses]",
      "authors": [
        "E Volchan",
        "M Pereira",
        "L Oliveira",
        "C Vargas",
        "J Mourão-Miranda",
        "T De Azevedo",
        "W Machado-Pinheiro",
        "L Pessoa"
      ],
      "year": "2003",
      "venue": "Revista brasileira de psiquiatria"
    },
    {
      "citation_id": "7",
      "title": "Looking at pictures: Affective, facial, visceral, and behavioral reactions",
      "authors": [
        "P Lang",
        "M Greenwald",
        "M Bradley",
        "A Hamm"
      ],
      "year": "1993",
      "venue": "Psychophysiology"
    },
    {
      "citation_id": "8",
      "title": "Emotional experience",
      "authors": [
        "A Toga"
      ],
      "year": "2015",
      "venue": "Brain Mapping: An Encyclopedic Reference"
    },
    {
      "citation_id": "9",
      "title": "Reciprocal influences between body and brain in the perception and expression of affect: A polyvagal perspective",
      "authors": [
        "S Porges"
      ],
      "year": "2008",
      "venue": "The healing power of emotion: Affective neuroscience, development & clinical practice"
    },
    {
      "citation_id": "10",
      "title": "Emotion recognition and artificial intelligence: A systematic review (2014-2023) and research recommendations",
      "authors": [
        "S Khare",
        "V Blanes-Vidal",
        "E Nadimi",
        "U Acharya"
      ],
      "year": "2024",
      "venue": "Information Fusion"
    },
    {
      "citation_id": "11",
      "title": "Recognition of human emotions using EEG signals: A review",
      "authors": [
        "M Rahman",
        "A Sarkar",
        "M Hossain",
        "M Hossain",
        "M Islam",
        "M Hossain",
        "J Quinn",
        "M Moni"
      ],
      "year": "2021",
      "venue": "Computers in Biology and Medicine"
    },
    {
      "citation_id": "12",
      "title": "Affective computing: A review",
      "authors": [
        "J Tao",
        "T Tan"
      ],
      "year": "2005",
      "venue": "Affective Computing and Intelligent Interaction"
    },
    {
      "citation_id": "13",
      "title": "Affective computing",
      "authors": [
        "R Picard"
      ],
      "year": "1997",
      "venue": "Affective computing"
    },
    {
      "citation_id": "14",
      "title": "Affective Computing and Sentiment Analysis",
      "authors": [
        "E Cambria",
        "D Das",
        "S Bandyopadhyay",
        "A Feraco"
      ],
      "year": "2017",
      "venue": "Affective Computing and Sentiment Analysis"
    },
    {
      "citation_id": "15",
      "title": "A survey of affective computing for stress detection: Evaluating technologies in stress detection for better health",
      "authors": [
        "S Greene",
        "H Thapliyal",
        "A Caban-Holt"
      ],
      "year": "2016",
      "venue": "IEEE Consumer Electronics Magazine"
    },
    {
      "citation_id": "16",
      "title": "4D attentionbased neural network for EEG emotion recognition",
      "authors": [
        "G Xiao",
        "M Shi",
        "M Ye",
        "B Xu",
        "Z Chen",
        "Q Ren"
      ],
      "year": "2022",
      "venue": "Cognitive Neurodynamics"
    },
    {
      "citation_id": "17",
      "title": "NEMO: A Database for Emotion Analysis Using Functional Near-Infrared Spectroscopy",
      "authors": [
        "M Spapé",
        "K Mäkelä",
        "T Ruotsalo"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "18",
      "title": "Affective Computing: Recent Advances, Challenges, and Future Trends",
      "authors": [
        "G Pei",
        "H Li",
        "Y Lu",
        "Y Wang",
        "S Hua",
        "T Li"
      ],
      "year": "2024",
      "venue": "Affective Computing: Recent Advances, Challenges, and Future Trends"
    },
    {
      "citation_id": "19",
      "title": "Convolutional neural network for emotional eeg decoding and visualization",
      "authors": [
        "J Lin",
        "L Li",
        "A Belkacem",
        "J Liang",
        "C Chen"
      ],
      "year": "2023",
      "venue": "Proceedings of the 2023 12th International Conference on Computing and Pattern Recognition"
    },
    {
      "citation_id": "20",
      "title": "Automatic seizure detection using fully convolutional nested lstm",
      "authors": [
        "Y Li",
        "Z Yu",
        "Y Chen",
        "C Yang",
        "Y Li",
        "X Li",
        "B Li"
      ],
      "year": "2020",
      "venue": "International Journal of Neural Systems"
    },
    {
      "citation_id": "21",
      "title": "Cross-Subject Emotion Recognition Brain-Computer Interface Based on fNIRS and DBJNet",
      "authors": [
        "X Si",
        "H He",
        "J Yu",
        "D Ming"
      ],
      "year": "2023",
      "venue": "Cyborg and Bionic Systems"
    },
    {
      "citation_id": "22",
      "title": "Neural fuzzy systems: a neuro-fuzzy synergism to intelligent systems",
      "authors": [
        "C.-T Lin",
        "C Lee"
      ],
      "year": "1996",
      "venue": "Neural fuzzy systems: a neuro-fuzzy synergism to intelligent systems"
    },
    {
      "citation_id": "23",
      "title": "Fuzzy centered explainable network for reinforcement learning",
      "authors": [
        "L Ou",
        "Y.-C Chang",
        "Y.-K Wang",
        "C.-T Lin"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Fuzzy Systems"
    },
    {
      "citation_id": "24",
      "title": "Neural-network-based fuzzy logic control and decision system",
      "authors": [
        "C.-T Lin",
        "C Lee"
      ],
      "year": "1991",
      "venue": "IEEE Transactions on Computers"
    },
    {
      "citation_id": "25",
      "title": "A Fuzzy-based Approach to Predict Human Interaction by Functional Near-Infrared Spectroscopy",
      "authors": [
        "X Jiang",
        "L Ou",
        "Y Chen",
        "N Ao",
        "Y.-C Chang",
        "T Do",
        "C.-T Lin"
      ],
      "venue": "A Fuzzy-based Approach to Predict Human Interaction by Functional Near-Infrared Spectroscopy"
    },
    {
      "citation_id": "26",
      "title": "iFuzzyTL: Interpretable Fuzzy Transfer Learning for SSVEP BCI System",
      "authors": [
        "X Jiang",
        "B Cao",
        "L Ou",
        "Y.-C Chang",
        "T Do",
        "C.-T Lin"
      ],
      "venue": "iFuzzyTL: Interpretable Fuzzy Transfer Learning for SSVEP BCI System"
    },
    {
      "citation_id": "27",
      "title": "An interpretable evolving fuzzy neural network based on self-organized direction-aware data partitioning and fuzzy logic neurons",
      "authors": [
        "P De Campos Souza",
        "E Lughofer",
        "A Guimaraes"
      ],
      "year": "2021",
      "venue": "Applied Soft Computing"
    },
    {
      "citation_id": "28",
      "title": "Fuzzy neural networks and neurocomputations",
      "authors": [
        "W Pedrycz"
      ],
      "year": "1993",
      "venue": "Fuzzy Sets and Systems"
    },
    {
      "citation_id": "29",
      "title": "Evolving fuzzy neural networks for supervised/unsupervised online knowledge-based learning",
      "authors": [
        "N Kasabov"
      ],
      "year": "2001",
      "venue": "IEEE Transactions on Systems, Man and Cybernetics"
    },
    {
      "citation_id": "30",
      "title": "EEGNet: A compact convolutional neural network for EEG-based brain-computer interfaces",
      "authors": [
        "V Lawhern",
        "A Solon",
        "N Waytowich",
        "S Gordon",
        "C Hung",
        "B Lance"
      ],
      "year": "2018",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "31",
      "title": "Tsception: Capturing temporal dynamics and spatial asymmetry from eeg for emotion recognition",
      "authors": [
        "Y Ding",
        "N Robinson",
        "S Zhang",
        "Q Zeng",
        "C Guan"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "32",
      "title": "A novel caps-eegnet combined with channel selection for eeg-based emotion recognition",
      "authors": [
        "K Chen",
        "H Jing",
        "Q Liu",
        "Q Ai",
        "L Ma"
      ],
      "year": "2023",
      "venue": "Biomedical Signal Processing and Control"
    },
    {
      "citation_id": "33",
      "title": "Recent advances in neuro-fuzzy system: A survey",
      "authors": [
        "K Shihabudheen",
        "G Pillai"
      ],
      "year": "2018",
      "venue": "Knowledge-Based Systems"
    },
    {
      "citation_id": "34",
      "title": "Inter-brain synchrony during interpersonal touch is associated with the remission of negative emotion",
      "authors": [
        "Y Chen",
        "N Ao",
        "X Jiang",
        "H Niu",
        "J Xu",
        "Y Yang",
        "F Du",
        "M Wang"
      ],
      "year": "2025",
      "venue": "PsyArXiv"
    },
    {
      "citation_id": "35",
      "title": "A large finer-grained affective computing eeg dataset",
      "authors": [
        "J Chen",
        "X Wang",
        "C Huang",
        "X Hu",
        "X Shen",
        "D Zhang"
      ],
      "year": "2023",
      "venue": "Scientific Data"
    },
    {
      "citation_id": "36",
      "title": "Functional atlas of emotional faces processing: a voxel-based meta-analysis of 105 functional magnetic resonance imaging studies",
      "authors": [
        "P Fusar-Poli",
        "A Placentino",
        "F Carletti",
        "P Landi",
        "P Allen",
        "S Surguladze",
        "F Benedetti",
        "M Abbamonte",
        "R Gasparotti",
        "F Barale"
      ],
      "year": "2009",
      "venue": "Journal of psychiatry and neuroscience"
    },
    {
      "citation_id": "37",
      "title": "Effects of prefrontal cortex damage on emotion understanding: Eeg and behavioural evidence",
      "authors": [
        "A Perry",
        "S Saunders",
        "J Stiso",
        "C Dewar",
        "J Lubell",
        "T Meling",
        "A.-K Solbakk",
        "T Endestad",
        "R Knight"
      ],
      "year": "2017",
      "venue": "Brain"
    },
    {
      "citation_id": "38",
      "title": "Adult clinical neuropsychology: lessons from studies of the frontal lobes",
      "authors": [
        "D Stuss",
        "B Levine"
      ],
      "year": "2002",
      "venue": "Annual review of psychology"
    },
    {
      "citation_id": "39",
      "title": "Functions of the frontal lobes: Relation to executive functions",
      "authors": [
        "D Stuss"
      ],
      "year": "2011",
      "venue": "Journal of the International Neuropsychological Society"
    }
  ]
}