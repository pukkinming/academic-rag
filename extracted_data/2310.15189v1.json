{
  "paper_id": "2310.15189v1",
  "title": "Towards Subject Agnostic Affective Emotion Recognition",
  "published": "2023-10-20T23:44:34Z",
  "authors": [
    "Amit Kumar Jaiswal",
    "Haiming Liu",
    "Prayag Tiwari"
  ],
  "keywords": [
    "Emotion recognition",
    "EEG",
    "Domain adaptation"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "This paper focuses on affective emotion recognition, aiming to perform in the subject-agnostic paradigm based on EEG signals. However, EEG signals manifest subject instability in subject-agnostic affective Brain-computer interfaces (aBCIs), which led to the problem of distributional shift. Furthermore, this problem is alleviated by approaches such as domain generalisation and domain adaptation. Typically, methods based on domain adaptation confer comparatively better results than the domain generalisation methods but demand more computational resources given new subjects. We propose a novel framework, meta-learning based augmented domain adaptation for subject-agnostic aBCIs. Our domain adaptation approach is augmented through meta-learning, which consists of a recurrent neural network, a classifier, and a distributional shift controller based on a sum-decomposable function. Also, we present that a neural network explicating a sum-decomposable function can effectively estimate the divergence between varied domains. The network setting for augmented domain adaptation follows meta-learning and adversarial learning, where the controller promptly adapts to new domains employing the target data via a few self-adaptation steps in the test phase. Our proposed approach is shown to be effective in experiments on a public aBICs dataset and achieves similar performance to state-of-the-art domain adaptation methods while avoiding the use of additional computational resources.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "The human emotional experience and the understanding of its intricate interplay can be a challenging task. Recent technological advancements in brain-computer interaction systems, specifically affective Brain-computer interfaces, have enabled the automatic identification of user emotions and facilitated a more humanised mode of interaction  [1, 2] . The electroencephalography (EEG) signal, in particular, has been utilised in subject-dependent emotion models to recognise user emotions, with both the training and test data derived from a single subject  [3, 4] . Despite the potential of EEG signals in aBCIs, their application is limited by the non-stationary nature of these signals and the structural variability among different subjects impose significant challenges in the development of subject-independent models. These models are often following the assumption of independent and identically distributed samples  1  and typically exhibit poor generalisation performance in practical aBCI applications due to the problem of domain shift  [5, 6, 7, 8, 9] . To address the problem of domain shift in subject-agnostic EEG-based emotion recognition, an emergent approach of Domain adaptation can be leveraged, which utilises data from both the source and target domains to enhance the adaptation performance. A key domain adaptation technique involves mapping the two distributions to a shared feature space, where they have identical marginal distributions. Despite its considerable success in subject-independent EEG-based emotion recognition  [8, 10, 9] , domain adaptation approaches can be computationally intensive and time-consuming, which poses a vexing challenge leading to suboptimal user experiences in real-world applications. To address this issue, the notion of domain generalisation has emerged, particularly in scenarios in which multiple source domains are accessible with a lack of unlabelled target samples. The subject-agnostic emotion recognition models can be constructed using domain generalisation techniques  [11, 12] . Nonetheless, given that there is no prior knowledge pertaining to the target domain during training, it becomes arduous for domain generalisation to achieve performance on par with that domain adaptation. A potential approach is to leverage adaptive subspace feature matching (ASFM), which pre-trains the primary model and utilises a limited number of test samples to adjust efficiently  [13] . While the ASFM approach can evade the time-consuming nature of adaptation, most of them necessitate the retention of both source and target domains in the test phase, which leads to additional storage requirements and reduces portability  [14] . Nevertheless, in real-world applications, the ability of an EEG-based affective model to rapidly adapt to different subjects while maintaining its portability is crucial.\n\nThis paper presents a novel framework, namely, meta-learning based augmented domain adaptation (MeLaDA) for subject-agnostic EEG-based emotion recognition. Unlike the traditional adaptive subspace feature matching (ASFM), MeLaDA only demands the target domain during the test phase. Therefore, MeLaDA can generate predictions more rapidly compared to domain adaptation and ASFM. Based on the viewpoint of real-world applications, MeLaDA is better suited to constructing emotion models for subject-agnostic aBCIs. The proposed meta-learning based augmented domain adaptation (MeLaDA) framework is implemented by formulating the equivalence of a network with a sum-decomposable structure to domain discrepancy metrics utilised in classical domain adaptation techniques such as maximum mean discrepancy  [15, 16]  or ‚Ñã-divergence  [17, 18] . Using our formulation, we present the MeLaDA framework, which incorporates a classifier, a feature extractor, and a sum-decomposable structure termed domain shift regulator. By leveraging the benefits of adversarial learning and meta-learning, the regulator facilitates the MeLaDA model's rapid generalisation to new domains by using the target data through a few self-adaptive steps during the test phase. The key contributions of our approach are three-fold:\n\n1. MeLaDA derives a pertinent approach to develop a subject-agnostic EEG-based emotion recognition model and a way to incorporate any type of domain discrepancy explicated by a sum-decomposable network.\n\n2. Our proposed framework is constructed to be portable and able to quickly adapt to various subjects for EEG-driven emotion recognition.\n\n3. We carried out extensive experiments on the publicly available EEG-based aBCIs dataset, SEED  2  . The results of the experiments indicate that our proposed approach outperforms domain generalisation methods. Moreover, our proposed approach, MeLaDA, exhibits comparable time and storage costs to domain generalisation methods.",
      "page_start": 1,
      "page_end": 3
    },
    {
      "section_name": "Motivation",
      "text": "The key motivation behind our MeLaDA framework is to simplify the estimation of domain shift by leveraging a basic network that only requires the target domain as input. This is in contrast to traditional domain adaptation approaches which compare the target domain with a specific source domain, requiring additional storage space for source data and complex methods such as generative adversarial network (GAN)  [19]  to represent domain shift during the test phase. These limitations make the practical application of domain adaptation approaches difficult in EEG-driven emotion recognition. However, in a multi-source scenario, we demonstrate that minimising the discrepancy between all pairwise domains is equivalent to minimising the discrepancy between each domain and an implicit domain. Moreover, we prove that any domain shift metrics can be represented theoretically by a network with a sum-decomposition form.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Prior Work",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Eeg-Based Emotion Recognition:",
      "text": "The inherent non-stationarity of EEG signals and variability across individuals, developing a subject-independent model for EEG-based emotion recognition using conventional machine learning methods is challenging. Recently, attention has been directed towards affective brain-computer interfaces  [1] , which explicated the concept of aBCIs by integrating affective factors into traditional brain-computer interfaces  [20] . Subsequently, there has been a focus on the application of aBCIs in EEG-based emotion recognition  [21]  which involves 15 participants who watched selected Chinese movie clips to elicit three emotions i.e., happy, neutral, and sad. They curated an EEG emotion recognition dataset called SEED, in which they recorded the EEG signals of the participants. Building upon the SEED dataset, researchers have made significant advancements in developing models for EEG-based emotion recognition, particularly in the context of subject-dependent models. To address this issue, researchers have turned their attention to domain adaptation and domain generalisation techniques for subject-independent EEG-based emotion recognition. Domain adaptation approaches primarily focus on reducing domain shift by minimising discrepancies between different domains using established metrics such as maximum mean discrepancy (MMD)  [15, 16, 22] , the Kullback-Leibler divergence  [23] , and ‚Ñã-divergence  [17] . Existing work  [21]  among varied domains that employed transfer component analysis  [15]  to minimise MMD  [24]  by constructing a kernel matrix, which led to the successful development of personalised EEG-based emotion models. Domain Adaptation and Domain Generalisation: Adversarial domain adaptation methods have gained significant attention and emerged as successful approaches across various application  [25, 26, 27] . These methods draw inspiration from the concept of GAN, which involves adversarial training to align the generated distribution with the real distribution. In the field of aBCIs, researchers have also embraced adversarial domain adaptation approaches with successful outcomes. For instance, the usage of domain-adversarial neural networks (DANN)  [28]  for EEG-based emotion recognition, in subject-independent models  [29] . Furthermore, the adoption of Wasserstein GAN  [30]  for domain adaptation (WGAN-DA) has been successfully utilised for facilitating subject-independent emotion recognition models  [31] . From the viewpoint of practical scenarios pertaining to aBCIs, each subject represents an individual domain. Domain adaptation (DA) approaches, although computationally intensive for new domains, have been commonly employed in aBCIs. However, domain generalisation techniques, which generalise to unseen target domains without requiring additional target domain data, have gained traction in aBCIs  [32] . The domain residual network (DResNet)  [33]  extends the structure of DANN  [28]  for subject-independent EEG-based vigilance estimation and emotion recognition, showcasing improved generalisation ability without target domain data. While domain adaptation methods often yield better results than domain generalisation techniques in aBCIs, an alternative approach called ASFM  [13]  has been adopted, which has been integrated into an EEG-based emotion recognition setting, referred to as Plug-and-Play domain adaptation framework  [34] .",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Meta-Learning:",
      "text": "The notion of meta-learning is to learn functional prior knowledge and involves episode-level learning  [35] , has gained significant traction, particularly in the context of domain generalisation. Meta-learning for domain generalisation (MLDG)  [36]  presented the first meta-learning strategy to domain generalisation. Subsequently, MetaReg  [37]  and Feature-Critic  [38]  were proposed to enhance the generalisation capability of the model by incorporating auxiliary losses during training. Unlike previous domain generalisation approaches that design specific models, meta-learning-based schemes focus on a model-agnostic training strategy that exposes the model to domain shifts during training.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Problem Formulation",
      "text": "We describe the key aspects of our problem that encompass a few components for our framework settings. The input space for EEG data is represented by ‚Ñ∞ ùêº , and the output space is represented by ‚Ñ∞ ùëÇ . A domain ùíü is described as a joint distribution P ‚Ñ∞ ùêº ‚Ñ∞ ùëÇ over the space ‚Ñ∞ ùêº √ó ‚Ñ∞ ùëÇ . As the distribution is subject to change due to various factors, we assume that it follows a distribution ùí´. However, it should be noted that domains are not directly observable, and we can only observe samples ùëÜ ùëñ of domains, where each ùëÜ ùëñ refers to a set of {‚Ñ∞ ùêº ùëñ , ‚Ñ∞ ùëÇùëñ }. The presence of inconsistency between domains may lead to a suboptimal generalisation capability. In order to address this issue, one approach is to employ a functional mapping ùí¨ that transforms one domain into another while minimising the divergence between the domains. The selection of a divergence loss function ùëë(‚Ä¢, ‚Ä¢) is typically necessary, as it considers the marginal or joint distribution. The ultimate selection of the optimal ùí¨ is determined by minimising the Equation  1 .\n\nThe utilisation of a functional ùí¨ ùëëùëé enables the transfer of various domains to a shared feature space, thereby ensuring that the model trained on ùí¨(ùëÜ) does not encounter any domain shift issue. This approach is known as alignment.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Shift-Independent Domain",
      "text": "In the context of multi-source domain adaptation or domain generalisation, a common approach to incorporate domain adaptation methods involves the concurrent minimisation of the divergence between each pair of source domains, as expressed by Equation  2 .\n\nUnder ideal circumstances, the alternative variation ‚àëÔ∏Ä . Figure  1  depicts that the simultaneous alignment of all pairwise domains can be regarded as aligning each individual domain with the shift-independent domain. Once the shift-independent domain is obtained, a network can be constructed to calculate the shift of the target domain, and utilise it to regulate the process of meta-learning based augmented domain adaptation. In the following sections, we will elaborate on the construction of this network.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Sum Decomposable Component",
      "text": "Permutation-invariant constraints are an essential criterion for a function to capture domain discrepancy, which implies that the arrangement or order of the source domain data should not impact the output. Extensive research has been conducted on this property in prior studies  [39, 40] . Typically, summation is commonly employed to enforce permutation invariance, leading to the concept of sum-decomposition.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "The Proposed Method",
      "text": "In accordance with the theoretical framework, our proposed approach, referred to as MeLaDA, integrates a sum-decomposable domain shift controller with the temporal multi-layer perceptron (MLP) network. The architecture, depicted in Figure  2 , consists of a feature extractor ùêπ (ùúÉ) and a classifier ùê∂(ùúë) as constituent components of the temporal MLP network. The domain shift controller ùê∑ ùê∂ (ùúî) utilises the features extracted by ùêπ (ùúÉ) to assess the dissimilarity between the current domain and the shift-independent domain. When applying this network for the classification of target domain data, ùê∑ ùê∂ propagates forward to compute the domain shift and subsequently propagates backward to fine-tune the feature extractor ùêπ . This behaviour resembles the actions of an intelligent controller who dynamically adjusts the network based on its performance in generating shift-independent features. Under the guidance of ùê∑ ùê∂ , the entire network exhibits the ability to generalise to unseen domains through meta-learning augmented domain adaptation. By leveraging the trained controller, the feature extractor effectively mitigates the domain shift present in the data from individual subjects. Consequently, data samples with identical emotion labels originating from diverse domains exhibit a comparable distribution within the shared space. The subsequent sections will outline the design principles for the domain shift controller and provide an overview of our training strategy.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Model",
      "text": "We describe our proposed modelling approach based on the aforementioned components.\n\nIn order to satisfy the permutation-invariance requirement of the domain shift controller, a straightforward approach is to incorporate a summation layer into a neural network, similar to the method employed by Feature-Critic  [38]  networks. The Feature-Critic (FC) network appends a summation layer to the end of a multi-layer perceptron, disregarding the external mapping ùúå defined in Definition 4.2. Consequently, it may not fully embody the characteristics of a domain shift controller. Furthermore, our experimental findings indicate that introducing adversarial elements to the network can enhance its capabilities. Specifically, we incorporate two gradient reversal layers (GRL)  [28]  before and after a two-layer MLP, followed by an additional layer to further augment its performance. The rationale behind incorporating GRL into the network draws inspiration from traditional methods used to represent domain discrepancy, such as MMD or adversarial-based approaches  [25, 27] . These methods share a common principle, which entails utilising the \"largest\" difference between two domains to depict their divergence. To imbue our network with the same capacity for simulating domain shift as these traditional methods, we introduce a novel divergence measure, akin to MMD and ‚Ñã-divergence, that we term maximum mean norm discrepancy (ùëÄ MND ).\n\n, where a function ùëî maps ùë• into a vector space.\n\nBased on Theorem 4.1, the selection of an implicit domain as the shift-independent domain is a viable approach to circumvent the need for direct domain comparison. The implicit domain choice aims to minimise the overall divergence, facilitating efficient optimisation. Consequently, our proposed objective function encompasses both minimisation and maximisation components, as indicated by Equation  4 ,\n\nwhere the loss function of the controller's output is represented by ‚Ñí ùëê . Within the domain shift controller framework, the function ùëî corresponds to the inner mapping ùúì in Equation  2 and is represented by the initial layers of the network. The subsequent summation layer calculates the mean value of ùëî(ùë•), while the final layer of the domain shift controller computes the norm of the difference. To address the maximisation and minimisation objectives, we employ the method proposed by GAN  [19] , which involves the inclusion of gradient reversal layers in the controller network. During forward propagation, the GRL operates as an identity map, but during backward propagation, it reverses the direction of gradients. In contrast to the domain adaptation regulariser utilised in domain-adversarial networks  [25] , our domain shift controller incorporates an additional minimisation task. Consequently, two GRL layers are employed, the left GRL facilitates the controller into identifying the most significant domain difference, while the right GRL adjusts the feature extractor to generate consistent features across varied domains.\n\nIt is worth noting that the two gradient reversal layers structure may exhibit instability during experiments. To mitigate this, we employ a strategy where we freeze a portion of the network between the two GRL layers once a predefined iteration threshold is reached, ensuring stability in the training process.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Meta-Learning Based Training Strategy",
      "text": "In this section, we present a meta-learning based strategy for the parameter learning process.\n\nIn order to ensure the domain shift controller's ability for generalisation, we formulate the algorithmic approach for training settings. The overall algorithm can be divided into two distinct components, the training of the domain shift controller and the training of the network. These components are delineated in Algorithm 1 and Algorithm 2, respectively.\n\nTraining Procedure for the Domain Shift Controller: In order to augment the model's capability for generalisation, we adopt a two-fold approach that involves optimising the output ‚Ñí ùëê of the domain shift controller to mitigate domain shift, while simultaneously incorporating meta-learning to facilitate the generalisation process. Initially, the available domains are randomly divided into meta-train domains denoted as ùëÜ train and meta-test domains, alternatively referred to as meta-validation domains, denoted as ùëÜ valid . The controller is leveraged to optimise the feature extractor ùêπ (ùúÉ) specifically on the meta-train domains. Subsequently, we assess the efficacy of the optimised feature extractor ùêπ (ùúÉ ‚Ä≤ ) on the meta-test domains, evaluating its performance and ability to generalise beyond the trained domains. After updating the parameter ùúÉ to ùúÉ ‚Ä≤ , the classification loss function, represented by ‚Ñì, undergoes a transformation from ‚Ñì(ùë• ùëñ , ùë¶ ùëñ ; ùúÉ) to ‚Ñì(ùë• ùëñ , ùë¶ ùëñ ; ùúÉ ‚Ä≤ ). Inspired by the approach developed in Feature-critic networks  [38] , we establish the meta loss function as depicted in Equation  5 .\n\nThe overall loss for updating the parameter ùúî is expressed as depicted in Equation  6 .\n\n‚Ñí ùê∂ (ùúÉ, ùúë, ùúî; ùëÜ train ) + ùúÜ‚Ñí meta (ùúÉ ‚Ä≤ , ùúë, ùúî; ùëÜ valid )\n\nThe hyperparameter ùúÜ, as well as the parameters ùúÉ, ùúë, and ùúî corresponding to ùêπ , ùê∂, and ùê∑ ùê∂ respectively, are involved in Equation  6 . Through the optimisation of Equation  6 , the parameter ùúî of ùê∑ ùê∂ (ùúî) is ultimately updated accordingly.\n\nTraining Procedure for the MeLaDA framework: In contrast to the training approach employed by MetaReg  [37]  or Feature-Critic networks  [38] , which involves training the auxiliary network before training the task network, our proposed method MeLaDA adopts an alternative training scheme for the domain shift controller and temporal MLP network. This is necessary because the controller network ùê∑ ùê∂ needs to remain functional during the test phase, requiring continuous updates even while other parts of the network are being trained. Additionally, to fully adhere to the principles of meta-learning, we leverage the model-agnostic meta-learning (MAML)  [35]  framework to train the network, rather than directly optimising it. We treat the domain shift controller and classification as two distinct tasks and utilise episodic training  [42]  to update their respective parameters. The dataset is divided into two subsets, ùëÜ train (meta-train domains) and ùëÜ valid (meta-validation domains). The domain shift controller, ùê∑ ùê∂ , utilises data from ùëÜ train to compute the domain shift loss, ‚Ñí ùê∂ (ùúÉ, ùúî; ùëÜ train ), as well as the classification loss, ‚Ñí train classif . These losses are then used to update the parameters of the feature extractor, ùêπ (ùúÉ). Subsequently, with the updated parameters, ùêπ (ùúÉ ‚Ä≤ ), processes data from ùëÜ valid , and the temporal MLP network computes the corresponding classification loss, ‚Ñí valid classif . The overall loss function for optimising ùêπ (ùúÉ) and ùê∂(ùúë) is defined as follows\n\nThe introduction of MeLaDA adopts an alignment-based domain adaptation perspective. However, an alternative explanation of this method can be provided through the lens of metalearning. Recent domain generalisation approaches  [36]  suggest that meta-learning involves linking various tasks by aligning their gradients in a shared direction. In our scenario, the domain shift controller task is deliberately designed to be coupled with the \"domain generalisation\" process. Consequently, when the model encounters a new domain, the optimisation objective of adapting to this domain aligns with the optimisation objective propelled by the controller.",
      "page_start": 8,
      "page_end": 10
    },
    {
      "section_name": "Experiments",
      "text": "",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Dataset And Feature Extraction",
      "text": "In our evaluation of the MeLaDA framework, we employ the SEED dataset  [21]  which was created for emotion recognition and aBCIs using EEG signals. This dataset encompasses EEG signals collected from 15 subjects who were enlisted to watch carefully curated 4 minutes of film clips. These clips were specifically chosen to elicit one of three distinct emotions which are happiness, neutrality, and sadness. Each subject have been subjected to an experiment 3 times in intervals of one week. During the selection process of film clips, stringent criteria were applied to ensure that each clip was well-edited, enabling the creation of coherent emotion elicitation while maximising emotional significance. The EEG signals were recorded using the ESI NeuroScan system, employing a 62-electrode headset. The sampling rate for the signals was set at 1000 Hz. By utilising the SEED dataset, we were able to assess the performance and effectiveness of our MeLaDA approach in the context of emotion recognition. The dataset's comprehensive nature and carefully designed stimuli provide a valuable resource for training, testing, and validating algorithms and models aimed at understanding and interpreting emotions from EEG signals. The feature extraction process follows the similar strategies by deep belief networks for EEG-driven emotion recognition  [21] . Given that the SEED dataset has already undergone preprocessing, we are able to directly extract the features. Specifically, we employ the differential entropy feature  [43] , which has been previously shown to be effective for EEG-based emotion recognition in several studies  [21, 44] . Existing work  [45]  have demonstrated that the differential entropy feature corresponds to the logarithmic spectral energy of a fixed-length EEG sequence within a specific frequency band. To obtain the spectral energy, we apply the short-time Fourier transform using a non-overlapping Hanning window of 1 second to the EEG signal, considering five frequency bands, which are ùõø ranging from 1 Hz to 3 Hz, ùúÉ from 4 Hz to 7 Hz, ùõº from 8 Hz to 13 Hz, ùõΩ from 14 Hz to 30 Hz, and ùõæ from 31 Hz to 50 Hz. Subsequently, we compute the differential entropy feature. Considering the inherent dynamism observed in EEG-based emotion recognition tasks, we integrate the linear dynamic system methodology to effectively filter the differential entropy feature. Each sample has a dimension of 310 (62 channels √ó 5 frequency bands). Since the EEG data consist of time series, we resample the feature with a time-step of 15 and a 1-second overlap, resulting in 3184 samples per subject.",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "Parameter And Implementation Settings",
      "text": "In line with the Plug-and-play (PnP) approach  [34] , we have adopted the leave-one-subject-out (LOSO) strategy to assess the generalisation capability of the MeLaDA framework. For each iteration, one subject is selected as the target, while the remaining 14 subjects are used to train our model. During the test phase, the prediction results obtained after 10 steps of self-adaptation are utilised. The feature extractor component of MeLaDA consists of a two-layer LSTM network with an output dimension of 256 and a time step of 15. The classifier is implemented as a two-layer MLP with a hidden size of 100. Both the temporal MLP network and the domain shift controller undergo optimisation using the Adam optimizer with a learning rate of 0.0002 and a weight decay of 0.0001. The parameter ùúÜ is assigned a value of 0.1. Initially, the temporal MLP network is pre-trained until it achieves an accuracy of over 85% on the training set. Subsequently, MeLaDA is employed to jointly train the domain shift controller and the temporal MLP network. The threshold for freezing a portion of the controller within the gradient reversal layers is set to 40, and the maximum number of iterations is set to 200.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Results And Discussion",
      "text": "To assess the efficacy of our proposed MeLaDA framework, we employ the leave-one-subjectout cross-validation evaluation scheme and conduct a comparative analysis between MeLaDA and various domain adaptation and domain generalisation approaches using the SEED dataset. The evaluation results, comprising the mean accuracy (MA) and standard deviation (SD), are presented in Table  1 . In contrast to the baseline approach, which involves aggregating data from all source domains and training a single model using the support vector machine (SVM), all the evaluated methods exhibit a significant improvement in accuracy of at least 13%. Notably, MeLaDA surpasses all domain generalisation methods in terms of performance. When compared to the domain adaptation methods, MeLaDA still achieves commendable results. Although WGAN-DA  [31]  and Plug-and-Play method  [34]  exhibit marginally higher accuracy than MeLaDA. It should be noted that WGAN-DA requires all source domains and the Plug-and-Play method necessitates the utilisation of a subset of domains for adaptation, thereby limiting the fast generalisation capability of PnP method. It is important to note that our proposed method, being an implementation of a meta-learning strategy, achieves a superior accuracy compared to MLDG  [36]  and Feature-Critic  [38]  by approximately 7% and 6% respectively. These results indicate that MLDG, which directly employs episodic training to generalise the model is insufficient in effectively addressing the subject variability inherent in EEG-based emotion recognition.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Models",
      "text": "",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Da",
      "text": "Models DG MA SD MA SD SVM  [46]  0.567 0.16 ---TCA  [46]  0.640 0.15 MLDG  [36]  0.795 0.12 TPT  [46]  0.752 0.13 FC  [38]  0.806 0.12 DAN  [29]  0.838 0.08 DICA  [33]  0.7 0.08 DANN  [29]  0.792 0.13 DResNet  [33]  0.853 0.08 WGAN-DA  [31]  0.871 0.07 PnP  [34]  0.854 0.07 MeLaDA (Ours) 0.864 0.09 MeLaDA 0.864 0.09",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Table 1",
      "text": "The mean accuracy and standard deviation for both domain adaptation (DA) and domain generalisation (DG) are reported with comparative baseline methods on the SEED dataset.\n\nSimilarly, the Feature-Critic network, despite utilising a sum-decomposable MLP to simulate domain shift during the training phase, does not lead to a significant improvement in the results. This suggests that the application of a domain shift controller during the testing phase proves to be beneficial. As an augmented domain adaptation method, MeLaDA demonstrates the capability to predict any target set with only a few steps of self-adaptation, thereby leveraging the advantages of both domain adaptation and domain generalisation. Also, we examine the",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Conclusion",
      "text": "In this study, we present an augmented domain adaptation approach, MeLaDA for dealing with a subject-agnostic model for EEG-based emotion recognition without the need for source domain data in the test phase. Our proposed approach adopted a sum-decomposable domain shift controller to facilitate augmented domain adaptation. By integrating adversarial learning and meta-learning techniques, MeLaDA demonstrates the ability to generalise to new domains with minimal self-adaptive iterations. Experimental results conducted on the SEED dataset showcase the superiority of MeLaDA over traditional domain generalisation methods in terms of performance. This highlights the suitability of MeLaDA for constructing subject-agnostic affective models, surpassing conventional domain adaptation, domain generalisation, and ASFM methods.",
      "page_start": 13,
      "page_end": 13
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: The schematic representation of the overall dissimilarity among pairwise domains, as well as",
      "page": 5
    },
    {
      "caption": "Figure 1: depicts that the simultaneous alignment of all pairwise domains can be regarded as",
      "page": 5
    },
    {
      "caption": "Figure 2: , consists of a feature extractor ùêπ(ùúÉ) and",
      "page": 6
    },
    {
      "caption": "Figure 2: An overview of the proposed MeLaDA framework. The operational procedure of our framework",
      "page": 7
    },
    {
      "caption": "Figure 3: Results of self-adaptation with the left subplot delineating the test accuracy of MeLaDA",
      "page": 12
    },
    {
      "caption": "Figure 3: demonstrates the self-adaptation capabilities of MeLaDA when confronted",
      "page": 12
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Models": "-",
          "DA\nMA\nSD": "0.567\n0.16",
          "DG\nMA\nSD": "-\n-"
        },
        {
          "Models": "MLDG [36]",
          "DA\nMA\nSD": "0.640\n0.15",
          "DG\nMA\nSD": "0.795\n0.12"
        },
        {
          "Models": "FC [38]",
          "DA\nMA\nSD": "0.752\n0.13",
          "DG\nMA\nSD": "0.806\n0.12"
        },
        {
          "Models": "DICA [33]",
          "DA\nMA\nSD": "0.838\n0.08",
          "DG\nMA\nSD": "0.7\n0.08"
        },
        {
          "Models": "DResNet [33]",
          "DA\nMA\nSD": "0.792\n0.13",
          "DG\nMA\nSD": "0.853\n0.08"
        },
        {
          "Models": "PnP [34]",
          "DA\nMA\nSD": "0.871\n0.07",
          "DG\nMA\nSD": "0.854\n0.07"
        },
        {
          "Models": "MeLaDA",
          "DA\nMA\nSD": "0.864\n0.09",
          "DG\nMA\nSD": "0.864\n0.09"
        }
      ],
      "page": 12
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "A survey of affective brain computer interfaces: principles, state-of-the-art, and challenges",
      "authors": [
        "C M√ºhl",
        "B Allison",
        "A Nijholt",
        "G Chanel"
      ],
      "year": "2014",
      "venue": "Brain-Computer Interfaces"
    },
    {
      "citation_id": "2",
      "title": "Brain-machine interfaces from motor to mood",
      "authors": [
        "M Shanechi"
      ],
      "year": "2019",
      "venue": "Nature neuroscience"
    },
    {
      "citation_id": "3",
      "title": "Feature extraction and selection for emotion recognition from eeg",
      "authors": [
        "R Jenke",
        "A Peer",
        "M Buss"
      ],
      "year": "2014",
      "venue": "IEEE Transactions on Affective computing"
    },
    {
      "citation_id": "4",
      "title": "A systematic review on affective computing: Emotion models, databases, and recent advances",
      "authors": [
        "Y Wang",
        "W Song",
        "W Tao",
        "A Liotta",
        "D Yang",
        "X Li",
        "S Gao",
        "Y Sun",
        "W Ge",
        "W Zhang"
      ],
      "year": "2022",
      "venue": "Information Fusion"
    },
    {
      "citation_id": "5",
      "title": "Covariate shift adaptation by importance weighted cross validation",
      "authors": [
        "M Sugiyama",
        "M Krauledat",
        "K.-R M√ºller"
      ],
      "year": "2007",
      "venue": "Journal of Machine Learning Research"
    },
    {
      "citation_id": "6",
      "title": "Transferring subspaces between subjects in brain-computer interfacing",
      "authors": [
        "W Samek",
        "F Meinecke",
        "K.-R M√ºller"
      ],
      "year": "2013",
      "venue": "IEEE Transactions on Biomedical Engineering"
    },
    {
      "citation_id": "7",
      "title": "Making brain-machine interfaces robust to future neural variability",
      "authors": [
        "D Sussillo",
        "S Stavisky",
        "J Kao",
        "S Ryu",
        "K Shenoy"
      ],
      "year": "2016",
      "venue": "Nature communications"
    },
    {
      "citation_id": "8",
      "title": "Improving eeg-based emotion classification using conditional transfer learning",
      "authors": [
        "Y.-P Lin",
        "T.-P Jung"
      ],
      "year": "2017",
      "venue": "Frontiers in human neuroscience"
    },
    {
      "citation_id": "9",
      "title": "Cross-subject eeg-based emotion recognition through neural networks with stratified normalization",
      "authors": [
        "J Fdez",
        "N Guttenberg",
        "O Witkowski",
        "A Pasquali"
      ],
      "year": "2021",
      "venue": "Frontiers in neuroscience"
    },
    {
      "citation_id": "10",
      "title": "Domain adaptation techniques for eeg-based emotion recognition: a comparative study on two public datasets",
      "authors": [
        "Z Lan",
        "O Sourina",
        "L Wang",
        "R Scherer",
        "G M√ºller-Putz"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems"
    },
    {
      "citation_id": "11",
      "title": "Eegbased emotion recognition using spatial-temporal representation via bi-gru",
      "authors": [
        "W.-C Lew",
        "D Wang",
        "K Shylouskaya",
        "Z Zhang",
        "J.-H Lim",
        "K Ang",
        "A.-H Tan"
      ],
      "year": "2020",
      "venue": "2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)"
    },
    {
      "citation_id": "12",
      "title": "A domain adversarial graph attention model for subject independent eeg-based emotion recognition",
      "authors": [
        "T Xu",
        "W Dang",
        "J Wang",
        "Y Zhou"
      ],
      "year": "2022",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "13",
      "title": "A fast, efficient domain adaptation technique for cross-domain electroencephalography (eeg)-based emotion recognition",
      "authors": [
        "X Chai",
        "Q Wang",
        "Y Zhao",
        "Y Li",
        "D Liu",
        "X Liu",
        "O Bai"
      ],
      "year": "2017",
      "venue": "Sensors"
    },
    {
      "citation_id": "14",
      "title": "Multi-source domain transfer discriminative dictionary learning modeling for electroencephalogram-based emotion recognition",
      "authors": [
        "X Gu",
        "W Cai",
        "M Gao",
        "Y Jiang",
        "X Ning",
        "P Qian"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Computational Social Systems"
    },
    {
      "citation_id": "15",
      "title": "Domain adaptation via transfer component analysis",
      "authors": [
        "S Pan",
        "I Tsang",
        "J Kwok",
        "Q Yang"
      ],
      "year": "2011",
      "venue": "Domain adaptation via transfer component analysis"
    },
    {
      "citation_id": "16",
      "title": "Deep transfer learning with joint adaptation networks",
      "authors": [
        "M Long",
        "H Zhu",
        "J Wang",
        "M Jordan"
      ],
      "year": "2017",
      "venue": "International conference on machine learning"
    },
    {
      "citation_id": "17",
      "title": "A theory of learning from different domains",
      "authors": [
        "S Ben-David",
        "J Blitzer",
        "K Crammer",
        "A Kulesza",
        "F Pereira",
        "J Vaughan"
      ],
      "year": "2010",
      "venue": "Machine learning"
    },
    {
      "citation_id": "18",
      "title": "On learning invariant representations for domain adaptation",
      "authors": [
        "H Zhao",
        "R Des Combes",
        "K Zhang",
        "G Gordon"
      ],
      "year": "2019",
      "venue": "International conference on machine learning"
    },
    {
      "citation_id": "19",
      "title": "Generative adversarial networks",
      "authors": [
        "I Goodfellow",
        "J Pouget-Abadie",
        "M Mirza",
        "B Xu",
        "D Warde-Farley",
        "S Ozair",
        "A Courville",
        "Y Bengio"
      ],
      "year": "2020",
      "venue": "Communications of the ACM"
    },
    {
      "citation_id": "20",
      "title": "Context-aware brain-computer interfaces: exploring the information space of user, technical system and environment",
      "authors": [
        "T Zander",
        "S Jatzev"
      ],
      "year": "2011",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "21",
      "title": "Investigating critical frequency bands and channels for eeg-based emotion recognition with deep neural networks",
      "authors": [
        "W.-L Zheng",
        "B.-L Lu"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on autonomous mental development"
    },
    {
      "citation_id": "22",
      "title": "Visual domain adaptation with manifold embedded distribution alignment",
      "authors": [
        "J Wang",
        "W Feng",
        "Y Chen",
        "H Yu",
        "M Huang",
        "P Yu"
      ],
      "year": "2018",
      "venue": "Proceedings of the 26th ACM international conference on Multimedia"
    },
    {
      "citation_id": "23",
      "title": "Supervised representation learning: Transfer learning with deep autoencoders",
      "authors": [
        "F Zhuang",
        "X Cheng",
        "P Luo",
        "S Pan",
        "Q He"
      ],
      "year": "2015",
      "venue": "Twenty-fourth international joint conference on artificial intelligence"
    },
    {
      "citation_id": "24",
      "title": "A kernel method for the two-sample-problem",
      "authors": [
        "A Gretton",
        "K Borgwardt",
        "M Rasch",
        "B Sch√∂lkopf",
        "A Smola"
      ],
      "year": "2006",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "25",
      "title": "Unsupervised domain adaptation by backpropagation, in: International conference on machine learning",
      "authors": [
        "Y Ganin",
        "V Lempitsky"
      ],
      "year": "2015",
      "venue": "PMLR"
    },
    {
      "citation_id": "26",
      "title": "Adversarial discriminative domain adaptation",
      "authors": [
        "E Tzeng",
        "J Hoffman",
        "K Saenko",
        "T Darrell"
      ],
      "year": "2017",
      "venue": "Adversarial discriminative domain adaptation"
    },
    {
      "citation_id": "27",
      "title": "Wasserstein distance guided representation learning for domain adaptation",
      "authors": [
        "J Shen",
        "Y Qu",
        "W Zhang",
        "Y Yu"
      ],
      "year": "2018",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "28",
      "title": "Domain-adversarial training of neural networks",
      "authors": [
        "Y Ganin",
        "E Ustinova",
        "H Ajakan",
        "P Germain",
        "H Larochelle",
        "F Laviolette",
        "M Marchand",
        "V Lempitsky"
      ],
      "year": "2016",
      "venue": "The journal of machine learning research"
    },
    {
      "citation_id": "29",
      "title": "Cross-subject emotion recognition using deep adaptation networks",
      "authors": [
        "H Li",
        "Y.-M Jin",
        "W.-L Zheng",
        "B.-L Lu"
      ],
      "year": "2018",
      "venue": "Neural Information Processing: 25th International Conference"
    },
    {
      "citation_id": "30",
      "title": "Wasserstein generative adversarial networks",
      "authors": [
        "M Arjovsky",
        "S Chintala",
        "L Bottou"
      ],
      "year": "2017",
      "venue": "International conference on machine learning"
    },
    {
      "citation_id": "31",
      "title": "Wgan domain adaptation for eeg-based emotion recognition",
      "authors": [
        "Y Luo",
        "S.-Y Zhang",
        "W.-L Zheng",
        "B.-L Lu"
      ],
      "year": "2018",
      "venue": "Neural Information Processing"
    },
    {
      "citation_id": "32",
      "title": "Generalizing to unseen domains: A survey on domain generalization",
      "authors": [
        "J Wang",
        "C Lan",
        "C Liu",
        "Y Ouyang",
        "T Qin",
        "W Lu",
        "Y Chen",
        "W Zeng",
        "P Yu"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Knowledge and Data Engineering"
    },
    {
      "citation_id": "33",
      "title": "Reducing the subject variability of eeg signals with adversarial domain generalization",
      "authors": [
        "B.-Q Ma",
        "H Li",
        "W.-L Zheng",
        "B.-L Lu"
      ],
      "year": "2019",
      "venue": "Neural Information Processing: 26th International Conference"
    },
    {
      "citation_id": "34",
      "title": "Plug-and-play domain adaptation for cross-subject eeg-based emotion recognition",
      "authors": [
        "L.-M Zhao",
        "X Yan",
        "B.-L Lu"
      ],
      "year": "2021",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "35",
      "title": "Model-agnostic meta-learning for fast adaptation of deep networks",
      "authors": [
        "C Finn",
        "P Abbeel",
        "S Levine"
      ],
      "year": "2017",
      "venue": "International conference on machine learning"
    },
    {
      "citation_id": "36",
      "title": "Learning to generalize: Meta-learning for domain generalization",
      "authors": [
        "D Li",
        "Y Yang",
        "Y.-Z Song",
        "T Hospedales"
      ],
      "year": "2018",
      "venue": "Proceedings of the AAAI conference on artificial intelligence"
    },
    {
      "citation_id": "37",
      "title": "Towards domain generalization using meta-regularization",
      "authors": [
        "Y Balaji",
        "S Sankaranarayanan",
        "R Chellappa",
        "Metareg"
      ],
      "year": "2018",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "38",
      "title": "Feature-critic networks for heterogeneous domain generalization",
      "authors": [
        "Y Li",
        "Y Yang",
        "W Zhou",
        "T Hospedales"
      ],
      "year": "2019",
      "venue": "International Conference on Machine Learning"
    },
    {
      "citation_id": "39",
      "title": "Deep sets, Advances in neural information processing systems",
      "authors": [
        "M Zaheer",
        "S Kottur",
        "S Ravanbakhsh",
        "B Poczos",
        "R Salakhutdinov",
        "A Smola"
      ],
      "year": "2017",
      "venue": "Deep sets, Advances in neural information processing systems"
    },
    {
      "citation_id": "40",
      "title": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space",
      "authors": [
        "C Qi",
        "L Yi",
        "H Su",
        "L Guibas"
      ],
      "year": "2017",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "41",
      "title": "On the limitations of representing functions on sets",
      "authors": [
        "E Wagstaff",
        "F Fuchs",
        "M Engelcke",
        "I Posner",
        "M Osborne"
      ],
      "year": "2019",
      "venue": "International Conference on Machine Learning"
    },
    {
      "citation_id": "42",
      "title": "Episodic training for domain generalization",
      "authors": [
        "D Li",
        "J Zhang",
        "Y Yang",
        "C Liu",
        "Y.-Z Song",
        "T Hospedales"
      ],
      "year": "2019",
      "venue": "Proceedings of the IEEE/CVF International Conference on Computer Vision"
    },
    {
      "citation_id": "43",
      "title": "Differential entropy feature for eeg-based emotion classification",
      "authors": [
        "R.-N Duan",
        "J.-Y Zhu",
        "B.-L Lu"
      ],
      "year": "2013",
      "venue": "2013 6th International IEEE/EMBS Conference on Neural Engineering (NER)"
    },
    {
      "citation_id": "44",
      "title": "Identifying stable patterns over time for emotion recogni-tion from eeg",
      "authors": [
        "W.-L Zheng",
        "J.-Y Zhu",
        "B.-L Lu"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "45",
      "title": "Differential entropy feature for eeg-based vigilance estimation",
      "authors": [
        "L.-C Shi",
        "Y.-Y Jiao",
        "B.-L Lu"
      ],
      "year": "2013",
      "venue": "2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)"
    },
    {
      "citation_id": "46",
      "title": "Personalizing eeg-based affective models with transfer learning",
      "authors": [
        "W.-L Zheng",
        "B.-L Lu"
      ],
      "year": "2016",
      "venue": "Proceedings of the twenty-fifth international joint conference on artificial intelligence"
    }
  ]
}