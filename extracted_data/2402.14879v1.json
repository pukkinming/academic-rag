{
  "paper_id": "2402.14879v1",
  "title": "Driving Generative Agents With Their Personality",
  "published": "2024-02-21T21:29:57Z",
  "authors": [
    "Lawrence J. Klinkert",
    "Stephanie Buongiorno",
    "Corey Clark"
  ],
  "keywords": [
    "Large Language Models",
    "chatGPT",
    "psychometrics",
    "procedural content generation"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "This research explores the potential of Large Language Models (LLMs) to utilize psychometric values, specifically personality information, within the context of video game character development. Affective Computing (AC) systems quantify a Non-Player character's (NPC) psyche, and an LLM can take advantage of the system's information by using the values for prompt generation. The research shows an LLM can consistently represent a given personality profile, thereby enhancing the human-like characteristics of game characters. Repurposing a human examination, the International Personality Item Pool (IPIP) questionnaire, to evaluate an LLM shows that the model can accurately generate content concerning the personality provided. Results show that the improvement of LLM, such as the latest GPT-4 model, can consistently utilize and interpret a personality to represent behavior.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "In the dynamic and rapidly evolving domain of the video game industry, the exigent task of developing Non-Playable Characters (NPCs) that emulate human-like behavior presents a formidable challenge. A significant obstacle is the aspiration to create NPCs interacting with their environment and displaying a rich tapestry of character depth and emotional complexity. The current state of NPCs often fails to meet this ambitious objective, resulting in a gaming experience that is less immersive and emotionally engaging.\n\nThe impetus for this study is rooted in the potential of Affective Computing (AC) to bridge this existing gap. With its capacity to recognize, interpret, and simulate human emotions, AC can supply the necessary psychometric components to delineate NPCs' emotional and personality traits. By capitalizing on components from an AC system, we show to augment the emotional intelligence of NPCs, thereby fostering a more immersive and emotionally engaging gaming experience.\n\nThis paper hypothesizes that Large Language Models (LLMs) can be synergistically used with AC systems to engender more human-like NPCs. This research suggests that LLMs can be prompted with psychometric values derived from an AC system, particularly personality, the LLM can generate content aligning with the expected behaviors of the NPC. This process is validated by repurposing the International Personality Item Pool (IPIP) questionnaire, a human measuring evaluation, to evaluate the LLMs generated content. By comparing the prompted personality against the questionnaire's results, we show that the latest LLM can consistently generate the results expected for the initial personality. The demonstration and validity of the personality with an LLM indicates the plausibility of utilizing more values from an AC system, providing additional quantitative information for an LLM to generate content aligning with an NPCs psyche.\n\nThe subsequent sections of this paper will delve deeper into this hypothesis, exploring the potential of integrating AC psychometrics with LLMs. Section two will elucidate the background information, encompassing topics such as video game companies researching AC for their games, the latest scholarly research in AC, LLM integrations with video games, and the rationale for integrating AC with an LLM. Section three will delve into personality psychometrics, specifically the Big Five personality model. Section four will discuss using a personality test dataset and how its information can be used to benchmark against an LLM. Section five will generate synthetic data from the LLM and compare its results against the baseline dataset. Section six will outline a use case of an LLM using personality for gameplay. The paper will conclude with section seven.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Background Information",
      "text": "Prominent video game corporations increasingly endeavor to integrate AC systems into their games. Corporations such as Square Enix, Worldwalker Games, and Eidos Sherbrooke are exploring the possibilities of AC and its assimilation into their gaming products  [1, 2, 3] . These corporations employ AC to empower Non-Playable Characters (NPCs) to perceive and project emotions within their games. In executing this approach, these video game corporations experimented with emotive simulations for NPCs so that the player can recognize and empathize with the character. However, AC systems such as Popescu et al. 's GAMYGDALA, Shirvani & Ware's emotional narrative planning system, and Klinkert and Clark's Artificial Psychosocial Framework (APF)  [4, 5, 6] , are proficient in discerning, interpreting, processing, and simulating human emotional states between player and NPCs. Enhancing this pursuit for human-like NPCs is the integration of an LLM, which further improves the sophistication of dialogue generation and decision-making processes not only with the player but with other NPC interactions as well.\n\nThe advent of LLMs is paradigm shifting in the contemporary technological landscape. Many companies, such as Microsoft, Google, Meta, and Nvidia, are actively seizing opportunities to integrate LLMs into their products  [7] . However, this transition is not without its challenges, which include issues such as data hallucinations, memory limitations, and constrained accessibility of these models  [8, 9] . These issues become magnified within the context of the video game industry. This sector is keen to employ LLMs to generate in-game content but encounters additional complications, including the assurance of correct behavior, potential ethical liabilities, and extensive retesting debugging scenarios  [10] . These complexities, coupled with the initial challenges, have induced a level of hesitancy within the industry toward fully embracing LLMs  [11] . Nevertheless, the work conducted by Park et al., which highlights the development of Generative Agents, serves as a remarkable exemplar, demonstrating that the successful integration of an LLM system into video games is indeed achievable  [12] . With the integration of an LLM into a simulated village, Park et al. show NPCs understand their surroundings, plan their days with what they know, and spread information to share knowledge. To further push these NPCs to be believable humans, the game would integrate an AC system that provides psychometric values for the LLM to process alongside their knowledge representation and dissemination.\n\nThe primary objective of this research is to investigate the potential capability of an LLM to output the correct content of a character's psychological persona based on the input of psychometric values. AC systems are instrumental in providing these psychometric values, encompassing facets such as personality traits, emotional states, and the dynamics of relationships between game entities and other characters in the environment  [4, 5, 6] . This paper lays out a crucial first step in this inquiry: discerning whether an LLM can effectively interact with and interpret these psychometric values, with an initial focus on personality information. Personality traits, whether based on popular psychological models such as the Big Five or other frameworks, can significantly impact a character's decisions, actions, and reactions within a game's narrative. Therefore, the capability of an LLM to properly utilize these traits can play a crucial role in creating characters that are not only believable but also possess a consistent behavioral pattern.\n\nAC systems capitalize on personality models such as the Big Five, otherwise referred to as the Five Factor or OCEAN model, to represent a character's fundamental psychological composition within a game  [6] . This model comprises five diverse factors: Openness to novel experiences, Conscientiousness in tasks and interpersonal relationships, Extraversion in social contexts, Agreeableness towards diverse viewpoints and mutual understandings, and Neuroticism in interpreting circumstances  [13] .\n\nWe postulate the potential benefits of incorporating a personality model with an LLM. These include optimizing prompt use, broad application of general knowledge, and providing dynamic character transformations within the video game. We hypothesize that an LLM can craft content consistent with the specified personality when instructing it to roleplay as a character using a well-researched personality framework, such as the Big Five. Representing the Big Five as a 5-tuple to prompt the LLM, we use fewer tokens to explain the expected personality for an NPC. Given the extensive array of internet-based data used to train an LLM, it is plausible that research related to the Big Five forms a portion of that data set, including examples of individuals exemplifying each personality factor. Consequently, the LLM can generate dialogue content aligned with a given personality. Moreover, it is vital to acknowledge that a character's personality will likely evolve as players engage with games. Accordingly, the content generated by these characters should mirror their evolving persona.\n\nThis research aims to facilitate game developers in creating NPCs that exhibit a higher degree of human-like behavior and characteristics. It could provide invaluable insights to game designers, aiding them in integrating and effectively using AC systems within their design process. This not only enhances the realism of the characters but also allows for the generation of more diverse and nuanced in-game interactions.\n\nIncorporating personality profiles into LLMs is just the start. Including other aspects of AC systems, such as dynamic emotional states and social relationship metrics, can further provide an LLM with the necessary context to generate even more realistic, human-like behavior. This holistic approach can truly bring NPCs to life, making them more believable and immersive.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Personality Representation",
      "text": "The Big Five breaks personalities into five categories: Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism, which are represented on a continuous scale ranging from zero to one. A score of one signifies the full expression of a particular trait, while zero implies the presence of the opposing attribute  [13] .\n\nTo illustrate, a score of 1.0 on the Openness dimension indicates that an individual exhibits high creativity, readily embraces novelty, is driven by tackling new challenges, and engages in abstract thought. Conversely, a score of 0.0 in the Openness factor signifies resistance to change, disinterest in novelty, reluctance to welcome new ideas, and a deficit in imaginative thinking. Therefore, the Openness factor can also be conceptualized as a spectrum ranging from cautious/consistent to inventive/curious, corresponding to zero and one, respectively.\n\nHowever, it is important to note that the values assigned to any particular trait need not be restricted to the extremes of this scale. Instead, they can occupy any position within this range, providing an extensive, nuanced representation of personality traits. Consequently, the model spans five dimensions and is infinite along any axis, suggesting the potential for a virtually limitless array of personality combinations across these five factors.\n\nDrawing on the work of Van Mensvoort, the Big Five can be discretized into 20 distinct personality profiles  [14] . This subdivision encompasses a range of behavioral characteristics, from negative behavioral disorders such as Paranoid and Schizoid, to positive behavioral traits including Accommodating and Laissez-faire. This fine-grained classification allows for a more precise and detailed depiction of personality, accommodating its complex, multifaceted nature.\n\nThese personality profiles discretize the Big Five to distinct points, shown in Figure  1 , which enables one to label a particular personality configuration as one of the established profiles. This process identifies a specific categorization and imbues additional context into what the given personality configuration symbolizes. Moreover, these profiles, each denoting a general region within the model's domain, can serve as the foundation for a hierarchical structure.\n\nEmploying these profiles as categorical labels, we leverage human data to establish our Baseline in this research. This Baseline serves as a comparative standard against which we evaluate the performance of our methodology and the LLM's capacity to embody and express various character personalities. Thus, the defined profiles and our chosen baseline data inform our research approach and assist in objectively evaluating our outcomes.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Data Collection",
      "text": "We investigate the results from a comprehensive Big Five personality dataset using the personality profiles. The dataset, derived from the Open-Source Psychometrics Project, comprises personality test results from over a million participants (n = 1,015,342) who responded to a 50-item Big Five personality test  [15, 13] . Each test item was a statement to which participants responded on a Likert scale, with one indicating a strong disagreement with the presented behavior and five denoting strong agreement. The dataset not only includes the results of the personality test but also records auxiliary information such as the time taken to complete the test, the number of attempts made by the same participant (identified based on IP address), geographical coordinates (latitude and longitude), race, and so forth.\n\nWe undertook a thorough data-cleaning process to optimize the dataset for our research. We first ensured that each test response included answers to all 50 statements. We further filtered the data to include only those responses that took more than 300 milliseconds to answer a question, as the average human response time ranges between 150 and 300 milliseconds, thus mitigating bot submissions to the analysis. Finally, we only retained the first submission from each unique IP address. Following these preparation steps, a total of 596,956 test results remained for our analysis. This extensive and robust dataset now forms the foundation for our subsequent investigations. You can find the cleaned version of the dataset within the provided repository.\n\nThe subsequent phase involved the evaluation of the personality test results. This evaluation was conducted  based on a scoring key included with the test, accessed from the IPIP website  [16] . Each statement in the test corresponds to a particular personality factor. As a participant assigns a Likert value to a given statement, that value is accumulated into a running total for the respective personality factor. The assigned value may be inverted based on the statement's wording directionality. For instance, a statement reflective of Extraversion, such as \"Don't talk a lot, \" possesses a negative direction, thereby necessitating the inversion of the corresponding response value. Consequently, a response of 5 for this statement would be translated into a value of 1.\n\nFollowing the completion of this evaluation, each personality factor scores within a range of  [10, 50] . These values are then mapped to a [0.0, 1.0] range using linear interpolation to normalize the scores for comparative   (O, C, E, A, N ). This detailed evaluation process ensures an accurate and comprehensive representation of an individual's personality configuration based on the Big Five model.\n\nWe executed the label assignment of a personality profile with the evaluated test results using a nearestneighbor approach. For every test result represented as a 5-tuple vector, we calculated the Euclidean Distance to each of the 20 personality profiles. The personality profile with the smallest distance to the profile was identified as the corresponding label.\n\nThe final preparatory procedure was conducting disproportionate sampling for each personality profile. As the goal of this research is not to replicate the profile distribution of the entire population but rather to exam-ine the distribution of test results per personality profile, we opted for an equal representation across all profiles (m = 2525). Consequently, our baseline dataset incorporated a total of 50,500 test results, and the statistical description can be found in Table  1 . This methodological approach ensures that each personality profile is adequately represented in our analysis, enabling a balanced and comprehensive investigation of how an LLM can interpret and utilize psychometric values. The subset version of the cleaned dataset can also be found in the provided repository.\n\nFrom the works of Van Mensvoort's research, we projected the various personalities onto a two-dimensional plane by computing the values for Cognitive Stability (CS) and Cognitive Flexibility (CF)  [14]  defined by Equation 1 and 2 respectively. In Equation  1 , A is Agreeableness, C is Conscientiousness and S is Emotional Stability which is the inverse of N, Neuroticism. In Equation  2 , E is Extraversion and O is Openness.\n\nCognitive\n\nThis methodology allows us to visualize the distribution and interrelation of the various personality profiles within our baseline dataset. The resulting twodimensional representation of the Big Five offers a clear and intuitive overview of the personality landscape, as illustrated in Figure  2 . This approach not only affords an understanding of individual profiles but also elucidates the underlying relationships between various personality factors.\n\nFigure  2  shows that each personality type forms a cluster around its corresponding profile, represented by the central X within each cluster. Beyond this evaluative visualization, we have also employed a dimensionality reduction technique, Linear Discriminant Analysis (LDA), to plot the 50-item personality test responses, shown in Figure  3 . This method, once again, yielded distinct clusters that effectively distinguished between different personality profiles.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Generate Synthetic Data",
      "text": "The LLMs selected for this research comprised a suite of OpenAI models: text-davinci-003, gpt-3.5-turbo-0613, and gpt-4-0613. Each LLM model was prompted with a succinct description delineating the extremes of each personality factor. This was followed by the 5-tuple representing the personality profile and instructions to complete the personality test. Each model underwent this The resulting test responses demonstrated variability, ranging from the expected Comma-Separated Value (CSV) format to comprehensive paragraph-based breakdowns encompassing each statement and the corresponding rationale. The results provided in the CSV format were added to the analysis; however, the comprehensive results were parsed and converted to the proper CSV format and then added to the analysis. Note that the final results and the prompt provided to the LLM are available for download from the provided repository. An assessment determined the correspondence between the test results and the assigned personality profiles. This assessment involved the computation of accuracy using the same approach as in the baseline dataset, namely determining the shortest Euclidian Distance from each personality profile. The results exhibited significant disparities across the models, as shown in Table  2 . The text-davinci-003 model performed the poorest, with an accuracy of 13.83% (+/-1.34% at 95% confidence interval) , followed by gpt-3.5-turbo-0613 at 17.77% (+/-1.4809% at 95% confidence interval). In contrast, the next-generation model, gpt-4-0613, exhibited a substantial leap in performance, achieving an accuracy of 73.98% (+/-1.6995% at 95% confidence interval).\n\nAnother assessment method employed in this research is the Root Mean Squared Prediction Error (RMSPE). This measurement assumes that if the labeling of the personality profile is accurate, the error in the evaluated test results should be marginal; thus, they should closely align with the respective profile. Two variants of RMSPE were utilized: Euclidian Distance and Cosine Similarity. In either case, treating the 5-tuple personality traits either as a point in the 5D space or a vector within the space led to the same conclusion. As long as the RMSPE values were close to zero, the error was considered negligible, indicating a successful personality embodiment by the model.\n\nTable  3  provides an overview of the RMSPE values for Euclidian Distance and Cosine Similarity, respectively, for the Baseline and each of the three models. Comparatively, the text-davinci-003 model performed the poorest again, followed by gpt-3.5-turbo-0613. However, the gpt-4-0613 model outperformed its predecessors and demon- Visual representations of these findings can be seen in Figure  2 , which shows the clustering of test results according to the personality profiles. Since text-davinci-003 is at the time considered a legacy model, we can clearly see this by the clustering of evaluated test results and test responses outside the clusters of the baseline. As the GPT model improves with the next iteration of gpt-3.5-turbo-0613 and gpt-4-0613, the clusters of evaluated test results and test responses move closer to their respective baseline clusters to the point gpt-4-0613 clusters right above the personality profile location. The degree of closeness within each cluster and the clear separation between clusters further underscores the marked improvement in the performance of the gpt-4-0613 model over the other models and even the Baseline.\n\nInter-rater reliability (IRR) is another key measure utilized in this research. IRR assesses the extent to which different ratings of the same entity agree with each other. This concept can be illustrated using the example of judges scoring a competition, where ideally, the scores provided by different judges for the same contestant should vary minimally, indicating consistent evaluation criteria. In the context of this research, the intuition behind applying IRR is that if 128 individuals with the same Paranoid personality profile took the same personality test, their answers should be fairly similar, reflecting their shared psychological characteristics.\n\nTable  4  presents the IRR results for each model and the Baseline. The data indicates that it is quite rare but pos-  The violin plots shown in Figure  4  provide a clear, visual representation of the distribution of test results for each personality factor. These plots help understand the variations in results for each LLMs and offer a basis for comparison with the baseline. Each personality profile's position, indicated by the red circle, should ideally intersect within the baseline distributions, represented by the green violin. This would imply that the generated test results align closely with the actual personality profile. The distributions for text-davinci-003 and gpt-3.5-turbo-0613, represented by the blue and lime violins, respectively, seldom intersect with the actual personality profile, suggesting that these models might not be accurately generating test results consistent with the given personality. In contrast, the gpt-4-0613 results intersect with the personality profile within the lower or upper quartile, implying that the model is more successful at generating test results that align closely with the given personality profile. This intersection suggests greater accuracy and consistency with gpt-4-0613, making it a potentially more effective tool for game developers in creating realistic, human-like characters based on the Big Five. These findings underscore the potential of utilizing advanced LLMs like gpt-4-0613 to generate more accurate and nuanced character responses in video games, thereby improving the overall gaming experience for players.",
      "page_start": 5,
      "page_end": 8
    },
    {
      "section_name": "Use Cases",
      "text": "The potential of LLMs to generate content accurately reflecting a provided personality opens up exciting possibilities for integrating AC systems and LLMs for NPCs. This integration could be applied in various contexts, enhancing the gaming experience by creating more dynamic and emotionally nuanced characters. The following paragraphs will delve into three possible scenarios where this integration could be utilized to enrich the narrative and gameplay. Each scenario will explore how context clues can be used with an LLM to generate unique and engaging content that aligns with the personality of the NPC. From retelling stories based on experiences to improvising narratives and piecing together the end of a story, the use of LLMs promises to revolutionize the way NPCs interact within the gaming world.\n\nIn one scenario, context clues could be provided, prompting the LLM to retell a story. The given personality would guide the model to focus on aspects relevant to that personality, influencing the choice of semantics to reflect the character's disposition. This could be seen in games like \"Tales of Arabian Nights, \" \"Grandpa's Farm, \" or \"This War of Mine,\" where NPCs experience events and undergo narratives to advance the plot. The NPCs, powered by an LLM, would interpret these experiences and share their stories, offering additional information or different perspectives.\n\nIn another scenario, context clues could be generated on the spot to create an active, evolving story. Similar to improvisation, the model would adopt a \"yes and...\" approach, contributing to the communal story. The LLM, guided by its assigned personality, would describe actions and aspects that align with its psyche and how it would resolve a situation. This could be applied in games like \"Dungeons and Dragons, \" \"Once Upon a Time, \" and \"Zork, \" where players need to describe what is happening and their actions in the moment.\n\nFinally, context clues could be used to reveal the end of a story, with the LLM tasked with explaining how the story reached that conclusion. The LLM would need to link events together, with the assigned personality acting as a heuristic to narrow down the choices. This could be seen in games like \"Dark Stories,\" \"Sherlock Holmes Consulting Detective, \" or \"Shadows of Doubt. \" The NPC would use its personality-driven intuition to fill in the gaps in the narrative and motivate the next steps to find the respective clues.",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Conclusion",
      "text": "Our investigation of LLM's proper use of personality information by repurposing the IPIP questionary, a human measuring technique to determine personality, has revealed promising potential for creating more engaging and realistic NPCs. The continual improvement of LLMs, such as the current dominating gpt-4-0613 model, will only further improve the output of proper behaviors corresponding with psychometric values, particularly personality traits, creating NPCs with consistent and believable behavioral patterns. Incorporating personality models with LLMs enables dynamic character transformations and leverages the broad application of general knowledge, enhancing the overall gaming experience. Future research will continue to explore this exciting frontier, looking at different psychometric values, such as the emotional state of an NPC or their attitudes on objects, praises towards actions, the outlook of events, and their relationship with other NPCs. Additionally, finetuning an LLM basing the expected behavior on human psychometric datasets can further improve the model's content generation. Confirming that an LLM can construct dialogue or make decisions with these additional values can further necessitate the integration of an AC system for NPCs, providing additional context clues to describe the nuances of believable human behavior.",
      "page_start": 9,
      "page_end": 9
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: , which enables one",
      "page": 3
    },
    {
      "caption": "Figure 1: Van Mensvoortâ€™s 20 personality Profiles. Plotted",
      "page": 3
    },
    {
      "caption": "Figure 2: Nine different plots of evaluated test results using",
      "page": 4
    },
    {
      "caption": "Figure 3: Nine different plots of the 50 test responses using",
      "page": 4
    },
    {
      "caption": "Figure 2: This approach not only affords an",
      "page": 5
    },
    {
      "caption": "Figure 2: shows that each personality type forms a",
      "page": 5
    },
    {
      "caption": "Figure 3: This method, once again, yielded distinct",
      "page": 5
    },
    {
      "caption": "Figure 2: , which shows the clustering of test results ac-",
      "page": 6
    },
    {
      "caption": "Figure 4: Violin Plot of each personality profile (red point) against the baseline (green), davinci (blue), turbo (lime), and gpt-4",
      "page": 7
    },
    {
      "caption": "Figure 3: , the visual representation un-",
      "page": 7
    },
    {
      "caption": "Figure 4: provide a clear,",
      "page": 8
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "0.01899\n0.01463\n0.01348\n0.02825\n0.01208\n0.01714": "0.02071\n0.00934\n0.00728\n0.02403\n0.01190\n0.00895\n0.01182\n0.01756\n0.00581\n0.02003\n0.00562\n0.00469\n0.02516\n0.01098\n0.00405\n0.01792\n0.02363\n0.00752\n0.01279\n0.00975\n0.00425\n0.01836\n0.01078\n0.00692"
        },
        {
          "0.01899\n0.01463\n0.01348\n0.02825\n0.01208\n0.01714": "0.00974\n0.00463\n0.00302\n0.01634\n0.00513\n0.00229\n0.01026\n0.00399\n0.00314\n0.01108\n0.00402\n0.00427\n0.00637\n0.00520\n0.00316"
        },
        {
          "0.01899\n0.01463\n0.01348\n0.02825\n0.01208\n0.01714": "0.02085\n0.00680\n0.01033\n0.01662\n0.00510\n0.00469\n0.00932\n0.00587\n0.00360\n0.01061\n0.00512\n0.00317\n0.02335\n0.01075\n0.00358"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "0.10744\n0.11304\n0.11572\n0.11865\n0.12594\n0.13536": "0.12259\n0.12516"
        },
        {
          "0.10744\n0.11304\n0.11572\n0.11865\n0.12594\n0.13536": "0.13966"
        },
        {
          "0.10744\n0.11304\n0.11572\n0.11865\n0.12594\n0.13536": "0.12653"
        },
        {
          "0.10744\n0.11304\n0.11572\n0.11865\n0.12594\n0.13536": "0.10422"
        }
      ],
      "page": 6
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "AI summit: Driving emotionally expressive NPC animations and behaviors with a designer friendly pipeline",
      "authors": [
        "G Boeda"
      ],
      "year": "2021",
      "venue": "AI-Summit-Driving-Emotionally-Expressive, game Developers Conference"
    },
    {
      "citation_id": "2",
      "title": "Independent games summit session: Getting players emotionally invested in procedural characters in 'wildermyth",
      "authors": [
        "N Austin"
      ],
      "year": "2022",
      "venue": "Independent-Games-Summit-Session-Getting, game Developers Conference"
    },
    {
      "citation_id": "3",
      "title": "Machine learning summit: Emotion detection for expressive characters in 'marvel's guardians of the galaxy",
      "authors": [
        "R Trachel"
      ],
      "year": "2022",
      "venue": "Machine-Learning-Summit-Emotion-Detection, game Developers Conference"
    },
    {
      "citation_id": "4",
      "title": "GAMYG-DALA: An emotion engine for games",
      "authors": [
        "A Popescu",
        "J Broekens",
        "M Van Someren"
      ],
      "year": "2014",
      "venue": "conference Name: IEEE Transactions on Affective Computing",
      "doi": "10.1109/T-AFFC.2013.24"
    },
    {
      "citation_id": "5",
      "title": "A formalization of emotional planning for strong-story systems",
      "authors": [
        "A Shirvani",
        "S Ware"
      ],
      "year": "2020",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment",
      "doi": "10.1609/aiide.v16i1.7419"
    },
    {
      "citation_id": "6",
      "title": "Artificial psychosocial framework for affective non-player characters",
      "authors": [
        "L Klinkert",
        "C Clark"
      ],
      "year": "2021",
      "venue": "Advances in Artificial Intelligence and Applied Cognitive Computing",
      "doi": "10.1007/978-3-030-70296-0_50"
    },
    {
      "citation_id": "7",
      "title": "A survey of large language models",
      "authors": [
        "W Zhao",
        "K Zhou",
        "J Li",
        "T Tang",
        "X Wang",
        "Y Hou",
        "Y Min",
        "B Zhang",
        "J Zhang",
        "Z Dong",
        "Y Du",
        "C Yang",
        "Y Chen",
        "Z Chen",
        "J Jiang",
        "R Ren",
        "Y Li",
        "X Tang",
        "Z Liu",
        "P Liu",
        "J.-Y Nie",
        "J.-R Wen"
      ],
      "year": "2023",
      "venue": "A survey of large language models",
      "doi": "10.48550/arXiv.2303.18223",
      "arxiv": "arXiv:2303.18223"
    },
    {
      "citation_id": "8",
      "title": "Large language models and the perils of their hallucinations",
      "authors": [
        "R Azamfirei",
        "S Kudchadkar",
        "J Fackler"
      ],
      "year": "2023",
      "venue": "Critical Care",
      "doi": "10.1186/s13054-023-04393-x"
    },
    {
      "citation_id": "9",
      "title": "Augmenting language models with long-term memory",
      "authors": [
        "W Wang",
        "L Dong",
        "H Cheng",
        "X Liu",
        "X Yan",
        "J Gao",
        "F Wei"
      ],
      "year": "2023",
      "venue": "Augmenting language models with long-term memory",
      "doi": "10.48550/arXiv.2306.07174",
      "arxiv": "arXiv:2306.07174"
    },
    {
      "citation_id": "10",
      "title": "Unexpected circumstances that make it difficult to interact with game characters with generated AI",
      "authors": [
        "J Takeyama"
      ],
      "year": "2023",
      "venue": "Unexpected circumstances that make it difficult to interact with game characters with generated AI"
    },
    {
      "citation_id": "11",
      "title": "Artificial neural networks, in: AI for Games",
      "authors": [
        "I Millington"
      ],
      "year": "2019",
      "venue": "Artificial neural networks, in: AI for Games"
    },
    {
      "citation_id": "12",
      "title": "Generative agents: Interactive simulacra of human behavior",
      "authors": [
        "J Park",
        "J O'brien",
        "C Cai",
        "M Morris",
        "P Liang",
        "M Bernstein"
      ],
      "year": "2023",
      "venue": "Generative agents: Interactive simulacra of human behavior",
      "doi": "10.48550/arXiv.2304.03442",
      "arxiv": "arXiv:2304.03442"
    },
    {
      "citation_id": "13",
      "title": "The development of markers for the big-five factor structure",
      "authors": [
        "L Goldberg"
      ],
      "year": "1992",
      "venue": "Psychological Assessment",
      "doi": "10.1037/1040-3590.4.1.26"
    },
    {
      "citation_id": "15",
      "title": "System for big five personality profile interpretation derived from personality disorder prototypes",
      "authors": [
        "M Mensvoort"
      ],
      "year": "2023",
      "venue": "System for big five personality profile interpretation derived from personality disorder prototypes"
    },
    {
      "citation_id": "16",
      "title": "Open psychology data: Raw data from online personality tests",
      "authors": [
        "L Goldberg"
      ],
      "year": "2019",
      "venue": "Open psychology data: Raw data from online personality tests"
    },
    {
      "citation_id": "17",
      "title": "2022, IPIP home",
      "authors": [
        "L Goldberg"
      ],
      "venue": "2022, IPIP home"
    }
  ]
}