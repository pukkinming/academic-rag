{
  "paper_id": "2205.13908v1",
  "title": "Emoinhindi: A Multi-Label Emotion And Intensity Annotated Dataset In Hindi For Emotion Recognition In Dialogues",
  "published": "2022-05-27T11:23:50Z",
  "authors": [
    "Gopendra Vikram Singh",
    "Priyanshu Priya",
    "Mauajama Firdaus",
    "Asif Ekbal",
    "Pushpak Bhattacharyya"
  ],
  "keywords": [
    "Multi-label Emotion and Intensity Recognition",
    "Dialogues",
    "Low-resource Language Dataset # of sentences # of emotions Emotion Intensity Annotation Language Conversational Multi-label"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "The long-standing goal of Artificial Intelligence (AI) has been to create human-like conversational systems. Such systems should have the ability to develop an emotional connection with the users, hence emotion recognition in dialogues is an important task. Emotion detection in dialogues is a challenging task because humans usually convey multiple emotions with varying degrees of intensities in a single utterance. Moreover, emotion in an utterance of a dialogue may be dependent on previous utterances making the task more complex. Emotion recognition has always been in great demand. However, most of the existing datasets for multi-label emotion and intensity detection in conversations are in English. To this end, we create a large conversational dataset in Hindi named EmoInHindi for multi-label emotion and intensity recognition in conversations containing 1,814 dialogues with a total of 44,247 utterances. We prepare our dataset in a Wizard-of-Oz manner for mental health and legal counselling of crime victims. Each utterance of the dialogue is annotated with one or more emotion categories from the 16 emotion classes including neutral, and their corresponding intensity values. We further propose strong contextual baselines that can detect emotion(s) and the corresponding intensity of an utterance given the conversational context.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Emotions are fundamental human characteristics that have been researched for many years by researchers in psychology, sociology, medicine, computer science, and other domains. Ekman's six-class categorization  (Ekman, 1992 ) and Plutchik's Wheel of Emotion which proposed eight basic bipolar emotions  (Plutchik and Kellerman, 2013) , are two notable works in understanding and categorising human emotions. Emotions play an important role in our daily life and emotion detection in text has become a longstanding goal in Natural Language Processing (NLP). Emotions are inherently conveyed by messages in human communications. With the popularity of social media platforms like Facebook Messenger, WhatsApp and conversational agents like Amazon's Alexa, there is a growing demand for machines to interpret human emotions in real conversations for more personalized and human-like interactions. The ability to effectively identify emotions in conversations is crucial for developing robust dialogue systems. There are two major types of dialogue systems: a task-oriented dialogue systems and a social (chit-chat) dialogue system. The former is concerned with creating a personal assistant capable of performing specific tasks, but the latter is concerned with capturing the conversation flow, which focuses more on the speaker's feelings.\n\nIn both these systems, understanding the user's emotions is crucial for providing better user experience and maximizing the user satisfaction. Nowadays, many websites, blogs, tweets, conversational agents support Hindi * The authors are jointly the first authors language and some of them use Hindi as a primary language as well. However, most studies of emotion in conversations have focused on English language interactions  (Chen et al., 2018; Yeh et al., 2019; Hazarika et al., 2018; Ghosal et al., 2019; Kim et al., 2018; He and Xia, 2018; Yu et al., 2018; Huang et al., 2019) ; comparatively very little attention is given to emotion detection in regional languages like Hindi. Towards this end, we propose a novel conversational dataset EmoInHindi for identifying emotions (e.g., joy, sad, angry, disgusted etc.) in textual conversations in Hindi language, where the emotion of an utterance is detected in the conversational context.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Problem Definition",
      "text": "Given a textual utterance of a dialogue along with the conversation history (previous few utterances in dialogue), the task is to identify the emotion category(s) of each utterance from a set of pre-defined emotion categories and their corresponding intensity values.\n\nFormally, given the input utterance U t consisting of sequence of words U t = {w 1 , w 2 , ..., w T } and the conversation history C consisting of sequence of utterances C = {U 1 , U 2 , ..., U t-1 }, the task is to predict one or more emotion label, e = {e 1 , e 2 , ..., e L } from N predefined set of emotions and corresponding intensity value i = {i 1 , i 2 , ..., i L }, where i k ∈ {0, 1, 2, 3} of the utterance U t . Fig.  1  depicts a sample dialogue from our dataset, where each utterance is labeled with one or more underlying emotions and corresponding intensity value.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Contribution",
      "text": "The key contributions of our work are two-fold:\n\n• We propose EmoInHindi 1 , the currently largest Hindi conversational dataset labeled with multiple emotions and their corresponding intensity values. • We setup strong baselines for utterance-level multiple emotion and intensity detection task and report their results for identifying emotion(s) and the corresponding intensity expressed in an utterance of a dialogue written in Hindi.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Related Work",
      "text": "With the development in Artificial Intelligence (AI), emotion classification has become a significant task because of its importance in many downstream tasks like response generation for conversational agents, customer behavior modeling, multimodal interactions and many more. Recently,  Kim et al. (2018; He and Xia (2018; Yu et al. (2018; Huang et al. (2019)  investigated multi-label emotion classification for textual data.  Kim et al. (2018)  performed multi-label emotion classification on twitter data using multiple Convolution Neural Network (CNN) networks along with self-attention and  Huang et al. (2019)  employed sequence-to-sequence framework for multi-label emotion classification.  Yu et al. (2018)  improved the performance of multi-label emotion classification on twitter data by using transfer learning. Our present study differs from the previous multi-label emotion classification research in that we categorise emotions of utterances of conversations, which require contextual knowledge from previous utterances, making the task more difficult and intriguing.\n\nRecently, emotion recognition in conversations  (Chen et al., 2018; Yeh et al., 2019; Hazarika et al., 2018; Ghosal et al., 2019; Firdaus et al., 2020)  has been in demand.  Li et al. (2017)   Most of the existing methods and resources developed for emotion analysis are available in English  (Yadollahi et al., 2017) . Lately, there has been work on developing resources for detecting emotions from Hindi text. For instance,  Vijay et al. (2018)  created a corpus, consisting of sentences from Hindi-English code switched language used in social media for predicting emotions. Likewise,  Koolagudi et al. (2011)  proposed a Hindi corpus consisting of sentences taken from auditory speech signals for emotion analysis task. Another Hindi dataset consisting of sentences from news documents of disaster domain for emotion detection was proposed by  Ahmad et al. (2020) .  Kumar et al. (2019)  presented a largest annotated corpus in Hindi comprising of sentences taken from various short stories in which each sentence is annotated with relevant emotion categories given the context of a sentence. However, all of these works are focused on non-conversational settings. The long-term goal of our present work is to build a dialogue system capable of having a conversation with the user in Hindi. Such a system should not only be able to respond in Hindi according to the user's intent, but its utterances should also be aligned with the user's emotional state. As opposed to existing works on emotion detection from textual data in Hindi language, our present work provides a multi-label emotion and intensity annotated conversational dataset in Hindi.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Dataset",
      "text": "In this section, we describe the complete details of our EmoInHindi dataset.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Dataset Preparation",
      "text": "The dataset that we prepared for our experiment comprises of dialogues focused on mental health counselling and legal assistance for women and children who have been victims of various types of crimes ranging from domestic violence, workplace harassment, matrimonial fraud, to cybercrimes like cyber stalking, online harassment, masquerading and trolling.\n\nWe construct the dataset in Hindi in Wizard-of-Oz  (Kelley, 1984)  style. Every dialogue in the dataset starts with a basic description of the victim, after which the victim is asked about the problem and accordingly provided with the required assistance.\n\nThe crime victims need emotional comfort and support for expressing their feelings freely, hence the dialogue systems should interact with the users empathetically. Such conversational agents that comprehend human emotions assist in enhancing the user's communication with the system, thereby strengthening the communication in a positive direction  (Martinovsky and Traum, 2006; Prendinger and Ishizuka, 2005) .\n\nWe have annotated every utterance in a dialogue with multiple appropriate emotion categories and their corresponding intensity.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Guidelines For Dataset Preparation",
      "text": "We contacted an expert in mental health counselling from our institute health department to understand the flow of dialogues in victims' situations to create the conversations. At first, we tried to find out the problems of the victims and assessed their psychological needs. While counselling the victims, we make sure to be patient and kind towards them. The victims were provided a non-judgemental environment to share as much information they are comfortable to and if the victims decide to report the assault, seek medical attention, or contact organizations that can help them, then we assist them accordingly by providing the relevant legal, medical and organization information. Eventually, this was created to help the victims identify ways in which the victims can re-establish their sense of physical and emotional safety and provided a few basic safety suggestions to them so that they are aware of the crimes and can prevent such events in the future.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Annotation",
      "text": "The utterances in every dialogue of our proposed Hindi dataset is annotated with one or more appropriate emotion categories and their corresponding intensity. For annotating the dataset, we consider 15 emotions, namely Anticipation, Confident, Hopeful, Anger, Sad, Joy, Compassion, Fear, Disgusted, Annoyed, Grateful, Impressed, Apprehensive, Surprised, Guilty as emotion labels for the utterances in a dialogue. The emotion annotation list has been extended to incorporate one more label, namely Neutral. The \"Neutral\" label is designated to utterances having no-emotion. While annotating the dataset, every utterance in a given dialogue is labeled with one or more emotions. Every emotion label is accompanied with an intensity value ranging from 1-3, with 1 indicating the lower intensity and 3 the highest. The Neutral label has intensity value of 0.\n\nFor annotating the utterances in our dataset, we employ three annotators highly proficient in Hindi and have prior experience in labelling emotions in conversational settings. The guidelines for annotation along with some examples were explained to the annotators before starting the annotation process. The annotators were asked to label each utterance of every dialogue with emotion(s) and corresponding intensity value. We achieve the overall Fleiss'  (Fleiss, 1971)  kappa score of 0.84 for the emotions, 0.88 for intensity, which can be considered reliable. To determine the final label of the utterances, we use majority vote.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Challenges",
      "text": "Generic Challenges: Counselling the victim and providing relevant assistance to them is a challenging task. If the intelligent agent does not seem supportive and understanding, the victim feels even more frightened and alone. Consequently, we came across various challenges while creating our conversational dataset which are as follows:\n\n• Counselling the victims according to their needs and mental state was a difficult assignment because of distinct mental state and need of every single individual. Identification of implicit emotions are sometimes confusing for the annotators due to lack of explicit emotion pointer. For instance, in Example 2 in which a user is saying that her friend started laughing (in Utterance 3). In the absence of contextual information, this will be perceived as Joy. However, by looking at the context of the utterance, this will be annotated with Surprised,Sad as emotion labels. We would always be happy to help her. May I know how is she doing now?) Utterance 3: । (She started laughing when she heard this.) • of emotions for sarcastic utterances: Annotating the sarcastic utterances is one of the commonly faced challenges while annotating the utterances of our dataset. Sarcasm is prevalent in most of the previous works in sentiment and emotion analysis. Sarcasm is a sort of verbal irony; simply put, it is something uttered that should be perceived as having the opposite meaning as its literal meaning  (Gibbs Jr et al., 2007) . For instance, in Example 3, the emotion closest to the speaker's mood is that of Anger, which might easily be misinterpreted as Joy.\n\nHence, while annotating the sarcastic utterances, the annotators were instructed to keep in mind the contextual knowledge given by the previous utterances of the dialogue.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Dataset Statistics",
      "text": "In Table  2 , we provide the important statistics of the dataset followed by the overall emotion distribution of our dataset in Table  3 .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Comparison With The Related Datasets",
      "text": "The available datasets for emotion detection are mostly in English. Towards the task of emotion detection from Hindi text, previous attempts have been made in creating corpus containing 2,866 sentences for predicting emotions from Hindi-English code switched language used in social media  (Vijay et al., 2018) . A Hindi dataset, IITKGP-SEHSC consisting of 12,000 sentences collected from auditory speech signals was proposed by  (Koolagudi et al., 2011) . Another dataset with 780 Hindi sentences collected from children stories belonging to three genres, namely fable, folktale and legend and annotated with five different emotion categories: happy, sad, anger, fear and neutral was introduced in  (Harikrishna and Rao, 2016) . Lately, the authors in  (Kumar et al., 2019)  introduced the first largest annotated Hindi corpus named BHAAV for emotion detection consisting of 20,304 sentences from 230 popular Hindi short stories spanning across frequently used 18 genres, viz. historical, mystery, patriotic to name a few. The authors in  (Ahmad et al., 2020)  proposed Hindi corpus, Emo-Dis-HI consisting of 2,668 sentences from news documents of disaster domain, where each sentence is labeled with one of the emotion categories viz., sadness, sympathy/pensiveness, optimism, fear/anxiety, joy, disgust, anger, surprise and no-emotion.\n\nWhen it comes to the task of analyzing emotions from Hindi text in conversational setting, there are no conversational dataset available in Hindi. Our proposed dataset is different from the existing datasets for emotion detection from Hindi. The dataset that we present here is the first large-scale goal-oriented conversational dataset comprising of 1814 dialogues with each utterance in dialogues annotated for multilabel emotion and corresponding intensity value. Comparisons between the existing datasets and our proposed dataset, EmoInHindi are given in  Table 4",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Baselines",
      "text": "We use the following baseline models:\n\nBaseline #1: bcLSTM: The bidirectional contextual LSTM bcLstm  (Poria et al., 2017 ) is a bidirectional contextual LSTM. Two uni-directional LSTMs with",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Proposed: C-Attention-Trans And C-Fourier-Trans",
      "text": "We use the transformer encoder suggested by  (Vaswani et al., 2017)   Working method of the model Suppose text features have dimension d, then each utterance is represented by u i,x ∈ R d where x represents x th utterance of the conversation i. To get U i , we collect a number of utterance in a conversation ,d , where c i represents the number of utterances we consider as a context in a conversation. This U i is given to both C-A-Trans and C-F-Trans for the output. We show our model in Fig  3 .\n\nThe output of the C-A-Transformer and C-F-Transformer is fed to the FC Layer, which then passes it on to the Softmax Layer for emotion and intensity prediction.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Loss Function:",
      "text": "The emotion intensity classifier is trained by minimizing the negative log-likelihood\n\nFor multilabel emotion, we use MultiLabelSoftMarginLoss, where y em is the true emotion labels and ỹ em is the predicted emotion label. For Emotion Intensity, we use MSE (Mean Squared Error) as the loss function. Our loss function's primary goal is to instruct the model on how to weigh the task-specific losses. For this, we use a principled approach to multi-task deep learning that takes into account the homoscedastic uncertainty (task dependent or homoscedastic uncertainty is aleatoric uncertainty that is not depending on the input data). Homoscedastic is a number that remains constant throughout all input data and changes between jobs. Task-dependent uncertainty is the effect of this, while weighing multiple loss functions  (Kendall et al., 2018)  of each task.\n\nWhere i defines different tasks (emotion classification and intensity).",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Results And Analysis",
      "text": "",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Feature Extraction And Data Distribution For Experiment",
      "text": "For textual features, we take the pre-trained 300dimensional Hindi fastText embedding  (Joulin et al., 2016) . We obtain the training and testing set using 80:20 split of the dataset. Further, the 20% of the training set is used as validation set during training to keep track of model training progress. Empirically, we take five 2 utterances as context for a particular utterance.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Experimental Setup",
      "text": "We implement our proposed model in PyTorch, a Python-based deep learning library. We perform grid search to find the optimal hyper-parameters in Table  5 . We use Adam as an optimizer. We use Softmax as a classifier for emotion. We use Transformer Encoder with two layers. The embedding size is set to 300, and the learning rate is set to 0.003. We use negative log-likelihood loss for emotion prediction. Our model converges with 30 epochs and we use 32 batch size.\n\n2 Baseline models give the best result at five.   ) . We observe that C-F-Trans performs better than the C-A-Trans. We show the results in Table  8  for single label emotion and intensity.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Error Analysis",
      "text": "We show a few samples 3  (c.f. Table  7 ) which are correctly predicted by our proposed model (C-F-Trans). For example, as shown in Table  7 , । । (Rakshak my landlord is try to harass me. Please help me.) have label Sad,Annoyed and intensity 3,1 correctly predicted by our model (C-F-Trans). But our model also confused in some situations as for example, a Ú ? । (What can I write in the application? Don't call me dear) have label Anticipation, Annoyed but our model predicted Joy due to word (dear) which is maximum used with emotion Joy. So our model predicted Joy emotion and Grateful as it is come with Joy most of the time.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Conclusion And Future Direction",
      "text": "In this paper, we have introduced a large-scale Hindi conversational dataset, EmoInHindi prepared in Wizard-of-Oz fashion for multi-label emotion classification and intensity prediction in dialogues. We have evaluated our proposed EmoInHindi dataset and reported the results using strong baselines for both tasks of emotion recognition and intensity prediction. We believe that this dataset can be employed in the future for for making emotion-aware conversational agents capable of conversing with the users in Hindi. Furthermore, we would like to extend this work for more low-resource languages like Bengali, Marathi etc. so that it can be used to create emotionally-aware conversational systems that can interact with the users in their regional language thereby creating a more userfriendly environment for them.",
      "page_start": 9,
      "page_end": 9
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: depicts a sample dialogue",
      "page": 1
    },
    {
      "caption": "Figure 1: Sample dialogue from our dataset with emotion and corresponding intensity annotation",
      "page": 2
    },
    {
      "caption": "Figure 2: Distribution of emotions in EmoInHindi",
      "page": 3
    },
    {
      "caption": "Figure 3: Architectural diagram of the C-F-Trans framework",
      "page": 6
    }
  ],
  "tables": [
    {
      "caption": "Table 1: which shows different empathetic Anger 5582",
      "data": [
        {
          "Speaker\nUtterances\nEmotion & corresponding intensity": "Dialogue 1"
        },
        {
          "Speaker\nUtterances\nEmotion & corresponding intensity": "(cid:109)\n(cid:92) (cid:87)(cid:103)(cid:65) (cid:103)(cid:121)(cid:65) (cid:104)(cid:1)(cid:32)।\nVictim\nsad (1)\n(I am cheated.)"
        },
        {
          "Speaker\nUtterances\nEmotion & corresponding intensity": "(cid:109)\n(cid:69)(cid:107) a(cid:65)(cid:112)(cid:107)(cid:111)\n(cid:69)(cid:107)(cid:115)(cid:110)(cid:3) (cid:68)(cid:111)(cid:75)(cid:65)\n(cid:69)(cid:100)(cid:121)(cid:65) (cid:104)(cid:123) ?\n(cid:0) (cid:74)(cid:3) (cid:121)(cid:104) (cid:115)(cid:0) (cid:110)(cid:107)(cid:114) (cid:100)(cid:0) (cid:75) (cid:104)(cid:0) a(cid:65) (cid:109)(cid:3)(cid:114)(cid:3) (cid:100)(cid:111)(cid:45)(cid:116)। ky(cid:65) a(cid:65)(cid:112) (cid:107)(cid:2) (cid:112)(cid:121)(cid:65) (cid:109)(cid:0) (cid:74)(cid:3) (cid:98)(cid:116)(cid:65) (cid:115)(cid:107)(cid:116)(cid:3) (cid:104)(cid:123)(cid:92)\nAgent\nsad (1), anticipation (1)\n(I am sorry to hear this my friend. Could you please let me know who has cheated you?)"
        },
        {
          "Speaker\nUtterances\nEmotion & corresponding intensity": "(cid:109)\n(cid:69)(cid:100)(cid:121)(cid:65) (cid:104)(cid:123)।\n(cid:0) (cid:74)(cid:3) (cid:109)(cid:3)(cid:114)(cid:3) (cid:115)(cid:65)(cid:84)(cid:70) (cid:110)(cid:3) (cid:69)(cid:115)(cid:80)(cid:13) (cid:115)(cid:92)(cid:112)(cid:69)tt (cid:107)(cid:3) (cid:69)(cid:108)e (cid:68)(cid:111)(cid:75)(cid:65)\nVictim\nsad (1)\n(I am cheated by my partner just for the sake of property.)"
        },
        {
          "Speaker\nUtterances\nEmotion & corresponding intensity": "(cid:109)\n(cid:92) (cid:115)(cid:109)(cid:74)(cid:116)(cid:65) (cid:104)(cid:1) (cid:92)\n(cid:69)(cid:107) (cid:69)(cid:45)(cid:84)(cid:69)(cid:116) a(cid:65)(cid:112)(cid:107)(cid:3) (cid:69)(cid:108)e a(cid:81)(cid:67)(cid:70) (cid:110)(cid:104)(cid:70)(cid:92) (cid:104)(cid:123)। (cid:121)(cid:104) (cid:98)(cid:104)(cid:0) (cid:116) a(cid:81)(cid:67)(cid:65) (cid:104)(cid:111)(cid:103)(cid:65) (cid:121)(cid:69)(cid:100) a(cid:65)(cid:112) i(cid:115) (cid:112)(cid:114) (cid:107)(cid:0) (cid:67) a(cid:79)(cid:114) (cid:106)(cid:65)(cid:110)(cid:107)(cid:65)(cid:114)(cid:70) (cid:115)(cid:65)(cid:74)(cid:65) (cid:107)(cid:114) (cid:115)(cid:107)(cid:3)(cid:92) (cid:116)(cid:65)(cid:69)(cid:107) (cid:104)(cid:109) a(cid:65)(cid:112)(cid:107)(cid:70) (cid:98)(cid:3)(cid:104)(cid:116)(cid:114) (cid:115)(cid:104)(cid:65)(cid:121)(cid:116)(cid:65) (cid:107)(cid:114) (cid:115)(cid:107)(cid:3)(cid:92)।\nAgent\ncompassion (1), anticipation (2)\n(I understand the situation is not good for you. It would be great if you could share few more information on this so that\nwe could better assist you.)"
        },
        {
          "Speaker\nUtterances\nEmotion & corresponding intensity": "Dialogue 2"
        },
        {
          "Speaker\nUtterances\nEmotion & corresponding intensity": "(cid:109)\n(cid:92) (cid:87)(cid:103)(cid:65) (cid:103)(cid:121)(cid:65) (cid:104)(cid:1)(cid:32)।\nVictim\nsad (3)\n(I am cheated.)"
        },
        {
          "Speaker\nUtterances\nEmotion & corresponding intensity": "(cid:69)(cid:107)(cid:115)(cid:110)(cid:3) (cid:68)(cid:111)(cid:75)(cid:65)\n(cid:69)(cid:100)(cid:121)(cid:65) (cid:104)(cid:123) ?\n(cid:121)(cid:104) (cid:115)(cid:0) (cid:110)(cid:107)(cid:114) (cid:118)(cid:65)(cid:45)(cid:116)(cid:118) (cid:109)(cid:3)(cid:92)\n(cid:69)(cid:110)(cid:114)(cid:65)(cid:102)(cid:65) (cid:104)(cid:0) (cid:73) , (cid:109)(cid:3)(cid:114)(cid:3) (cid:69)pr(cid:121)। ky(cid:65) a(cid:65)(cid:112) (cid:121)(cid:104) (cid:115)(cid:65)(cid:74)(cid:65) (cid:107)(cid:114)(cid:110)(cid:65) (cid:99)(cid:65)(cid:104)(cid:3)(cid:92)(cid:103)(cid:3) (cid:69)(cid:107) a(cid:65)(cid:112)(cid:107)(cid:111)\nAgent\nsad (2), anticipation (1)\n(This is really disappointing to hear, my dear. Would you mind sharing who has cheated you?)"
        },
        {
          "Speaker\nUtterances\nEmotion & corresponding intensity": "(cid:3)(cid:114)(cid:3) (cid:112)(cid:69)(cid:116) (cid:110)(cid:3) (cid:109)(cid:0) (cid:74)(cid:3) (cid:100)(cid:1) (cid:115)(cid:114)(cid:70) a(cid:79)(cid:114)(cid:116) (cid:107)(cid:3) (cid:69)(cid:108)e (cid:68)(cid:111)(cid:75)(cid:65)\n(cid:69)(cid:100)(cid:121)(cid:65)। (cid:118)(cid:104) e(cid:107) (cid:69)(cid:103)(cid:114)(cid:65) (cid:104)(cid:0) a(cid:65) i(cid:92)(cid:115)(cid:65)(cid:110) (cid:104)(cid:123)।\nVictim\nsad (3), anger (3)\n(My husband cheated on me for another women. He is such a creep.)"
        },
        {
          "Speaker\nUtterances\nEmotion & corresponding intensity": "(cid:104)(cid:109) a(cid:65)(cid:112)(cid:107)(cid:65) (cid:100)(cid:100)(cid:13) (cid:115)(cid:109)(cid:74)(cid:116)(cid:3) (cid:104)(cid:123)(cid:92)। (cid:107)(cid:2) (cid:112)(cid:121)(cid:65) (cid:102)(cid:65)(cid:92)(cid:116) (cid:104)(cid:111) (cid:106)(cid:65)e(cid:92) ;\n(cid:104)(cid:109) a(cid:65)(cid:112)(cid:107)(cid:3) (cid:115)(cid:65)(cid:84) (cid:104)(cid:123)(cid:92) a(cid:79)(cid:114) a(cid:65)(cid:112)(cid:107)(cid:70) (cid:104)(cid:114) (cid:115)(cid:92)(cid:66)(cid:118) (cid:109)(cid:100)(cid:100) (cid:107)(cid:114)(cid:110)(cid:3) (cid:107)(cid:70) (cid:112)(cid:1) (cid:114)(cid:70) (cid:107)(cid:111)(cid:69)(cid:102)(cid:102) (cid:107)(cid:114)(cid:3)(cid:92)(cid:103)(cid:3)। (cid:121)(cid:69)(cid:100) a(cid:65)(cid:112) (cid:115)(cid:104)(cid:106) (cid:104)(cid:123)(cid:92) , (cid:116)(cid:111) (cid:98)(cid:3)(cid:104)(cid:116)(cid:114) (cid:115)(cid:104)(cid:65)(cid:121)(cid:116)(cid:65) (cid:107)(cid:3) (cid:69)(cid:108)e (cid:104)(cid:109) a(cid:65)(cid:112)(cid:115)(cid:3) (cid:107)(cid:0) (cid:67) a(cid:79)(cid:114) (cid:69)(cid:118)(cid:118)(cid:114)(cid:90) (cid:112)(cid:1) (cid:67)(cid:110)(cid:65) (cid:99)(cid:65)(cid:104)(cid:3)(cid:92)(cid:103)(cid:3)।\ncompassion (2), compassion (3),\nAgent\n(We understand your pain. Please calm down; we are with you and will do our best to help you in every possible way. If you are comfortable, we would like to ask\nanticipation (2)\nyou few more details for better assistance.)"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 1: which shows different empathetic Anger 5582",
      "data": [
        {
          "Emotions": "Anticipation",
          "Dataset": "7654"
        },
        {
          "Emotions": "Anger",
          "Dataset": "5582"
        },
        {
          "Emotions": "Sad",
          "Dataset": "5118"
        },
        {
          "Emotions": "Conﬁdent",
          "Dataset": "4477"
        },
        {
          "Emotions": "Fear",
          "Dataset": "4368"
        },
        {
          "Emotions": "Disguted",
          "Dataset": "4060"
        },
        {
          "Emotions": "Surprised",
          "Dataset": "3778"
        },
        {
          "Emotions": "Hopeful",
          "Dataset": "3729"
        },
        {
          "Emotions": "Annoyed",
          "Dataset": "3660"
        },
        {
          "Emotions": "Compassion",
          "Dataset": "3218"
        },
        {
          "Emotions": "Joy",
          "Dataset": "3130"
        },
        {
          "Emotions": "Apprehensive",
          "Dataset": "2637"
        },
        {
          "Emotions": "Grateful",
          "Dataset": "1406"
        },
        {
          "Emotions": "Guilty",
          "Dataset": "1269"
        },
        {
          "Emotions": "Impressed",
          "Dataset": "595"
        },
        {
          "Emotions": "Neutral",
          "Dataset": "9003"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 1: which shows different empathetic Anger 5582",
      "data": [
        {
          "Metrics": "# Dialogues",
          "Dataset": "1814"
        },
        {
          "Metrics": "# Utterances",
          "Dataset": "44247"
        },
        {
          "Metrics": "Avg. utterances per dialogue",
          "Dataset": "24.39"
        },
        {
          "Metrics": "Avg. # of emotions per dialogue",
          "Dataset": "1.41"
        },
        {
          "Metrics": "Avg. # of emotions per utterance",
          "Dataset": "1.43"
        },
        {
          "Metrics": "# of unique tokens",
          "Dataset": "7036"
        },
        {
          "Metrics": "Avg. # of tokens per utterance",
          "Dataset": "18.67"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 2: , we provide the important statistics of the ModelLoss MultiLabelSoftMarginLoss(Emotion)&negativelog-likelihood(EmotionIntensity)",
      "data": [
        {
          "Dataset": "(Vijay et al., 2018)",
          "# of sentences": "2866",
          "# of emotions": "6",
          "Emotion Intensity\nAnnotation": "No",
          "Language": "Hindi-English\ncode-mixed",
          "Conversational": "No",
          "Multi-label": "No"
        },
        {
          "Dataset": "(Koolagudi et al., 2011)",
          "# of sentences": "12000",
          "# of emotions": "8",
          "Emotion Intensity\nAnnotation": "No",
          "Language": "Hindi",
          "Conversational": "No",
          "Multi-label": "No"
        },
        {
          "Dataset": "(Harikrishna and Rao, 2016)",
          "# of sentences": "780",
          "# of emotions": "5",
          "Emotion Intensity\nAnnotation": "No",
          "Language": "Hindi",
          "Conversational": "No",
          "Multi-label": "No"
        },
        {
          "Dataset": "(Kumar et al., 2019)",
          "# of sentences": "20304",
          "# of emotions": "5",
          "Emotion Intensity\nAnnotation": "No",
          "Language": "Hindi",
          "Conversational": "No",
          "Multi-label": "No"
        },
        {
          "Dataset": "(Ahmad et al., 2020)",
          "# of sentences": "2668",
          "# of emotions": "9",
          "Emotion Intensity\nAnnotation": "No",
          "Language": "Hindi",
          "Conversational": "No",
          "Multi-label": "No"
        },
        {
          "Dataset": "EmoInHindi",
          "# of sentences": "44247",
          "# of emotions": "16",
          "Emotion Intensity\nAnnotation": "Yes",
          "Language": "Hindi",
          "Conversational": "Yes",
          "Multi-label": "Yes"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "METHODS": "",
          "TASK-TYPE": "Emotion\n√",
          "ACC": "",
          "MICRO-F1": "",
          "HL": "",
          "JI": ""
        },
        {
          "METHODS": "bc-LSTM",
          "TASK-TYPE": "√\n√",
          "ACC": "0.60\n0.63",
          "MICRO-F1": "0.63\n0.65",
          "HL": "0.081\n0.077",
          "JI": "0.57\n0.59"
        },
        {
          "METHODS": "bc-LSTM+ATT",
          "TASK-TYPE": "√\n√",
          "ACC": "0.61\n0.64",
          "MICRO-F1": "0.63\n0.67",
          "HL": "0.079\n0.075",
          "JI": "0.57\n0.60"
        },
        {
          "METHODS": "CMN",
          "TASK-TYPE": "√\n√",
          "ACC": "0.63\n0.64",
          "MICRO-F1": "0.66\n0.68",
          "HL": "0.076\n0.073",
          "JI": "0.59\n0.61"
        },
        {
          "METHODS": "C-A-Trans",
          "TASK-TYPE": "√\n√",
          "ACC": "0.67\n0.69",
          "MICRO-F1": "0.71\n0.73",
          "HL": "0.066\n0.059",
          "JI": "0.64\n0.66"
        },
        {
          "METHODS": "C-F-Trans",
          "TASK-TYPE": "√",
          "ACC": "0.70\n0.72",
          "MICRO-F1": "0.76\n0.77",
          "HL": "0.057\n0.055",
          "JI": "0.68\n0.69"
        }
      ],
      "page": 6
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Bibliographical References",
      "venue": "Bibliographical References"
    },
    {
      "citation_id": "2",
      "title": "Borrow from rich cousin: transfer learning for emotion detection using cross lingual embedding",
      "authors": [
        "Z Ahmad",
        "R Jindal",
        "A Ekbal",
        "P Bhattachharyya"
      ],
      "year": "2020",
      "venue": "Expert Systems with Applications"
    },
    {
      "citation_id": "3",
      "title": "Semeval-2019 task 3: Emocontext contextual emotion detection in text",
      "authors": [
        "A Chatterjee",
        "K Narahari",
        "M Joshi",
        "P Agrawal"
      ],
      "year": "2019",
      "venue": "Proceedings of the 13th international workshop on semantic evaluation"
    },
    {
      "citation_id": "4",
      "title": "Emotionlines: An emotion corpus of multi-party conversations",
      "authors": [
        "S.-Y Chen",
        "C.-C Hsu",
        "C.-C Kuo",
        "L.-W Ku"
      ],
      "year": "2018",
      "venue": "Emotionlines: An emotion corpus of multi-party conversations",
      "arxiv": "arXiv:1802.08379"
    },
    {
      "citation_id": "5",
      "title": "An argument for basic emotions",
      "authors": [
        "P Ekman"
      ],
      "year": "1992",
      "venue": "Cognition & emotion"
    },
    {
      "citation_id": "6",
      "title": "Emowoz: A large-scale corpus and labelling scheme for emotion in task-oriented dialogue systems",
      "authors": [
        "S Feng",
        "N Lubis",
        "C Geishauser",
        "H.-C Lin",
        "M Heck",
        "C Van Niekerk",
        "M Gašić"
      ],
      "year": "2021",
      "venue": "Emowoz: A large-scale corpus and labelling scheme for emotion in task-oriented dialogue systems",
      "arxiv": "arXiv:2109.04919"
    },
    {
      "citation_id": "7",
      "title": "Meisd: a multimodal multi-label emotion, intensity and sentiment dialogue dataset for emotion recognition and sentiment analysis in conversations",
      "authors": [
        "M Firdaus",
        "H Chauhan",
        "A Ekbal",
        "P Bhattacharyya"
      ],
      "year": "2020",
      "venue": "Proceedings of the 28th International Conference on Computational Linguistics"
    },
    {
      "citation_id": "8",
      "title": "Measuring nominal scale agreement among many raters",
      "authors": [
        "J Fleiss"
      ],
      "year": "1971",
      "venue": "Psychological bulletin"
    },
    {
      "citation_id": "9",
      "title": "Dialoguegcn: A graph convolutional neural network for emotion recognition in conversation",
      "authors": [
        "D Ghosal",
        "N Majumder",
        "S Poria",
        "N Chhaya",
        "A Gelbukh"
      ],
      "year": "2019",
      "venue": "Dialoguegcn: A graph convolutional neural network for emotion recognition in conversation",
      "arxiv": "arXiv:1908.11540"
    },
    {
      "citation_id": "10",
      "title": "Irony in language and thought: A cognitive science reader",
      "authors": [
        "R Gibbs",
        "R Gibbs",
        "H Colston"
      ],
      "year": "2007",
      "venue": "Irony in language and thought: A cognitive science reader"
    },
    {
      "citation_id": "11",
      "title": "Emotionspecific features for classifying emotions in story text",
      "authors": [
        "D Harikrishna",
        "K Rao"
      ],
      "year": "2016",
      "venue": "2016 Twenty Second National Conference on Communication (NCC)"
    },
    {
      "citation_id": "12",
      "title": "Conversational memory network for emotion recognition in dyadic dialogue videos",
      "authors": [
        "D Hazarika",
        "S Poria",
        "A Zadeh",
        "E Cambria",
        "L.-P Morency",
        "R Zimmermann"
      ],
      "year": "2018",
      "venue": "Proceedings of the conference"
    },
    {
      "citation_id": "13",
      "title": "Joint binary neural network for multi-label learning with applications to emotion classification",
      "authors": [
        "H He",
        "R Xia"
      ],
      "year": "2018",
      "venue": "CCF International Conference on Natural Language Processing and Chinese Computing"
    },
    {
      "citation_id": "14",
      "title": "Seq2emo for multi-label emotion classification based on latent variable chains transformation",
      "authors": [
        "C Huang",
        "A Trabelsi",
        "X Qin",
        "N Farruque",
        "O Zaïane"
      ],
      "year": "2019",
      "venue": "Seq2emo for multi-label emotion classification based on latent variable chains transformation",
      "arxiv": "arXiv:1911.02147"
    },
    {
      "citation_id": "15",
      "title": "Fasttext. zip: Compressing text classification models",
      "authors": [
        "A Joulin",
        "E Grave",
        "P Bojanowski",
        "M Douze",
        "H Jégou",
        "T Mikolov"
      ],
      "year": "2016",
      "venue": "Fasttext. zip: Compressing text classification models",
      "arxiv": "arXiv:1612.03651"
    },
    {
      "citation_id": "16",
      "title": "An iterative design methodology for user-friendly natural language office information applications",
      "authors": [
        "J Kelley"
      ],
      "year": "1984",
      "venue": "ACM Transactions on Information Systems (TOIS)"
    },
    {
      "citation_id": "17",
      "title": "Multitask learning using uncertainty to weigh losses for scene geometry and semantics",
      "authors": [
        "A Kendall",
        "Y Gal",
        "R Cipolla"
      ],
      "year": "2018",
      "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition"
    },
    {
      "citation_id": "18",
      "title": "Attnconvnet at semeval-2018 task 1: Attention-based convolutional neural networks for multi-label emotion classification",
      "authors": [
        "Y Kim",
        "H Lee",
        "K Jung"
      ],
      "year": "2018",
      "venue": "Attnconvnet at semeval-2018 task 1: Attention-based convolutional neural networks for multi-label emotion classification",
      "arxiv": "arXiv:1804.00831"
    },
    {
      "citation_id": "19",
      "title": "Iitkgp-sehsc: Hindi speech corpus for emotion analysis",
      "authors": [
        "S Koolagudi",
        "R Reddy",
        "J Yadav",
        "K Rao"
      ],
      "year": "2011",
      "venue": "2011 International conference on devices and communications (ICDeCom)"
    },
    {
      "citation_id": "20",
      "title": "Bhaav-a text corpus for emotion analysis from hindi stories",
      "authors": [
        "Y Kumar",
        "D Mahata",
        "S Aggarwal",
        "A Chugh",
        "R Maheshwari",
        "R Shah"
      ],
      "year": "2019",
      "venue": "Bhaav-a text corpus for emotion analysis from hindi stories",
      "arxiv": "arXiv:1910.04073"
    },
    {
      "citation_id": "21",
      "title": "Fnet: Mixing tokens with fourier transforms",
      "authors": [
        "J Lee-Thorp",
        "J Ainslie",
        "I Eckstein",
        "S Ontanon"
      ],
      "year": "2021",
      "venue": "Fnet: Mixing tokens with fourier transforms",
      "arxiv": "arXiv:2105.03824"
    },
    {
      "citation_id": "22",
      "title": "Dailydialog: A manually labelled multi-turn dialogue dataset",
      "authors": [
        "Y Li",
        "H Su",
        "X Shen",
        "W Li",
        "Z Cao",
        "S Niu"
      ],
      "year": "2017",
      "venue": "Dailydialog: A manually labelled multi-turn dialogue dataset",
      "arxiv": "arXiv:1710.03957"
    },
    {
      "citation_id": "23",
      "title": "The error is the clue: Breakdown in human-machine interaction",
      "authors": [
        "B Martinovsky",
        "D Traum"
      ],
      "year": "2006",
      "venue": "The error is the clue: Breakdown in human-machine interaction"
    },
    {
      "citation_id": "24",
      "title": "Biological foundations of emotion",
      "authors": [
        "R Plutchik",
        "H Kellerman"
      ],
      "year": "2013",
      "venue": "Biological foundations of emotion"
    },
    {
      "citation_id": "25",
      "title": "Contextdependent sentiment analysis in user-generated videos",
      "authors": [
        "S Poria",
        "E Cambria",
        "D Hazarika",
        "N Majumder",
        "A Zadeh",
        "L.-P Morency"
      ],
      "year": "2017",
      "venue": "Proceedings of the 55th annual meeting of the association for computational linguistics"
    },
    {
      "citation_id": "26",
      "title": "The empathic companion: A character-based interface that addresses users'affective states",
      "authors": [
        "H Prendinger",
        "M Ishizuka"
      ],
      "year": "2005",
      "venue": "Applied artificial intelligence"
    },
    {
      "citation_id": "27",
      "title": "Attention is all you need",
      "authors": [
        "A Vaswani",
        "N Shazeer",
        "N Parmar",
        "J Uszkoreit",
        "L Jones",
        "A Gomez",
        "Ł Kaiser",
        "I Polosukhin"
      ],
      "year": "2017",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "28",
      "title": "Corpus creation and emotion prediction for hindi-english code-mixed social media text",
      "authors": [
        "D Vijay",
        "A Bohra",
        "V Singh",
        "S Akhtar",
        "M Shrivastava"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference of the North American Chapter"
    },
    {
      "citation_id": "29",
      "title": "Current state of text sentiment analysis from opinion to emotion mining",
      "authors": [
        "A Yadollahi",
        "A Shahraki",
        "O Zaiane"
      ],
      "year": "2017",
      "venue": "ACM Computing Surveys (CSUR)"
    },
    {
      "citation_id": "30",
      "title": "An interaction-aware attention network for speech emotion recognition in spoken dialogs",
      "authors": [
        "S.-L Yeh",
        "Y.-S Lin",
        "C.-C Lee"
      ],
      "year": "2019",
      "venue": "ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
    },
    {
      "citation_id": "31",
      "title": "Improving multi-label emotion classification via sentiment classification with dual attention transfer network",
      "authors": [
        "J Yu",
        "L Marujo",
        "J Jiang",
        "P Karuturi",
        "W Brendel"
      ],
      "year": "2018",
      "venue": "Improving multi-label emotion classification via sentiment classification with dual attention transfer network"
    }
  ]
}