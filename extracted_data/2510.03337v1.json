{
  "paper_id": "2510.03337v1",
  "title": "Error Correction In Multiclass Image Classification Of Facial Emotion On Unbalanced Samples",
  "published": "2025-10-02T09:31:51Z",
  "authors": [
    "Andrey A. Lebedev",
    "Victor B. Kazantsev",
    "Sergey V. Stasenko"
  ],
  "keywords": [
    "multi-class classification",
    "unbalanced samples",
    "LSTM",
    "attention mechanism",
    "emotions in facial images",
    "classification error correction",
    "rare classes",
    "anti-fraud systems",
    "deep learning",
    "computer vision"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "This paper considers the problem of error correction in multi-class classification of face images on unbalanced samples. The study is based on the analysis of a data frame containing images labeled by seven different emotional states of people of different ages. Particular attention is paid to the problem of class imbalance, in which some emotions significantly prevail over others. To solve the classification problem, a neural network model based on LSTM with an attention mechanism focusing on key areas of the face that are informative for emotion recognition is used. As part of the experiments, the model is trained on all possible configurations of subsets of six classes with subsequent error correction for the seventh class, excluded at the training stage. The results show that correction is possible for all classes, although the degree of success varies: some classes are better restored, others are worse. In addition, on the test sample, when correcting some classes, an increase in key quality metrics for small classes was recorded, which indicates the promise of the proposed approach in solving applied problems related to the search for rare events, for example, in anti-fraud systems. Thus, the proposed method can be effectively applied in facial expression analysis systems and in tasks requiring stable classification under skewed class distribution. Keywords multi-class classification • unbalanced samples • LSTM • attention mechanism • emotions in facial images • classification error correction • rare classes • anti-fraud systems • deep learning • computer vision",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Introduction",
      "text": "Accurate facial emotion recognition has become a cornerstone in the broader domain of affective computing, which seeks to develop systems capable of recognizing, interpreting, and responding to human emotions using computational methods  [1] [2] [3] . However, one persistent challenge in facial expression classification is the presence of imbalanced class distributions, where certain emotions are significantly underrepresented  [4, 5] . Class imbalance often degrades model generalization, leading to biased predictions toward majority classes and poorer recognition of subtle or rare emotions such as fear or disgust  [6] .\n\nTo address such imbalances, researchers have proposed several strategies. Resampling techniques-such as oversampling minority classes or undersampling majority classes-are commonly employed to rebalance datasets, though they risk introducing redundancy or discarding critical information  [7, 8] . Another avenue involves loss reweighting, where algorithms adjust the learning focus by assigning greater weight to underrepresented classes. Methods such as classbalanced loss, focal loss, and label-distribution-aware margins exemplify this approach  [9] [10] [11] . Hybrid approaches that combine reweighting with resampling have also been shown to improve robustness in imbalanced emotion datasets  [12] .\n\nDeep neural networks enhanced with attention mechanisms have demonstrated considerable promise in emotion recognition tasks. For instance, models integrating attention within CNN-LSTM architectures allow the system to focus on discriminative facial regions, improving performance  [14] [15] [16] . Furthermore, attention-based frameworks have been used explicitly to handle uncertainties and class imbalances by emphasizing learning from underrepresented samples  [13, 18] . Self-attention and Transformer-based designs have also gained traction for emotion recognition, outperforming traditional CNN-based approaches in scenarios with noisy or imbalanced data  [19, 20] .\n\nAlongside these approaches, a complementary line of research emphasizes AI error correction without retraining legacy systems. This paradigm, pioneered by Gorban and colleagues, introduces external correctors-lightweight modules that detect risky cases and propose alternative decisions. The theoretical foundation rests on stochastic separation theorems, which demonstrate that in high-dimensional spaces, even simple classifiers (such as Fisher's linear discriminants) can separate error cases from correctly classified ones with high probability  [23] . This leads to practical one-shot correction methods capable of improving system reliability without iterative retraining  [24] . More recent advances generalize these results to fine-grained, clustered data distributions, showing that families of multi-correctors can handle complex structures and even facilitate new class discovery in high-dimensional settings  [25, 26] . These methods have been validated on benchmarks such as CIFAR-10, where external correctors successfully amended errors of deep convolutional networks and supported incremental learning of novel object classes. Despite these advances, most studies focus on models trained directly on the full emotion set, with balanced or rebalanced inputs, rather than exploring error correction strategies that recover missing or excluded classes. Your novel approach addresses this gap by using an LSTM-based model with attention that is trained on subsets of classes, with subsequent error correction applied to the omitted (seventh) class.\n\nIn your experiments, the model is trained on all possible combinations of six out of seven emotion classes, and then evaluated on its ability to correct for the seventh class that was held out during training. Your results show that while the success rate of correction varies per class, even small or rare emotion classes benefit, with key quality metrics-such as precision or recall-improving for those minority classes. These findings complement recent evidence showing that auxiliary learning and reconstruction-based strategies can significantly enhance minority class recognition in affective computing tasks  [21, 22] . This finding is particularly significant for real-world applications where detecting rare or atypical emotional signals can be critical-for example, in anti-fraud systems or security contexts. The potential to enhance recognition of these low-frequency classes underscores the practical value of your method in scenarios requiring robust classification under skewed class distributions.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Methodology",
      "text": "",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "The Corrector Model",
      "text": "Let's consider the problem of multiclass classification in the feature space. Let\n\nThe basic classifier is defined by the mapping\n\nwhich assigns a class label f (x)toeachpointx ∈ X ∈ Y.\n\nIn this case, the model additionally induces the display e :\n\n,\n\nwhere e(x) is interpreted as an embedding vector obtained during the inference process.\n\nTo build a correction mechanism, we introduce the binary mapping\n\nwhere g(z) = 0 corresponds to familiar data, and g(z) = 1 corresponds to unfamiliar (out-of-distribution).\n\nBased on this, we define a generalized classifier with correction:\n\nThus, the h function combines two mechanisms:\n\n1. standard classification by means of f on a set of known classes Y; 2. identification of new or missing classes using the g corrector.\n\nThis separation makes it possible to formalize the error correction task of a pre-trained system as a combination of the classification task and the task of detecting unknown data. In particular, the proposed approach provides:\n\n• resilience to the appearance of classes that were missing at the learning stage;\n\n• the ability to process unbalanced samples by highlighting \"rare\" or excluded classes;\n\n• extending the functionality of the original f classifier to the more general h system.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Metrics For Evaluating The Quality Of A Proofreader",
      "text": "Let's give the test set D = {(x j , y j )} N j=1 , where y j ∈ Y = {1, . . . , K}. Let's denote the predictions of the basic (without correction) model f by ŷ(f) j , and the predictions of the system with correction h by ŷ(h) j . For a fixed class i ∈ Y, we assume\n\nLet's introduce a set of indexes of class i samples that have been correctly classified by one system or another:\n\nWe also denote the error sets (for class i):",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Basic One-Class Metrics.",
      "text": "First-class accuracy (synonyms of TPR for each class):\n\nRelative and absolute increment:\n\nwhere ε > 0 is a small regularization for stability at zero base.\n\nConservation and harm metrics for already correctly classified samples. The characteristic we are interested in is how the corrector affects those samples that have already been correctly classified by f . We introduce the following concepts.\n\nRetention -the proportion of samples of class i that were correctly recognized by f , which remained correctly recognized even after applying the corrector:\n\nHarm (harm) -the proportion of i class samples correctly recognized by f that became erroneous after correction:\n\nCorrection gain -the proportion of previously misclassified Class i samples that became correct after correction:",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Metrics Of \"Spillover\" And False Positives On Other Classes.",
      "text": "To take into account how the corrector affects the incorrect reassignment of the label towards the class i, we define\n\nN -N i -the proportion of samples from other classes that were classified as class i by the h system (i.e., \"false positive for i\"). Accordingly, for f :\n\nFalse-positive percentage change:",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Summary Indicators And Standards.",
      "text": "The following aggregates are offered for a summary assessment:\n\nYou can also weight the frequencies of the classes N i /N , if desired, to get a \"micro\" version of the metrics:",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Interpretation Of Metrics.",
      "text": "• Ret i close to 1 means that the corrector does not spoil the already correctly recognized samples of class i.\n\n• Harm i demonstrates the share of \"collateral damage\" for already correct predictions; the lower the better.\n\n• Gain i shows the corrector's ability to restore previously erroneous examples of this class.\n\n• ∆FPR i > 0 indicates an increase in false-positive assignments to class i (side effect).",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Statement Of The Problem",
      "text": "In this paper, we propose a method for error correction in the problem of multi-class classification of facial images with unbalanced samples using an ensemble of a neural network model and a gradient boosting algorithm. The experiments were performed on a dataset containing data on 7 classes of emotional states of people of different ages with a pronounced imbalance in the distribution by classes. The method includes the following stages:\n\nIterative exclusion of classes. For each experiment, one class is excluded from the training set. The model is trained on the remaining six classes, and the excluded one is used at the inference and correction stage. Thus, a sequential analysis of the model's behavior is carried out in the absence of each of the classes.\n\nBase model: LSTM with an attention mechanism.  The images are highly diverse in features such as age, gender, ethnicity, head rotation, lighting conditions, and the presence of partial occlusions (e.g. glasses, beard, or self-occlusion). In addition, the images may contain filters and special effects, which makes the dataset particularly suitable for emotion recognition tasks in near-real-world settings.\n\nFigure  1 : Examples of images labeled with different emotions in the sample, according to the labeling shown in Table  1 .\n\nTo conduct experiments according to the described methodology, it is necessary to select three random subsets from the initial data:",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Technical Implementation Of The Experiment",
      "text": "To solve the problem of classifying emotions in facial images, a custom neural network model was developed that combines convolutional layers for feature extraction, a recurrent component (LSTM) for modeling the spatial-sequential structure, and an attention mechanism for identifying the most informative features.   Consists of three convolutional blocks, each of which includes:\n\n• convolutional layer (Conv2d) with kernel 3 × 3, stride 1 and padding 1;\n\n• batch normalization (BatchNorm2d);\n\n• ReLU activation function;\n\n• pooling layer MaxPooling with kernel 2 × 2.\n\nLayer parameters:\n\n• Conv1: in_channels=3, out_channels=32;\n\n• Conv2: in_channels=32, out_channels=64;\n\n• Conv3: in_channels=64, out_channels=128.\n\nAt the output of the block, spatial feature maps of dimension [B, 128, H ′ , W ′ ], where B is the batch size, are formed.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Nn Block",
      "text": "",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Recurrent Block (Rnn)",
      "text": "The output of the convolutional block is transformed into a sequence: the tensor is transformed into the form [B, T, D],\n\nwhere T = H ′ • W ′ , and D = 128. On this sequence, an LSTM is applied with the following parameters:\n\n• input and hidden state size: 128;\n\n• batch_first=True.\n\nThis allows the model to capture spatial dependencies between different regions of the image.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Attention Mechanism (Attention)",
      "text": "The output of the LSTM is a multi-headed attention mechanism (MultiheadAttention):\n\n• key, query, and value dimensions: 128;\n\n• one projection layer (out_proj) is used at the output.\n\nThe attention mechanism allows the model to focus on the most significant areas of the face when making a classification decision.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Classification Head / Fully Connected Classifier (Fc_Layers)",
      "text": "The attention result is aggregated and fed to the fully connected part of the model:\n\n• Linear(128 → 128) with ReLU activation;\n\n• Dropout(p=0.5) for regularization;\n\n• Linear(128 → 7) is the output layer for classification by N emotions.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Loss Function",
      "text": "Since there is a pronounced imbalance between the classes in the training set, a weighted loss function is used. The class weights are calculated as the ratio of the total number of examples to the number of examples in each class:\n\nwhere N is the total number of samples, n i is the number of samples of the i-th class.\n\nNext, the cross-entropy loss function is used:\n\nwhere C is the number of classes, y i is the true label, ŷi is the model output (softmax probability) for class i, and w i is the class weight.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Early Stopping Mechanism",
      "text": "To determine the criterion for early learning stoppage, we tried several different rules based on the average roc-auc-score, loss function, and average accuracy. It has been empirically found that the best rule for stopping learning in the proposed architecture is:\n\n• loss function on train set → min;\n\n• accuracy on the validation set → max.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Model Training.",
      "text": "The results of a study of a descriptive neural network in conjugation of both grades 6 and 7 showed, in the form of a segmented metric, the accuracy of determining classes in the table 4.\n\nAccuracy is calculated as the proportion of correctly predicted labels:\n\nwhere I is the indicator function.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Extraction Of Hidden Features",
      "text": "For correction, a method of repeated inference of the model on additional images that were not included in the training and validation samples was used. During the inference process, the values of all intermediate representations (feature maps and hidden states) were saved at the stages:\n\n• output from convolutional layers;\n\n• output from the LSTM layer;\n\n• after applying the attention mechanism (Multihead Attention);\n\n• output from the fully connected layer before the final classification.\n\nThus, for each image, a vector of hidden features was formed, containing multi-level information about its spatial and semantic content.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Mechanism For Correcting Neural Network Predictions",
      "text": "After completing the training of the basic neural network model, an additional stage of analysis and correction of predictions was implemented in order to improve the quality of classification under uncertainty on new data.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Training A Gradient Boosted Model",
      "text": "The generated latent feature vectors were used as input for a gradient boosting model (e.g., XGBoost or LightGBM).\n\nThe target variable was the true class label of the image.\n\nA special feature of the approach is that the boosting model is trained on examples that were not used to train the original neural network. This allows boosting to identify patterns in the latent representations that were not covered by LSTM training, and thus compensate for possible gaps in the generalization ability of the base model.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Training The Corrector.",
      "text": "To train the corrector, we used the XGBoost implementation with parameters selected empirically.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Using The Corrector",
      "text": "After training, the corrector model was used as an additional filter: during inference, the main model passes the hidden features to boosting, and, in case of a high error probability (g(z i ) < τ ), the prediction is either corrected or not depending on the decision policy.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Purpose Of The Method",
      "text": "Thus, gradient boosting acts as an external evaluator over the outputs of the neural network. It can:\n\n• improve the accuracy of class recognition on previously unseen data;\n\n• identify areas of low confidence in the neural network;\n\n• use more flexible dependencies between latent features and class labels.\n\nThis approach can be viewed as a type of stacking, where boosting serves as a meta-model trained on the embeddings of the base neural network.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Results",
      "text": "This section presents the quantitative results of applying the proposed classification error correction method. The analysis was carried out using the metrics Retention, Harm, changes in Gain, ∆FPR, as well as the integral performance characteristics listed below. 0.000 0.000 0.000 0.037 0.005 0.003 0.029 2 0.102 0.000 0.023 0.011 0.000 0.023 0.000 3 0.000 0.000 0.000 0.023 0.000 0.000 0.055 4 0.001 0.001 0.001 0.000 0.003 0.001 0.025 5 0.008 0.000 0.005 0.124 0.000 0.000 0.119 6 0.019 0.005 0.000 0.097 0.032 0.000 0.023 7 0.018 0.001 0.003 0.045 0.043 0.000 0.000 Average 0.021 0.001 0.005 0.048 0.012 0.004 0.036 Table  2 : Values of Harm and Retention metrics for all classes. The Harm metric reflects the proportion of examples that were correctly classified by the original model, but became erroneous after applying the corrector. The Retention metric shows the proportion of correct predictions that remained after the correction. The values on the main diagonal are underlined and correspond to preserving/distorting predictions within the same class. The Retention and Harm metrics are also highlighted in red, which are higher and lower than the average, respectively.   3 : Summary metrics of proofreader quality for each class. ∆FPR -the average change in the false positive error after applying the corrector. Gain -the proportion of previously erroneous examples of the corrected class that were classified correctly.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Retention",
      "text": "",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Label",
      "text": "From the results shown in the 2 table, it can be seen that the values of Retention remain high (close to unity) in all cases, which indicates that most of the correct predictions of the basic model are preserved. The values of Harm, on the contrary, record cases when the corrector introduces distortions. From the table 2 it can be seen that the corrector does the most harm to the recognition of Fear(2) when correcting Surprise(1), Sadness  (5)  and Anger(6) when correcting Happiness(4) and Sadness(5) when correcting Neutral  (7)  Summary indicators of the corrector's effectiveness are given in the table 3. There is a positive trend for all classes Gain, which confirms the correctors ability to improve the completeness of the classification of the excluded class. The growth of ∆FPR remains relatively moderate, which makes the increase in Gain statistically significant. The greatest increase in quality is observed for «Happiness»(4), «Surprise»(1), «Disgusting»(3), «Neutral»(7) and even worse «Fear»(2), «Sadness»(5), «Anger»(6).\n\nThe table  4  shows the results of experiments to exclude classes from the training sample. In different cases, the correction allows for varying degrees of partial compensation for the loss of information about the excluded class. Values on the main diagonal (errors within its own class) highlighted in red, the maximum values by row (the best prediction option for this class) are green. The last column shows the accuracy of the original model without correction.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Predict",
      "text": "For a formal assessment of the corrector's contribution to the final quality of the classification, we introduce corrector power indicator P , which is defined as the ratio of classification accuracy with correction to accuracy without correction:\n\nAccuracy with corr Accuracy without corr .\n\nThe table  4  shows the values of the strength indicator of the corrector P . The best result was recorded for the class «Happiness» (P = 0.86), while for the classes «Sadness» and «Anger» the values P is significantly lower (P ≈ 0.30). This indicates a pronounced class dependence of the method's effectiveness: for some emotions, correction successfully restores accuracy, for others, the increase is lower.\n\nThus, the error correction method is a promising tool. It is capable of increasing the stability of multiclass classifiers in conditions of incomplete and unbalanced samples, but its effectiveness depends on the class structure and requires further research.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Discussion",
      "text": "However, in the general case, correction turns out to be less effective than complete retraining and does not allow reaching the level of a fully trained model. In turn, building a corrector is computationally much easier than completely retraining the model, as well as the proposed method allows you to create many correctors that implement a complex, nonlinear stack model. Further development of the approach may go in the direction of:\n\n• for using more compact embeddings;\n\n• scaling experiments on large samples to increase stability;\n\n• for developing adaptive correctors that take into account the semantic and statistical relationships of classes.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Conclusion",
      "text": "The results show that the proposed error correction method can significantly improve the quality of recognition of excluded classes, while maintaining high accuracy on already known data. However, a significant dependence of efficiency on the nature of a particular class has been revealed.\n\nHigh values of Retention indicate that the basic structure of the model's predictions is preserved., and the risk of quality deterioration for the initial classes remains low. At the same time, the values Harm and ∆FPR demonstrate, that the corrector can introduce undesirable distortions, especially in the case of emotions that are similar in feature space. Thus, the method has a positive effect, but requires careful adjustment.\n\nExperiments on class exclusion show that the corrector works especially successfully for classes with pronounced interclass similarity (for example, «Happiness»), whereas for classes less related to others (for example, «Sadness» and «Anger»), the effectiveness is noticeably lower.",
      "page_start": 10,
      "page_end": 10
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: The dataset contains 15,339 facial images labeled with basic and composite",
      "page": 5
    },
    {
      "caption": "Figure 1: Examples of images labeled with different emotions in the sample, according to the labeling shown in Table",
      "page": 5
    },
    {
      "caption": "Figure 2: Pie chart showing the proportion of classes in the initial sample.",
      "page": 6
    },
    {
      "caption": "Figure 3: Scheme of the developed convolutional neural network model with memory and attention",
      "page": 6
    }
  ],
  "tables": [
    {
      "caption": "Table 1: Toconductexperimentsaccordingtothedescribedmethodology,itisnecessarytoselectthreerandomsubsetsfromthe",
      "data": [
        {
          "Data Split": "Train"
        },
        {
          "Data Split": "814"
        },
        {
          "Data Split": "166"
        },
        {
          "Data Split": "449"
        },
        {
          "Data Split": "2974"
        },
        {
          "Data Split": "1216"
        },
        {
          "Data Split": "435"
        },
        {
          "Data Split": "1615"
        },
        {
          "Data Split": "7669"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Retention": ""
        },
        {
          "Retention": "Label"
        },
        {
          "Retention": "1\n2\n3\n4\n5\n6\n7\nAverage"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Harm": ""
        },
        {
          "Harm": "Label"
        },
        {
          "Harm": "1\n2\n3\n4\n5\n6\n7\nAverage"
        }
      ],
      "page": 9
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Affective computing: A review",
      "authors": [
        "J Tao",
        "T Tan"
      ],
      "year": "2005",
      "venue": "International Journal Of Automation And Computing"
    },
    {
      "citation_id": "2",
      "title": "Affect detection: An interdisciplinary review of models, methods, and their applications",
      "authors": [
        "R Calvo",
        "S D'mello"
      ],
      "year": "2010",
      "venue": "IEEE Transactions On Affective Computing"
    },
    {
      "citation_id": "3",
      "title": "Emotion recognition by deeply learned multi-channel textual and EEG features. Future Generation Computer Systems",
      "authors": [
        "Y Liu",
        "G Fu"
      ],
      "year": "2021",
      "venue": "Emotion recognition by deeply learned multi-channel textual and EEG features. Future Generation Computer Systems"
    },
    {
      "citation_id": "4",
      "title": "DEAP: A database for emotion analysis using physiological signals",
      "authors": [
        "S Koelstra",
        "C Muhl",
        "M Soleymani",
        "J Lee",
        "A Yazdani",
        "T Ebrahimi",
        "T Pun",
        "A Nijholt",
        "I Patras"
      ],
      "year": "2012",
      "venue": "IEEE Transactions On Affective Computing"
    },
    {
      "citation_id": "5",
      "title": "Automatic analysis of facial affect: A survey of registration, representation, and recognition",
      "authors": [
        "E Sariyanidi",
        "H Gunes",
        "A Cavallaro"
      ],
      "year": "2015",
      "venue": "IEEE Transactions On Pattern Analysis And Machine Intelligence"
    },
    {
      "citation_id": "6",
      "title": "Others Challenges in representation learning: A report on three machine learning contests",
      "authors": [
        "I Goodfellow",
        "D Erhan",
        "P Carrier",
        "A Courville",
        "M Mirza",
        "B Hamner",
        "W Cukierski",
        "Y Tang",
        "D Thaler",
        "D Lee"
      ],
      "year": "2013",
      "venue": "International Conference On Neural Information Processing"
    },
    {
      "citation_id": "7",
      "title": "Learning from imbalanced data",
      "authors": [
        "H He",
        "E Garcia"
      ],
      "year": "2009",
      "venue": "IEEE Transactions On Knowledge And Data Engineering"
    },
    {
      "citation_id": "8",
      "title": "Synthetic minority over-sampling technique",
      "authors": [
        "N Chawla",
        "K Bowyer",
        "L Hall",
        "W Kegelmeyer",
        "Smote"
      ],
      "year": "2002",
      "venue": "Journal Of Artificial Intelligence Research"
    },
    {
      "citation_id": "9",
      "title": "Class-balanced loss based on effective number of samples",
      "authors": [
        "Y Cui",
        "M Jia",
        "T Lin",
        "Y Song",
        "S Belongie"
      ],
      "year": "2019",
      "venue": "Proceedings Of The IEEE/CVF Conference On Computer Vision And Pattern Recognition"
    },
    {
      "citation_id": "10",
      "title": "Focal loss for dense object detection",
      "authors": [
        "T Lin",
        "P Goyal",
        "R Girshick",
        "K He",
        "P Dollár"
      ],
      "year": "2017",
      "venue": "Proceedings Of The IEEE International Conference On Computer Vision"
    },
    {
      "citation_id": "11",
      "title": "Striking the right balance with uncertainty",
      "authors": [
        "S Khan",
        "M Hayat",
        "S Zamir",
        "J Shen",
        "L Shao"
      ],
      "year": "2019",
      "venue": "IEEE Transactions On Pattern Analysis And Machine Intelligence"
    },
    {
      "citation_id": "12",
      "title": "Deep imbalanced learning for face recognition and attribute prediction",
      "authors": [
        "C Huang",
        "Y Li",
        "C Change Loy",
        "X Tang"
      ],
      "year": "2019",
      "venue": "IEEE Transactions On Pattern Analysis And Machine Intelligence"
    },
    {
      "citation_id": "13",
      "title": "Imbalanced data problem in machine learning: A review",
      "authors": [
        "M Altalhan",
        "A Algarni",
        "M Alouane"
      ],
      "year": "2025",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "14",
      "title": "A CNN-LSTM based deep neural networks for facial emotion detection in videos",
      "authors": [
        "A Hans",
        "S Rao"
      ],
      "year": "2021",
      "venue": "International Journal Of Advances In Signal And Image Sciences"
    },
    {
      "citation_id": "15",
      "title": "& Others Subject independent emotion recognition using EEG signals employing attention driven neural networks",
      "authors": [
        "A Rajpoot",
        "M Panicker"
      ],
      "year": "2022",
      "venue": "Biomedical Signal Processing And Control"
    },
    {
      "citation_id": "16",
      "title": "Region attention networks for pose and occlusion robust facial expression recognition",
      "authors": [
        "K Wang",
        "X Peng",
        "J Yang",
        "D Meng",
        "Y Qiao"
      ],
      "year": "2020",
      "venue": "IEEE Transactions On Image Processing"
    },
    {
      "citation_id": "17",
      "title": "Deep attention-based imbalanced image classification",
      "authors": [
        "L Wang",
        "L Zhang",
        "X Qi",
        "Z Yi"
      ],
      "year": "2021",
      "venue": "IEEE Transactions On Neural Networks And Learning Systems"
    },
    {
      "citation_id": "18",
      "title": "An integrated attention-guided deep convolutional neural network for facial expression recognition in the wild",
      "authors": [
        "S Saurav",
        "R Saini",
        "S Singh"
      ],
      "year": "2025",
      "venue": "Multimedia Tools And Applications"
    },
    {
      "citation_id": "19",
      "title": "Facial expression recognition with grid-wise attention and visual transformer",
      "authors": [
        "Q Huang",
        "C Huang",
        "X Wang",
        "F Jiang"
      ],
      "year": "2021",
      "venue": "Information Sciences"
    },
    {
      "citation_id": "20",
      "title": "Facial expression recognition based on attention mechanism. Scientific Programming",
      "authors": [
        "J Daihong",
        "D Lei",
        "P Jin"
      ],
      "year": "2021",
      "venue": "Facial expression recognition based on attention mechanism. Scientific Programming"
    },
    {
      "citation_id": "21",
      "title": "Data augmentation using conditional GANs for facial emotion recognition",
      "authors": [
        "W Yi",
        "Y Sun",
        "S He"
      ],
      "year": "2018",
      "venue": "Progress In Electromagnetics Research Symposium (PIERS-Toyama)"
    },
    {
      "citation_id": "22",
      "title": "Semi-supervised multimodal emotion recognition with classbalanced pseudo-labeling",
      "authors": [
        "H Chen",
        "C Guo",
        "Y Li",
        "P Zhang",
        "D Jiang"
      ],
      "year": "2023",
      "venue": "Proceedings Of The 31st ACM International Conference On Multimedia"
    },
    {
      "citation_id": "23",
      "title": "Stochastic separation theorems: how geometry may help to correct AI errors",
      "authors": [
        "A Gorban",
        "B Grechuk",
        "I Tyukin"
      ],
      "year": "2023",
      "venue": "Stochastic separation theorems: how geometry may help to correct AI errors"
    },
    {
      "citation_id": "24",
      "title": "Correction of AI systems by linear discriminants: Probabilistic foundations",
      "authors": [
        "A Gorban",
        "A Golubkov",
        "B Grechuk",
        "E Mirkes",
        "I Tyukin"
      ],
      "year": "2018",
      "venue": "Information Sciences"
    },
    {
      "citation_id": "25",
      "title": "High-dimensional separability for one-and few-shot learning",
      "authors": [
        "A Gorban",
        "B Grechuk",
        "E Mirkes",
        "S Stasenko",
        "I Tyukin"
      ],
      "year": "2021",
      "venue": "Entropy"
    },
    {
      "citation_id": "26",
      "title": "General stochastic separation theorems with optimal bounds. Neural Networks",
      "authors": [
        "B Grechuk",
        "A Gorban",
        "I Tyukin"
      ],
      "year": "2021",
      "venue": "General stochastic separation theorems with optimal bounds. Neural Networks"
    }
  ]
}