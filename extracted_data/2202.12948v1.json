{
  "paper_id": "2202.12948v1",
  "title": "Dagam: A Domain Adversarial Graph Attention Model For Subject Independent Eeg-Based Emotion Recognition",
  "published": "2022-02-27T08:02:07Z",
  "authors": [
    "Tao Xu",
    "Wang Dang",
    "Jiabao Wang",
    "Yun Zhou"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "One of the most significant challenges of EEGbased emotion recognition is the cross-subject EEG variations, leading to poor performance and generalizability. This paper proposes a novel EEGbased emotion recognition model called the domain adversarial graph attention model (DAGAM). The basic idea is to generate a graph to model multichannel EEG signals using biological topology. Graph theory can topologically describe and analyze relationships and mutual dependency between channels of EEG. Then, unlike other graph convolutional networks, self-attention pooling is applied to benefit salient EEG feature extraction from the graph, which effectively improves the performance. Finally, after graph pooling, the domain adversarial based on the graph is employed to identify and handle EEG variation across subjects, efficiently reaching good generalizability. We conduct extensive evaluations on two benchmark datasets (SEED and SEED IV) and obtain state-of-the-art results in subject-independent emotion recognition. Our model boosts the SEED accuracy to 92.59% (4.69% improvement) with the lowest standard deviation of 3.21% (2.92% decrements) and SEED IV accuracy to 80.74% (6.90% improvement) with the lowest standard deviation of 4.14% (3.88% decrements) respectively.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Investigating emotion recognition is a continuing concern within computer science. The findings and products of this emerging focus are increasingly applied to education, digital games, e-commerce, ad, e-health, and many other areas. Electroencephalogram (EEG) has been suggested as a promising tool to investigate human emotions as it can directly and precisely reflect cognitive and emotional states with relatively low costs. Thus, EEG-based emotion recognition has attracted considerable research attention and interest.\n\nHowever, studies of applying deep learning algorithms to EEG-based subject-independent emotion recognition are unsatisfactory. First, multichannel EEG signals have a structure based on biological topography, belonging to a non-Euclidean domain. Directly applying deep learning methods to EEG-based Recognition does not work well since these methods are designed for the tasks of CV and NLP. Second, the EEG signals vary significantly between individuals, leading to the different distribution of source domain and target domain. This makes it challenging to achieve good performance across subjects.\n\nThe human brain's structural and functional systems have features of biological topography. Graph theory can topologically describe and analyze relationships and mutual dependency between channels of EEG. The Graph Neural Networks (GNN)  [Scarselli et al., 2009]  make it promising to solve the classification problems on EEG data. Based on graph, many researchers have made great efforts  [Song et al., 2020]  [  Zhong et al., 2020] . These graph-based methods try to learn and extract the most salient features from the whole high dimensional graph feature space generated by EEG data. Although some existing research starts to recognize the critical role of EEG channels' topology, they do not fully utilize such structure to learn salient EEG features well.\n\nWhen EEG training and testing data from different individuals, most current recognition methods did not perform well. For EEG-based emotion recognition, the source domain and target domains' data distribution is different. This issue can be considered as a kind of domain adaptation.  Ganin et al. [Ganin et al., 2016]  proposed a domain-adversarial training of neural networks (DANN) to solve the cross-subject classification problem. Inspired by the idea of DANN, many studies have attempted and made achievements  [Bao et al., 2021; Zhong et al., 2020; Luo et al., 2018] . However, there is still considerable room to improve the performance.\n\nTo address the two aforementioned issues on subjectindependent emotion recognition, we propose a novel EEGbased emotion recognition model called domain adversarial graph attention model (DAGAM). First, we use a graph to model EEG signals based on biological topology. Then, the graph convolutional networks with self-attention pooling are applied to extract EEG features strongly correlated with emotions. Finally, after graph pooling, the domain adversarial based on the graph is employed to identify emotions across subjects. The main contributions lie in the following aspects:\n\n• The basic idea of DAGAM is to generate a graph to model multichannel EEG signals using biological topology. The use of graph attention neural networks (GANN) effectively explores the relationships among multiple EEG channels for emotion recognition. Unlike other graph convolutional networks, self-attention pooling is applied to benefit salient EEG feature extraction from the graph, which effectively improves the performance. • The domain adversarial (DA) based on the graph is employed to identify and handle EEG variation across subjects. Combining DA and GANN, the source domain and the target domain can adapt to each other. After evaluating DAGAM on two public emotion EEG datasets: SEED  [Zheng and Lu, 2015] , SEED IV  [Zheng et al., 2019] , we found that our model has achieved the state of the art results in subject-independent emotion recognition, reaching a superior accuracy of performance with the lowest standard deviation (SEED: 92.59%/3.21%, SEED-IV: 80.74%/4.14%) compared to other methods.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Work",
      "text": "EEG-based emotion recognition has received increased attention in recent years. The methods can be categorized into two groups. One group focuses on finding crucial features.  Shi et al. [Shi et al., 2013]  proposed a novel feature called differential entropy for EEG-based vigilance estimation. Jenke et al.  [Jenke et al., 2014]  reviewed a wide range of features to attempt to find suitable features for relevant emotions.  Wang et al. [Wang and Nie, 2014]  compared three existing EEG features: power spectrum, wavelet, and nonlinear dynamical analysis for improving emotion recognition. Another group is committed to proposing better classification algorithms. Petrantonakis et al. proposed a robust emotion recognition method based on higher order crossings (HOC) analysis.  Zhang et al. [Zhang et al., 2020]  proposed a heuristic Variational Pathway Reasoning (VPR) method to deal with EEG-based emotion recognition.  Xu et al. [Xu et al., 2020]  proposed a dynamic adaptive convolutional quorum voting approach for variable-length EEG data.\n\nRecently, increased researchers have paid attention to subject-independent emotion recognition. For example, Li et al.  [Li et al., 2020]  proposed a multisource transfer learning method for cross-subject EEG emotion recognition.  Li et al. [Li et al., 2018b]  proposed a bi-hemisphere domain adversarial neural network (BiDANN) model, which achieves good performance on cross-subject recognition. However, compared with the performance of subject-dependent emotion recognition, there is still room to improve for subjectindependent emotion recognition.\n\nAfter the first Graph Neural Network (GNN) was proposed in 2009  [Scarselli et al., 2009] , different GNNs are applied to different fields. EEG data are considered to belong to non-Euclidean domains, which can be represented as a graph. Graph model contains rich relational information  [Z et al., 2020] , and can reflect the connections between different regions of the brain. At present, many researchers attempt to apply it to the domain of EEG-based emotion recognition.  Song et al. [Song et al., 2020]  proposed novel dynamical graph convolutional neural networks. Zhong et al.  [Zhong et al., 2020]  proposed a regularized graph neural network (RGNN) for EEG-based emotion recognition, which extracts both local and global features among different EEG channels based on the biological topology among different brain regions. These methods only benefit some known biological features, but did not try to use unknown crucial internal connections and features via learning. The direction of future research is how to graph model and attention mechanism to find the salient features of EEG signals related to emotions.  Domain-Adversarial Neural Network [Ganin et al., 2016]  was the first work to demonstrate the success for two distinctive classification problems in 2016. Soon, it was widely used in the field of emotion recognition.  Li et al. [Li et al., 2018a]  applied Deep Adaptation Network (DAN) to eliminate the individual differences in EEG signals.  Luo et al. [Luo et al., 2018]  proposed a novel Wasserstein Generative Adversarial Network Domain Adaptation (WGANDA) framework for building cross-subject EEG-based emotion recognition models.  Bao et al. [Bao et al., 2021]  proposed a Two-level Domain Adaptation Neural Network (TDANN) to construct a transfer model for EEG-based emotion recognition.  Zhao et al. [Zhao and Lu, 2021]  proposed a plug-and-play domain adaptation method for dealing with the individual difference. It points out the research direction for subject-independent emotion recognition and finds a suitable classifier for domain adversarial.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Domain Adversarial Graph Attention Model",
      "text": "The structure of Domain Adversarial Graph Attention Model (DAGAM) is as shown in Fig.  1 . It contains three main parts: EEG data modeling based on the graph, graph attention neural networks, and domain adversarial based on the graph. First, the EEG data are modeled based on EEG channels' dependencies. Next, the graph attention neural is proposed to extract the core features and discard the unimportant channels in the graph structure. Finally, domain adversarial based on the graph helps to handle cross-subject EEG variations, enabling to achieve good performance on subject-independent emotion recognition. The detail of each part is provided as follows. The first thing is to model EEG signals by the graph. The basic graph can be expressed as a set of vertices and edges, denoted as G = (V, E), where V is the set of vertices and E is the set of edges. In our work, the vertices set can be expressed as the matrix X ∈ R N ×D , and the edge set can be expressed as the adjacency matrix A ∈ R N ×D , where N represents the number of EEG channels, D represents EEG data over time.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Eeg Modeling Based On The Graph",
      "text": "A is used to reflect the biological topography of EEG and indicates the relationship of EEG channels. The spatial dis- tance between the channels is used to define the weight of the edge. To correctly reflect this kind of relationship, we attempt to define the element of the adjacency matrix based on the method proposed by  [Zhong et al., 2020] , as follows:\n\nwhere d ij notes the physical distance between channels i and j, σ is a constant, used to calibrate the weight A ij can fall within (0, 1) Several global connections are added to the adjacency matrix to improve network efficiency. The global connection depends on the specific electrode position used in the experiment. Previous biological studies have proved that the asymmetry of neuronal activity between the left and right hemispheres is informative in terms of potency and arousal prediction, which have supported the selection of global channels. To use this information, we initialize the global inter-channel relationship in A to [-1, 0].",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Graph Attention Neural Networks",
      "text": "Graph structure helps us to model EEG data. However, longperiod EEG data with a complicated graph structure brings high computational cost for emotion recognition. The pooling method considers features both in the channels and the whole structure of the graph and removes the influence of unimportant nodes. It attempts to use a reasonable number of parameters to obtain better graph classification performance. Inspired by the work of  [Lee et al., 2019] , we adopted a graph pooling method based on self-attention, called SAGPool, to extract crucial features from EEG data. The detailed steps will be shown as follows:\n\nFirst, the EEG data is processed by three layers of GNN to obtain the self-attention score. A widely used GNN model, Graph Convolutional Networks (GCN)  [Kipf and Welling, 2017] , is implemented here, which is formulated as follows:\n\nwhere σ is the activation function of the layer network, and W att is a weighted matrix used to perform affine transformation on the input graph signal. Lsym is the re-normalized Laplacian matrix following by  [Kipf and Welling, 2017] .\n\nThe index and Score mask of self-attention graph pooling can be obtained as follows:\n\nwhere k ∈ (0, 1] is the proportion of nodes retained, top[kN ] is based on the self-attention score Score to select the nodes with the top proportion k, and N is the total number of nodes, top -rank[kN ] returns the index of the node of top[kN ], and then performs an index operation on Score to update the mask Score mask .\n\nNext, we perform a pooling operation on feature data by GCN. The new feature matrix and the corresponding adja-cency matrix are obtained as follows:\n\nwhere represents the broadcasted element-wise product, X out is the new feature matrix and A out refers to the corresponding adjacency matrix.\n\nFinally, the readout layer is provided to change features to the fixed size before graph classification. The representation results are concatenated by global average pooling and global max pooling, which is shown as follows:\n\nwhere N is the number of nodes, X i represents the feature value of i-th node, and is a concatenation operator.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Domain Adversarial Based On The Graph",
      "text": "Due to individual differences in emotion, the generalization of the emotion recognition model usually did not perform well. To improve the generalization performance of our model among different subjects, we propose a method of domain adversarial based on the graph.\n\nThe main advantage of our method is to reduce the computational complexity significantly. Differing from the work  [Zhong et al., 2020] , we apply domain adversarial to the graph after self-attention pooling instead to nodes, since this graph after pooling contains the crucial features obtained by extracting from GCN. The input data of the domain adversarial based on the graph are from the readout layer, including the source and target domains.\n\nThe core of domain adversarial based on the graph is the domain classifier. In the training process, the mixed samples from the source domain with labels and the target domain without labels are put into the domain adversarial model. To achieve effective domain migration, the domain classifier in this model is expected not to successfully distinguish between the training (source) domain data and the testing (target) domain data. During training, the domain classifier discriminates between the source and the target domains, and nocrucial features of the source domain and target are removed.\n\nFor the loss function that needs to be optimized, we select X S , X T ⊆ GCN f erture ∈ R G×d from GCN f erture , where X S is the source domain data, X T is the target domain data, G is the number of graphs, d is the dimension of the graph data. The data label belonging to the source domain is set to 0, and the data label belonging to the target domain is set to 1. It is converted to one-hot form as\n\nand then cross entropy (CE) is employed to construct as follows:\n\nClassifier in domain adversarial based on the graph is a three-layer fully connected neural network for emotion recognition, which attempts to find the correct emotion based on features from graph self-attention pooling. Kullback-Leibler (KL) divergence is adopted as the loss function of the emotion recognition classifier, since it can measure how one probability distribution is different from another.\n\nwhere Ŷ represents the real data, a measured probability distribution. Distribution q(x i ) represents instead a theory distribution of the data.\n\nThe training process is to minimize E all , which is sum of the emotion recognition loss (L i y ) and the domain classification loss (L i d ).",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Experiments And Evaluation",
      "text": "To evaluate our model, we apply DAGAM to two public emotion EEG-based datasets: SJTU Emotion EEG Dataset (SEED)  [Zheng and Lu, 2015] , and an evolution of the original SEED dataset (SEED IV)  [Zheng et al., 2019] .",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Implementation Details",
      "text": "In the experiment for two datasets, we set hyper-parameters in DAGAM as follows: the number of GCN layers L is 3; the pooling ratio k used in self-attention pooling is set to 0.5. The classifier of emotion recognition based on the graph is a three-layer fully connected neural network. The Adam is used as the model's gradient descent optimizer with the value of 0.001. We implemented the whole model by Py-Torch. The model runs on the server with Intel Core i9-9900K CPU @ 3.60GHz, 32GB memory, 512GB SSD, and NVIDIA GeForce RTX 3090 running Linux Ubuntu 18.04.03LTS.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Dataset Instruction",
      "text": "These datasets collect EEG signals by the same device: ESI NeuroScan with 62 channel electrodes according to the international 10-20 system at a sampling rate of 1000Hz. The raw EEG signals from these datasets are preprocessed and extract different salient features based on previous studies  [Shi et al., 2013] . The detailed information is provided as follows.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Seed And Seed Iv",
      "text": "In the SEED, 15 film clips were chosen to invoke three kinds of emotions: positive, neutral, and negative. Fifteen subjects participated in the experiment. There were 15 trials for each subject in the experiment. In the SEED IV, 72 film clips were chosen to invoke four kinds of emotions: happy, sad, fear, or neutral. It had also recruited 15 subjects to participate in this experiment. Three sessions, including 24 trials, were performed on different days for each subject. The raw EEG data were downsampled at 200Hz to facilitate recognition. Then a bandpass filter with 1Hz to 75Hz was applied to remove the noise and artifacts. In our experiments, a time-frequency domain feature, called differential entropy (DE)  [Shi et al., 2013]  was extracted.\n\nwhere the time series X follows the Gauss distribution N (µ, σ 2 ).",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Performance Analysis",
      "text": "We compare DAGAM with other baseline methods to comprehensively evaluate our model, including the state-of-theart (SOTA) in mean accuracy and standard deviation for SEED and SEED IV, respectively. The confusion matrix analysis is provided following. It ends with the ablation study.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Subject-Independent Emotion Recognition",
      "text": "We conduct experiments on two datasets (SEED and SEED IV) using Leave-one-out cross-validation (LOOCV) to evaluate the performance of DAGAM on subject-independent emotion recognition. The experiment settings are followed by  [Li et al., 2021b; Zhong et al., 2020] , which tests our DAGAM on one subject and trains on the remaining subjects for each fold. LOOCV evaluates every subject in datasets.\n\nThe mean accuracy (ACC) and standard deviation (STD) are compared.\n\nThe performance of our DAGAM is shown in Table  1 , which lists the comparison between the DAGAM model and other methods in the subject-independent in SEED and SEED IV. The comparison includes 17 methods as follows:  KLIEP [Kanamori et al., 2009] , ULSIF  [Kanamori et al., 2009] , STM  [Chu et al., 2017] , SVM  [Suykens and Vandewalle, 1999] ,TCA  [Pan et al., 2011] , SA  [Fernando et al., 2013] ,  GFK [Gong et al., 2012] , A-LSTM  [Song et al., 2019] , T-SVM  [Collobert et al., 2006] ,  DANN [Ganin et al., 2016] , DAN  [Li et al., 2018a] , BiDANN-S  [Li et al., 2018b] , Bi-HDM  [Li et al., 2021a] , RGNN  [Zhong et al., 2020]  DAGAM achieves the highest accuracy with the lowest standard deviation. It improves the accuracy of SOTA by 4.69% for SEED and 6.90% for SEED IV, respectively.\n\nWe directly quota emotion recognition results of other baselines from the work of  [Li et al., 2021b] . Our model improved substantially the performed much better than others concerning the accuracy, but with a relatively high standard deviation. We have double-checked our results.\n\nIn the aforementioned experiments, our DAGAM can further improve the subject-independent emotion recognition compared with other methods. Among the methods compared with our model, there are two methods that use graph neural networks:  DGCNN [Song et al., 2020]  and RGNN  [Zhong et al., 2020]  and six methods that use domain adversarial training:  TDANN [Bao et al., 2021] ,  WGAN-DA [Luo et al., 2018] , RGNN  [Zhong et al., 2020] , DAN  [Li et al., 2018a] , BiDANN-S  [Li et al., 2018b] ,  DANN [Ganin et al., 2016] . No one adopted the attention mechanism. Therefore, we assume that the graph self-attention pooling helps effectively to extract crucial invariable features and remove irrelevant ones.\n\nTo further verify this assumption, we do further experiments. In each round of the experiments on two datasets, we modify the core hyper parameters in graph attention neural networks: top proportion k. Table  2  shows the results. It can be easily found that the experimental results have undergone obvious changes, especially on SEED almost 5%. So the graph self-attention pooling did play a central role in our model.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Confusion Matrix Analysis",
      "text": "To make a deep insight into our model for different emotions, we provide the confusion matrix for SEED and SEED IV. As shown in Fig.  2  For SEED, as shown in Fig.  2a , our model performs a highlevel accuracy for all emotions. It performs on neutral emotions much better than others, while it is not very sensitive to negative emotions. The nearly 10% of neural and negative emotions are misrecognized with negative motion.\n\nFor SEED IV, as shown in Fig.  2b , our model performs around 80% for all four categorized emotions. It is good at distinguishing happy, but weak in recognizing neural. 8.15% of neural emotions are categorized as sad by mistakes, and 7.04% and 6.30% of it are recognized as fear and happy, respectively.\n\nOverall, the model shows a fairly high level of emotion recognition.  attention pooling is adopted in the feature extraction phase to extract crucial features based on biological topology. In the phase of graph classification, KL divergence is adopted to handle inaccurate emotion labels, which can quantify differences between the probability distribution of the training set and the testing set. In the training phase, the domain adversarial based on the graph is an attempt to solve the problem of the same labels with different distributions, that is, domain adaption.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Ablation Study",
      "text": "To study the effects of the three core parts in the model, we conducted the ablation study (three further experiments) to verify them. In the first experiment, we disable domain adversarial and only use other parts to recognize emotions to study the effects of domain adversarial based on the graph. In the second experiment, we replace KL divergence with the other loss function: cross-entropy to investigate the effect of KL divergence. In the third experiment, we attempt to find the effects of graph self-attention pooling by disabling domain adversarial and replacing KL divergence.\n\nThe results are shown in the Table . 3. The KL divergence has a significant impact on the performance of the model, especially on SEED. Without the KL divergence, the accuracy of SEED drops by nearly 5.78%. The domain adversarial based on the graph affects the performance as well, and the accuracy of the two datasets all decreases. We found that only domain adversarial is applied, and its accuracy does not have a large impact. If only the graph self-attention pooling is applied, it remains a good accuracy on these two datasets. This result verifies our previous assumption again that the graph self-attention pooling is a crucial part of our model.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Conclusion",
      "text": "This study contributes to the growing area of EEG-based subject-independent emotion recognition by proposing a domain adversarial graph attention model (DAGAM). DAGAM is powerful in learning the relationships among EEG channels based on graph pooling. The use of self-attention pooling benefits extracting salient features for the emotion recognition task. The domain adversarial training based on the graph contributes significantly to tackling the cross-subject EEG variations issue. Extensive experiments on two public datasets (SEED and SEED IV) show that the performance of our model achieves SOTA, providing the highest accuracy and low standard deviation than other competitive baselines. In our future work, we will continue to move along the line of graph models.",
      "page_start": 6,
      "page_end": 6
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: The structure of Domain Adversarial Graph Attention Model",
      "page": 3
    },
    {
      "caption": "Figure 2: The confusion matrices of the subject-independent EEG",
      "page": 6
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Graph self-attention": "pooling"
        }
      ],
      "page": 3
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Two-Level Domain Adaptation Neural Network for EEG-Based Emotion Recognition",
      "year": "2006",
      "venue": "Proceedings of Machine Learning Research"
    },
    {
      "citation_id": "2",
      "title": "A Bi-hemisphere Domain Adversarial Neural Network Model for EEG Emotion Recognition",
      "authors": [
        "Li"
      ],
      "year": "2018",
      "venue": "Neural Information Processing"
    },
    {
      "citation_id": "3",
      "title": "Multisource Transfer Learning for Cross-Subject EEG Emotion Recognition",
      "authors": [
        "Li"
      ],
      "year": "2020",
      "venue": "IEEE TCYB"
    },
    {
      "citation_id": "4",
      "title": "A Novel Bi-Hemispheric Discrepancy Model for EEG Emotion Recognition",
      "authors": [
        "Li"
      ],
      "year": "2021",
      "venue": "IEEE TCDS"
    },
    {
      "citation_id": "5",
      "title": "A Bi-Hemisphere Domain Adversarial Neural Network Model for EEG Emotion Recognition",
      "authors": [
        "Li"
      ],
      "year": "2011",
      "venue": "Neural Information Processing"
    },
    {
      "citation_id": "6",
      "title": "MPED: A Multi-Modal Physiological Emotion Database for Discrete Emotion Recognition",
      "authors": [
        "Scarselli"
      ],
      "year": "2009",
      "venue": "2013 35th Annual International Conference of the IEEE (EMBC)"
    },
    {
      "citation_id": "7",
      "title": "Decode Brain System: A Dynamic Adaptive Convolutional Quorum Voting Approach for Variable-Length EEG Data",
      "authors": [
        "Vandewalle Suykens",
        "J Suykens",
        "J Vandewalle",
        "; X Wang",
        "B Nie",
        "Dand Lu ; Xu",
        "Y Zhou",
        "Z Hou",
        "W Zhang",
        "Y Yuan"
      ],
      "year": "1999",
      "venue": "Neural Processing Letters"
    },
    {
      "citation_id": "8",
      "title": "Graph neural networks: A review of methods and applications",
      "year": "2020",
      "venue": "AI Open"
    },
    {
      "citation_id": "9",
      "title": "Variational Pathway Reasoning for EEG Emotion Recognition",
      "authors": [
        "Zhang"
      ],
      "year": "2020",
      "venue": "AAAI"
    },
    {
      "citation_id": "10",
      "title": "Investigating Critical Frequency Bands and Channels for EEG-Based Emotion Recognition with Deep Neural Networks",
      "authors": [
        "Lu ; X Zhao",
        "Land Zhao",
        "B Yan",
        "; W Lu",
        "B Zheng",
        "Lu"
      ],
      "year": "2015",
      "venue": "IEEE TAMD"
    },
    {
      "citation_id": "11",
      "title": "EmotionMeter: A Multimodal Framework for Recognizing Human Emotions",
      "authors": [
        "Zheng"
      ],
      "year": "2019",
      "venue": "IEEE TCYB"
    },
    {
      "citation_id": "12",
      "title": "EEG-Based Emotion Recognition Using Regularized Graph Neural Networks",
      "authors": [
        "Zhong"
      ],
      "year": "2020",
      "venue": "IEEE TAFFC"
    }
  ]
}